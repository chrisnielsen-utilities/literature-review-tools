{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5124ef2f",
   "metadata": {},
   "source": [
    "# The purpose of this script is to analyze the 2021 NeurIPS papers and rank them by review scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c011ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "14cf6e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import pprint\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41046e82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4aca9b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bbbdaa15",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e1131912",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/2021_neurips_processed_paper_data.pkl' ,'rb') as file:\n",
    "    paper_data = pickle.load(file)\n",
    "\n",
    "paper_by_name_dict = {}\n",
    "for paper in paper_data:\n",
    "    \n",
    "    if paper['title'] in paper_by_name_dict:\n",
    "        paper_by_name_dict[paper['title']]['review_2'] = paper\n",
    "    else:\n",
    "        paper_by_name_dict[paper['title']] = paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcf72d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39128627",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "493ba7db",
   "metadata": {},
   "source": [
    "### Compute the number of papers with code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4bd1d724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1507 papers have code out of 2469 total papers\n",
      "61.04% of papers come with code\n"
     ]
    }
   ],
   "source": [
    "papers_with_code = 0\n",
    "for paper_name in paper_by_name_dict:\n",
    "    paper = paper_by_name_dict[paper_name]\n",
    "    \n",
    "    if paper['code'] is not None:\n",
    "        papers_with_code += 1\n",
    "        \n",
    "print('%d papers have code out of %d total papers' % (papers_with_code, len(paper_by_name_dict)))\n",
    "print('%.02f%% of papers come with code' % (100*papers_with_code/len(paper_by_name_dict)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd24a834",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da7d05a9",
   "metadata": {},
   "source": [
    "### Compute the occurrence of keywords over the set of papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3ccfeb18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of distinct keywords: 5384\n",
      "183 reinforcement learning\n",
      "130 deep learning\n",
      "59 self-supervised learning\n",
      "56 representation learning\n",
      "54 generalization\n",
      "54 transformer\n",
      "53 graph neural networks\n",
      "50 robustness\n",
      "49 meta-learning\n",
      "47 online learning\n",
      "44 differential privacy\n",
      "41 optimization\n",
      "41 computer vision\n",
      "40 neural networks\n",
      "39 federated learning\n",
      "38 fairness\n",
      "38 adversarial robustness\n",
      "37 generative models\n",
      "37 transfer learning\n",
      "37 contrastive learning\n",
      "35 causal inference\n",
      "34 convex optimization\n",
      "34 variational inference\n",
      "33 transformers\n",
      "31 learning theory\n",
      "30 unsupervised learning\n",
      "30 gaussian processes\n",
      "29 interpretability\n",
      "29 machine learning\n",
      "29 deep reinforcement learning\n",
      "28 graph neural network\n",
      "26 statistical learning theory\n",
      "25 domain adaptation\n",
      "25 few-shot learning\n",
      "24 exploration\n",
      "23 active learning\n",
      "23 sparsity\n",
      "23 continual learning\n",
      "22 attention\n",
      "22 theory\n",
      "22 calibration\n",
      "21 stochastic optimization\n",
      "21 multi-armed bandits\n",
      "20 neuroscience\n",
      "20 regularization\n",
      "20 optimal transport\n",
      "20 clustering\n",
      "19 distributed optimization\n",
      "19 imitation learning\n",
      "19 multi-agent reinforcement learning\n",
      "19 adversarial examples\n",
      "19 bayesian optimization\n",
      "18 natural language processing\n",
      "18 vision transformer\n",
      "18 image classification\n",
      "18 object detection\n",
      "18 kernel methods\n",
      "18 explainability\n",
      "17 semi-supervised learning\n",
      "17 non-convex optimization\n",
      "17 density estimation\n",
      "17 causality\n",
      "17 offline reinforcement learning\n",
      "16 classification\n",
      "16 domain generalization\n",
      "16 gradient descent\n",
      "16 deep neural networks\n",
      "15 data augmentation\n",
      "15 dynamical systems\n",
      "15 knowledge distillation\n",
      "15 uncertainty quantification\n",
      "15 bayesian inference\n",
      "15 bandits\n",
      "15 generative adversarial networks\n",
      "15 reinforcement learning theory\n",
      "14 stochastic gradient descent\n",
      "14 information theory\n",
      "14 deep learning theory\n",
      "14 adversarial training\n",
      "14 neural architecture search\n",
      "14 sample complexity\n",
      "14 model-based reinforcement learning\n",
      "13 generative model\n",
      "13 bayesian neural networks\n",
      "13 invariance\n",
      "13 graph representation learning\n",
      "13 normalizing flows\n",
      "13 recurrent neural networks\n",
      "13 uncertainty\n",
      "13 equivariance\n",
      "13 semantic segmentation\n",
      "13 combinatorial optimization\n",
      "12 gaussian process\n",
      "12 variational autoencoder\n",
      "12 consistency\n",
      "12 deep generative models\n",
      "12 gan\n",
      "12 learning\n",
      "12 multi-task learning\n",
      "11 neural network\n",
      "11 acceleration\n",
      "11 nonconvex optimization\n",
      "11 neural tangent kernel\n",
      "11 explainable ai\n",
      "11 uncertainty estimation\n",
      "11 time series\n",
      "10 point clouds\n",
      "10 image generation\n",
      "10 variance reduction\n",
      "10 thompson sampling\n",
      "10 causal discovery\n",
      "10 meta learning\n",
      "10 generative modeling\n",
      "10 curriculum learning\n",
      "10 sampling\n",
      "9 disentanglement\n",
      "9 self-attention\n",
      "9 bayesian methods\n",
      "9 stability\n",
      "9 scalability\n",
      "9 manifold learning\n",
      "9 gnn\n",
      "9 out-of-distribution generalization\n",
      "9 information bottleneck\n",
      "9 sgd\n",
      "9 model compression\n",
      "9 compression\n",
      "9 neural odes\n",
      "9 statistical learning\n",
      "9 image synthesis\n",
      "9 regret\n",
      "9 regret minimization\n",
      "8 healthcare\n",
      "8 hyperparameter optimization\n",
      "8 out-of-distribution detection\n",
      "8 distribution shift\n",
      "8 high-dimensional statistics\n",
      "8 convolutional neural networks\n",
      "8 benchmark\n",
      "8 implicit regularization\n",
      "8 wasserstein distance\n",
      "8 lottery ticket hypothesis\n",
      "8 off-policy evaluation\n",
      "8 graph\n",
      "8 adversarial learning\n",
      "8 inverse problems\n",
      "8 multi-armed bandit\n",
      "8 spiking neural networks\n",
      "7 decentralized optimization\n",
      "7 lower bounds\n",
      "7 bayesian\n",
      "7 privacy\n",
      "7 computational neuroscience\n",
      "7 compositionality\n",
      "7 interpolation\n",
      "7 bayesian deep learning\n",
      "7 self-supervision\n",
      "7 matrix factorization\n",
      "7 structure learning\n",
      "7 overparameterization\n",
      "7 pruning\n",
      "7 multi-agent\n",
      "7 approximate inference\n",
      "7 constrained optimization\n",
      "7 inverse reinforcement learning\n",
      "7 adversarial attacks\n",
      "7 normalizing flow\n",
      "7 offline rl\n",
      "7 augmentation\n",
      "7 debiasing\n",
      "7 ranking\n",
      "7 algorithms\n",
      "7 robust learning\n",
      "7 mutual information\n",
      "7 vae\n",
      "7 planning\n",
      "7 contextual bandits\n",
      "7 out-of-distribution\n",
      "7 algorithmic stability\n",
      "7 coresets\n",
      "7 safe reinforcement learning\n",
      "6 memory\n",
      "6 probabilistic models\n",
      "6 multi-agent learning\n",
      "6 game theory\n",
      "6 topology\n",
      "6 generative modelling\n",
      "6 confidence intervals\n",
      "6 model selection\n",
      "6 complexity\n",
      "6 diffusion\n",
      "6 link prediction\n",
      "6 emergent communication\n",
      "6 program synthesis\n",
      "6 inductive bias\n",
      "6 evaluation\n",
      "6 physics\n",
      "6 unsupervised domain adaptation\n",
      "6 visual question answering\n",
      "6 distributionally robust optimization\n",
      "6 structured prediction\n",
      "6 bi-level optimization\n",
      "6 tensor decomposition\n",
      "6 imagenet\n",
      "6 differential equations\n",
      "6 distributed training\n",
      "6 graphical models\n",
      "6 instance segmentation\n",
      "6 partial differential equations\n",
      "6 certified robustness\n",
      "6 mcmc\n",
      "6 energy-based models\n",
      "6 algorithmic fairness\n",
      "6 vision transformers\n",
      "6 policy gradient\n",
      "6 global convergence\n",
      "6 hierarchical reinforcement learning\n",
      "6 variational autoencoders\n",
      "6 mechanism design\n",
      "6 langevin dynamics\n",
      "6 safety\n",
      "6 3d reconstruction\n",
      "6 image recognition\n",
      "6 generalization bounds\n",
      "6 quantization\n",
      "6 linear function approximation\n",
      "6 geometric deep learning\n",
      "6 neural ode\n",
      "5 discrete optimization\n",
      "5 3d object detection\n",
      "5 hyperbolic space\n",
      "5 rademacher complexity\n",
      "5 counterfactual\n",
      "5 multimodal\n",
      "5 automl\n",
      "5 linear regression\n",
      "5 question answering\n",
      "5 gradient flow\n",
      "5 reasoning\n",
      "5 score matching\n",
      "5 riemannian optimization\n",
      "5 stochastic approximation\n",
      "5 3d\n",
      "5 nlp\n",
      "5 regret analysis\n",
      "5 implicit bias\n",
      "5 pure exploration\n",
      "5 pose estimation\n",
      "5 k-means\n",
      "5 positional encoding\n",
      "5 inference\n",
      "5 inverse problem\n",
      "5 identifiability\n",
      "5 generalization bound\n",
      "5 intrinsic motivation\n",
      "5 symmetry\n",
      "5 catastrophic forgetting\n",
      "5 generative adversarial network\n",
      "5 supervised learning\n",
      "5 dropout\n",
      "5 adversarial\n",
      "5 backpropagation\n",
      "5 gradient estimation\n",
      "5 markov decision process\n",
      "5 adversarial attack\n",
      "5 double descent\n",
      "5 knowledge graphs\n",
      "5 policy optimization\n",
      "5 locality sensitive hashing\n",
      "5 neural rendering\n",
      "5 scaling\n",
      "5 importance sampling\n",
      "5 linear bandits\n",
      "5 lower bound\n",
      "5 multi-view learning\n",
      "5 function approximation\n",
      "5 approximation\n",
      "5 bert\n",
      "5 monte carlo\n",
      "5 persistent homology\n",
      "5 denoising\n",
      "5 boosting\n",
      "5 tree search\n",
      "5 adversarial machine learning\n",
      "5 image restoration\n",
      "5 quantile regression\n",
      "5 stochastic differential equations\n",
      "5 efficiency\n",
      "5 bandit\n",
      "5 online convex optimization\n",
      "5 logistic regression\n",
      "5 empirical risk minimization\n",
      "5 statistical physics\n",
      "5 conformal prediction\n",
      "4 momentum\n",
      "4 riemannian geometry\n",
      "4 compressed sensing\n",
      "4 integer programming\n",
      "4 zero-shot learning\n",
      "4 negative sampling\n",
      "4 generalization error\n",
      "4 automated machine learning\n",
      "4 interpretable machine learning\n",
      "4 security\n",
      "4 synaptic plasticity\n",
      "4 diffusion models\n",
      "4 manifold\n",
      "4 architecture\n",
      "4 video object segmentation\n",
      "4 graphs\n",
      "4 query complexity\n",
      "4 video understanding\n",
      "4 routing\n",
      "4 label noise\n",
      "4 gans\n",
      "4 expectation-maximization\n",
      "4 hessian\n",
      "4 min-max optimization\n",
      "4 convergence analysis\n",
      "4 regression\n",
      "4 recurrent neural network\n",
      "4 lossless compression\n",
      "4 benchmarks\n",
      "4 embodied ai\n",
      "4 parameter sharing\n",
      "4 few-shot classification\n",
      "4 image retrieval\n",
      "4 molecule generation\n",
      "4 learning with noisy labels\n",
      "4 neural coding\n",
      "4 network pruning\n",
      "4 recommender systems\n",
      "4 differentiable rendering\n",
      "4 knowledge graph\n",
      "4 energy-based model\n",
      "4 concentration inequalities\n",
      "4 mirror descent\n",
      "4 data poisoning\n",
      "4 loss landscape\n",
      "4 communication compression\n",
      "4 gaussian mixture model\n",
      "4 data privacy\n",
      "4 synthetic data\n",
      "4 attention mechanism\n",
      "4 explanations\n",
      "4 resnet\n",
      "4 motor control\n",
      "4 feature attribution\n",
      "4 time series forecasting\n",
      "4 certified defense\n",
      "4 noisy labels\n",
      "4 hypothesis testing\n",
      "4 evolution\n",
      "4 randomized smoothing\n",
      "4 deep neural network\n",
      "4 streaming algorithms\n",
      "4 hamiltonian monte carlo\n",
      "4 preference learning\n",
      "4 pac learning\n",
      "4 weakly supervised learning\n",
      "4 missing data\n",
      "4 probabilistic circuits\n",
      "4 hypergraph\n",
      "4 action recognition\n",
      "4 self-supervised\n",
      "4 actor-critic\n",
      "4 class imbalance\n",
      "4 vision\n",
      "4 bilevel optimization\n",
      "4 vqa\n",
      "4 online\n",
      "4 temporal abstraction\n",
      "4 options\n",
      "4 out of distribution\n",
      "4 convolution\n",
      "4 hypernetworks\n",
      "4 deep networks\n",
      "4 distributed learning\n",
      "4 mixture models\n",
      "4 kernels\n",
      "4 stochastic convex optimization\n",
      "4 autoencoders\n",
      "4 implicit deep learning\n",
      "4 regret bounds\n",
      "4 latent variable models\n",
      "4 mdp\n",
      "4 wasserstein barycenter\n",
      "4 language grounding\n",
      "4 linear programming\n",
      "4 robotics\n",
      "4 rkhs\n",
      "4 nash equilibrium\n",
      "4 robust statistics\n",
      "4 multi-modal\n",
      "4 topological data analysis\n",
      "4 deep generative model\n",
      "4 ntk\n",
      "4 cnn\n",
      "4 semidefinite programming\n",
      "4 machine translation\n",
      "4 kernel ridge regression\n",
      "4 replica method\n",
      "4 lasso\n",
      "4 dynamic programming\n",
      "4 spectral methods\n",
      "4 vision-and-language navigation\n",
      "3 low-rank\n",
      "3 dynamics\n",
      "3 ood\n",
      "3 neuroimaging\n",
      "3 graph embedding\n",
      "3 image segmentation\n",
      "3 text generation\n",
      "3 concept learning\n",
      "3 energy based models\n",
      "3 distillation\n",
      "3 test time adaptation\n",
      "3 video representation learning\n",
      "3 kernel machines\n",
      "3 hyperparameter tuning\n",
      "3 zero-sum games\n",
      "3 universal approximation\n",
      "3 systematic generalization\n",
      "3 language understanding\n",
      "3 adversarial defense\n",
      "3 geodesic convexity\n",
      "3 expressive power\n",
      "3 deep rl\n",
      "3 nonparametric\n",
      "3 q-learning\n",
      "3 unrolling\n",
      "3 welfare\n",
      "3 expressivity\n",
      "3 generalisation\n",
      "3 communication complexity\n",
      "3 second-order methods\n",
      "3 stochastic processes\n",
      "3 online optimization\n",
      "3 riemannian manifolds\n",
      "3 distributed\n",
      "3 best of both worlds\n",
      "3 stochastic bilevel optimization\n",
      "3 tracking\n",
      "3 bayesian networks\n",
      "3 lstm\n",
      "3 pretrained language models\n",
      "3 video prediction\n",
      "3 overfitting\n",
      "3 multitask learning\n",
      "3 adaptive methods\n",
      "3 interventions\n",
      "3 dnn\n",
      "3 domain shift\n",
      "3 differential geometry\n",
      "3 pairwise learning\n",
      "3 frank-wolfe\n",
      "3 variational methods\n",
      "3 entropy regularization\n",
      "3 optimal control\n",
      "3 sparse training\n",
      "3 text to speech\n",
      "3 datasets\n",
      "3 prediction with expert advice\n",
      "3 molecules\n",
      "3 heavy tails\n",
      "3 multi-objective optimization\n",
      "3 graph mining\n",
      "3 model robustness\n",
      "3 world models\n",
      "3 geometry\n",
      "3 language model\n",
      "3 rnn\n",
      "3 reverse engineering\n",
      "3 non-convex\n",
      "3 continuous control\n",
      "3 visual grounding\n",
      "3 cognitive science\n",
      "3 addernet\n",
      "3 neural program synthesis\n",
      "3 sequence models\n",
      "3 spurious correlation\n",
      "3 point process\n",
      "3 compositional generalization\n",
      "3 human pose estimation\n",
      "3 counterfactual explanations\n",
      "3 pretraining\n",
      "3 decision trees\n",
      "3 metrics\n",
      "3 counterfactuals\n",
      "3 policy learning\n",
      "3 causal representation learning\n",
      "3 benchmarking\n",
      "3 reliability\n",
      "3 segmentation\n",
      "3 nonconvex\n",
      "3 sketching\n",
      "3 tensors\n",
      "3 differentiable\n",
      "3 multimodal learning\n",
      "3 embedding\n",
      "3 incremental learning\n",
      "3 statistics\n",
      "3 control\n",
      "3 best-arm identification\n",
      "3 decision theory\n",
      "3 memorization\n",
      "3 speech processing\n",
      "3 spatio-temporal\n",
      "3 machine teaching\n",
      "3 unsupervised\n",
      "3 visual navigation\n",
      "3 ensemble\n",
      "3 diversity\n",
      "3 adaptive\n",
      "3 off-policy learning\n",
      "3 state abstraction\n",
      "3 double machine learning\n",
      "3 svd\n",
      "3 knowledge transfer\n",
      "3 auction design\n",
      "3 hierarchical\n",
      "3 batch normalization\n",
      "3 pre-training\n",
      "3 markov random fields\n",
      "3 likelihood\n",
      "3 nonlinear ica\n",
      "3 independent component analysis\n",
      "3 initialization\n",
      "3 search\n",
      "3 training\n",
      "3 metric learning\n",
      "3 efficient attention\n",
      "3 deep ensembles\n",
      "3 implicit representations\n",
      "3 decentralized learning\n",
      "3 graph convolutional networks\n",
      "3 transferability\n",
      "3 deblurring\n",
      "3 compressive sensing\n",
      "3 decision making\n",
      "3 mixup\n",
      "3 successor features\n",
      "3 group equivariance\n",
      "3 multiclass classification\n",
      "3 collaborative learning\n",
      "3 determinantal point processes\n",
      "3 skill discovery\n",
      "3 unsupervised reinforcement learning\n",
      "3 graph embeddings\n",
      "3 experimental design\n",
      "3 state space models\n",
      "3 local sgd\n",
      "3 super-resolution\n",
      "3 personalization\n",
      "3 neural network pruning\n",
      "3 approximation algorithms\n",
      "3 online algorithms\n",
      "3 fmri\n",
      "3 metric\n",
      "3 markov decision process theory\n",
      "3 multi-agent communication\n",
      "3 applications\n",
      "3 rnns\n",
      "3 newton's method\n",
      "3 priors\n",
      "3 anomaly detection\n",
      "3 submodular\n",
      "3 permutation invariance\n",
      "3 communication constraints\n",
      "3 hebbian learning\n",
      "3 learning to optimize\n",
      "3 data-driven algorithm design\n",
      "3 random forests\n",
      "3 streaming\n",
      "3 stochastic block model\n",
      "3 dimensionality reduction\n",
      "3 probabilistic methods\n",
      "3 video\n",
      "3 autonomous driving\n",
      "3 language modeling\n",
      "3 markov chain monte carlo\n",
      "3 fast rates\n",
      "3 adaptivity\n",
      "3 neural processes\n",
      "3 decision tree\n",
      "3 visual reasoning\n",
      "3 selection bias\n",
      "3 bayesian network structure learning\n",
      "3 stochastic shortest path\n",
      "3 heterogeneity\n",
      "3 pac-bayes\n",
      "3 risk bounds\n",
      "3 directed graph\n",
      "3 convex\n",
      "3 control theory\n",
      "3 low-rank approximation\n",
      "3 fine-tuning\n",
      "3 hashing\n",
      "3 speech recognition\n",
      "3 decision-making\n",
      "3 coreset\n",
      "3 experience replay\n",
      "3 covariate shift\n",
      "3 metropolis-hastings\n",
      "3 feature selection\n",
      "3 rl\n",
      "3 atari\n",
      "3 off-policy\n",
      "3 policy\n",
      "3 local differential privacy\n",
      "3 visualization\n",
      "3 distributional reinforcement learning\n",
      "3 stochastic\n",
      "3 oracle complexity\n",
      "3 change point detection\n",
      "3 constrained markov decision process\n",
      "3 extrapolation\n",
      "3 neuromorphic computing\n",
      "3 bias\n",
      "3 neural sde\n",
      "3 graph learning\n",
      "3 retrieval\n",
      "2 weight decay\n",
      "2 majorization minimization\n",
      "2 sparse models\n",
      "2 dna\n",
      "2 biological learning\n",
      "2 zeroth-order optimization\n",
      "2 object discovery\n",
      "2 neural fields\n",
      "2 noise robustness\n",
      "2 best arm identification\n",
      "2 non-myopic\n",
      "2 support vector machines\n",
      "2 reproducing kernel hilbert spaces\n",
      "2 network\n",
      "2 functional analysis\n",
      "2 efficient adversarial training\n",
      "2 reconstruction\n",
      "2 computational imaging\n",
      "2 3d human pose estimation\n",
      "2 halfspaces\n",
      "2 natural language\n",
      "2 meta-rl\n",
      "2 sparse reward\n",
      "2 injective flows\n",
      "2 low rank\n",
      "2 bootstrap\n",
      "2 associative memory\n",
      "2 stochastic multi-armed bandits\n",
      "2 control variates\n",
      "2 audio\n",
      "2 crfs\n",
      "2 fair learning\n",
      "2 computational learning theory\n",
      "2 structure\n",
      "2 objects\n",
      "2 layouts\n",
      "2 behavioral cloning\n",
      "2 implicit regularisation\n",
      "2 generative neural networks\n",
      "2 online algorithm\n",
      "2 svm\n",
      "2 3d vision\n",
      "2 fisher information matrix\n",
      "2 martingale\n",
      "2 simulation-based inference\n",
      "2 hierarchical models\n",
      "2 best of three worlds\n",
      "2 adversarial corruption\n",
      "2 quantum machine learning\n",
      "2 systems neuroscience\n",
      "2 dynamic network\n",
      "2 stochastic gradient\n",
      "2 high probability bounds\n",
      "2 ood detection\n",
      "2 bayesian nonparametrics\n",
      "2 zero-shot\n",
      "2 time series analysis\n",
      "2 language model pretraining\n",
      "2 double oracle\n",
      "2 two-player zero-sum games\n",
      "2 scientific machine learning\n",
      "2 time series data\n",
      "2 video action recognition\n",
      "2 group normalization\n",
      "2 fourier features\n",
      "2 modularity\n",
      "2 plasticity\n",
      "2 fair classification\n",
      "2 video instance segmentation\n",
      "2 path integration\n",
      "2 theory of computation\n",
      "2 information flow\n",
      "2 social media\n",
      "2 temporal point process\n",
      "2 tabular data\n",
      "2 inverse graphics\n",
      "2 hyperbolic geometry\n",
      "2 recommendation\n",
      "2 bayes\n",
      "2 3d point cloud\n",
      "2 speech synthesis\n",
      "2 medical report generation\n",
      "2 neural network optimization\n",
      "2 graph classification\n",
      "2 image editing\n",
      "2 ftrl\n",
      "2 regularized learning\n",
      "2 matrix sensing\n",
      "2 personalized pagerank\n",
      "2 multi-agent system\n",
      "2 causal structure learning\n",
      "2 off-policy policy evaluation\n",
      "2 adam\n",
      "2 quasi-newton methods\n",
      "2 quality diversity\n",
      "2 efficient\n",
      "2 intrinsic control\n",
      "2 submodular maximization\n",
      "2 learning dynamics\n",
      "2 differential equation\n",
      "2 variational auto-encoder\n",
      "2 probabilistic\n",
      "2 convolutional neural network\n",
      "2 low-rank matrix recovery\n",
      "2 overparameterized learning\n",
      "2 laplacian\n",
      "2 perturb-and-map\n",
      "2 invariances\n",
      "2 defense\n",
      "2 theoretical analysis\n",
      "2 generalization guarantee\n",
      "2 upper confidence bound\n",
      "2 finite width corrections\n",
      "2 deep metric learning\n",
      "2 feature learning\n",
      "2 first order methods\n",
      "2 stackelberg games\n",
      "2 equilibrium\n",
      "2 underspecification\n",
      "2 predictive coding\n",
      "2 algorithm\n",
      "2 hardness\n",
      "2 blind super-resolution\n",
      "2 network interpretation\n",
      "2 topic model\n",
      "2 molecular property prediction\n",
      "2 sgld\n",
      "2 langevin\n",
      "2 wasserstein\n",
      "2 spectral normalization\n",
      "2 linear models\n",
      "2 speech enhancement\n",
      "2 optimal feedback control\n",
      "2 causal effect\n",
      "2 implicit neural representations\n",
      "2 value factorization\n",
      "2 chess\n",
      "2 projection\n",
      "2 efficient networks\n",
      "2 policy selection\n",
      "2 nonsmooth optimization\n",
      "2 low-rank decomposition\n",
      "2 optimal transportation\n",
      "2 posterior\n",
      "2 post-training\n",
      "2 lipschitz constant\n",
      "2 feature disentanglement\n",
      "2 sequence-to-sequence learning\n",
      "2 adaptive regret\n",
      "2 system 2\n",
      "2 sample efficiency\n",
      "2 logic\n",
      "2 conditional image generation\n",
      "2 intervention\n",
      "2 distribution\n",
      "2 black-box adversarial attack\n",
      "2 panoptic segmentation\n",
      "2 cnns\n",
      "2 high-resolution\n",
      "2 3d-aware image synthesis\n",
      "2 predictor\n",
      "2 implicit neural representation\n",
      "2 coordinate-based representations\n",
      "2 data compression\n",
      "2 brier score\n",
      "2 curse of dimensionality\n",
      "2 neural network quantization\n",
      "2 trace estimation\n",
      "2 structured pruning\n",
      "2 minimax optimization\n",
      "2 latent confounders\n",
      "2 knowledge graph completion\n",
      "2 granger causality\n",
      "2 annealed importance sampling\n",
      "2 hyperbolic embedding\n",
      "2 automatic speech recognition\n",
      "2 post-processing\n",
      "2 confidence calibration\n",
      "2 computational efficiency\n",
      "2 memory efficiency\n",
      "2 scene understanding\n",
      "2 symbolic regression\n",
      "2 recurrent networks\n",
      "2 acquisition function\n",
      "2 cvar\n",
      "2 reward learning\n",
      "2 missing values\n",
      "2 distribution testing\n",
      "2 pomdps\n",
      "2 online planning\n",
      "2 voice conversion\n",
      "2 style transfer\n",
      "2 matching\n",
      "2 implicit models\n",
      "2 peer review\n",
      "2 kernel approximation\n",
      "2 efficient transformers\n",
      "2 spectral analysis\n",
      "2 object-centric representation learning\n",
      "2 biology\n",
      "2 biologically plausible\n",
      "2 credit assignment\n",
      "2 differentiable programming\n",
      "2 non-decomposable objectives\n",
      "2 constraints\n",
      "2 representation learning theory\n",
      "2 vehicle routing\n",
      "2 decomposition\n",
      "2 sensitivity\n",
      "2 hypergraph clustering\n",
      "2 score-based generative models\n",
      "2 disentangled representation\n",
      "2 unsupervised exploration\n",
      "2 robust reinforcement learning\n",
      "2 data-driven\n",
      "2 markov decision processes\n",
      "2 utility\n",
      "2 pac-bayesian bounds\n",
      "2 poisoning attacks\n",
      "2 salient object detection\n",
      "2 semi-supervised node classification\n",
      "2 ridge regression\n",
      "2 personalized federated learning\n",
      "2 submodularity\n",
      "2 redundancy\n",
      "2 robust\n",
      "2 posterior sampling\n",
      "2 dual-stream\n",
      "2 partial domain adaptation\n",
      "2 transductive learning\n",
      "2 conditional gradient\n",
      "2 quantum computing\n",
      "2 surrogate gradients\n",
      "2 prior\n",
      "2 mixture model\n",
      "2 blind source separation\n",
      "2 unsupervised representation learning\n",
      "2 saddle points\n",
      "2 conditional gan\n",
      "2 classifier\n",
      "2 data efficiency\n",
      "2 cycle consistency\n",
      "2 feature suppression\n",
      "2 deep kernel methods\n",
      "2 representation similarity\n",
      "2 neural network verification\n",
      "2 survival analysis\n",
      "2 convolutional networks\n",
      "2 partially observable\n",
      "2 navigation\n",
      "2 model-based optimization\n",
      "2 weakly convex optimization\n",
      "2 adversarial detection\n",
      "2 verification\n",
      "2 spurious correlations\n",
      "2 image priors\n",
      "2 commonsense reasoning\n",
      "2 identification\n",
      "2 random neural networks\n",
      "2 double/debiased machine learning\n",
      "2 localization\n",
      "2 sco\n",
      "2 minimax\n",
      "2 point cloud registration\n",
      "2 stochasticity\n",
      "2 antithetic\n",
      "2 machine unlearning\n",
      "2 goal-conditioned rl\n",
      "2 continuous normalizing flows\n",
      "2 social choice\n",
      "2 voting\n",
      "2 principal component analysis\n",
      "2 dynamic sparse training\n",
      "2 minimax regret\n",
      "2 kernel\n",
      "2 error feedback\n",
      "2 dataset shift\n",
      "2 trustworthy ai\n",
      "2 adaptive experiments\n",
      "2 likelihood-free inference\n",
      "2 time-series\n",
      "2 human motion prediction\n",
      "2 signal processing\n",
      "2 linear convergence\n",
      "2 neural module networks\n",
      "2 3d deep learning\n",
      "2 backdoor attacks\n",
      "2 adaptation\n",
      "2 high-dimensional\n",
      "2 treatment effects\n",
      "2 differentiable physics\n",
      "2 distributional shift\n",
      "2 first-order optimization\n",
      "2 convergence\n",
      "2 nesterov acceleration\n",
      "2 submodular optimization\n",
      "2 data heterogeneity\n",
      "2 feedback graphs\n",
      "2 risk-sensitivity\n",
      "2 physics simulation\n",
      "2 stochastic differential equation\n",
      "2 language models\n",
      "2 synthetic control\n",
      "2 central limit theorem\n",
      "2 cramer-rao lower bound\n",
      "2 community detection\n",
      "2 social network\n",
      "2 tensor\n",
      "2 topology optimization\n",
      "2 multilayer perceptrons\n",
      "2 lie group\n",
      "2 correlation clustering\n",
      "2 representations\n",
      "2 over-smoothing\n",
      "2 node classification\n",
      "2 human evaluation\n",
      "2 markov games\n",
      "2 tensor networks\n",
      "2 vc dimension\n",
      "2 posterior distribution\n",
      "2 individual fairness\n",
      "2 quadratic optimization\n",
      "2 first-order methods\n",
      "2 learning-augmented algorithms\n",
      "2 novel view synthesis\n",
      "2 linear contextual bandits\n",
      "2 label differential privacy\n",
      "2 contrastive loss\n",
      "2 proteins\n",
      "2 graph-neural networks\n",
      "2 cca\n",
      "2 efficient inference\n",
      "2 convolutions\n",
      "2 video recognition\n",
      "2 zero-shot coordination\n",
      "2 property elicitation\n",
      "2 lossy compression\n",
      "2 amortization\n",
      "2 pomdp\n",
      "2 probably approximately correct\n",
      "2 indexed minimum empirical divergence\n",
      "2 imperfect information\n",
      "2 gromov-wasserstein\n",
      "2 state-space models\n",
      "2 distributed algorithms\n",
      "2 deep active learning\n",
      "2 shapley values\n",
      "2 optimism\n",
      "2 pinball loss\n",
      "2 vision and language\n",
      "2 multi-modal learning\n",
      "2 gaussian process bandit\n",
      "2 end-to-end\n",
      "2 sequential algorithms\n",
      "2 diverse policies\n",
      "2 tractable inference\n",
      "2 sum-product networks\n",
      "2 spectral theory\n",
      "2 intrinsic dimension\n",
      "2 markov chains\n",
      "2 prediction\n",
      "2 controllable text generation\n",
      "2 adaptive control\n",
      "2 deep equilibrium model\n",
      "2 neural network training\n",
      "2 speech\n",
      "2 selective classification\n",
      "2 value equivalence\n",
      "2 machine learning theory\n",
      "2 generalization guarantees\n",
      "2 price of anarchy\n",
      "2 fair division\n",
      "2 self-organization\n",
      "2 distribution matching\n",
      "2 fusion\n",
      "2 discrete-continuous learning\n",
      "2 stochastic computation graphs\n",
      "2 bayesian optimisation\n",
      "2 structural causal model\n",
      "2 decoder\n",
      "2 representation\n",
      "2 alternating minimization\n",
      "2 bipartite matching\n",
      "2 random graphs\n",
      "2 mixture of experts\n",
      "2 maxsat\n",
      "2 manifolds\n",
      "2 random features\n",
      "2 variational auto-encoders\n",
      "2 optimization for deep networks\n",
      "2 random projections\n",
      "2 composite optimization\n",
      "2 manipulation\n",
      "2 distributional shifts\n",
      "2 imputation\n",
      "2 partial observability\n",
      "2 reward shaping\n",
      "2 motion processing\n",
      "2 visual perception\n",
      "2 polyak-ruppert averaging\n",
      "2 softmax\n",
      "2 deep ensemble\n",
      "2 task-agnostic\n",
      "2 self-training\n",
      "2 shapley value\n",
      "2 optimization theory\n",
      "2 neural dynamics\n",
      "2 differentiable learning\n",
      "2 predict-then-optimize\n",
      "2 differentiable optimization\n",
      "2 language modelling\n",
      "2 natural corruptions\n",
      "2 learning algorithms\n",
      "2 transfer\n",
      "2 alignment\n",
      "2 large-scale\n",
      "2 latent variables\n",
      "2 smoothness\n",
      "2 teacher-student\n",
      "2 fisher information\n",
      "2 deep gaussian processes\n",
      "2 medical imaging\n",
      "2 conditional value-at-risk\n",
      "2 ucb\n",
      "2 nngp\n",
      "2 time-series forecasting\n",
      "2 classification.\n",
      "2 trade-off\n",
      "2 gradient inversion\n",
      "2 backdoor defense\n",
      "2 trustworthy machine learning\n",
      "2 excess risk\n",
      "2 least squares\n",
      "2 finite-sample analysis\n",
      "2 point cloud\n",
      "2 forecasting\n",
      "2 stochastic linear bandits\n",
      "2 random walks\n",
      "2 mpc\n",
      "2 cusum\n",
      "2 nonlinear optimization\n",
      "2 phase retrieval\n",
      "2 approximate message passing\n",
      "2 admm\n",
      "2 nonparametric inference\n",
      "2 genomics\n",
      "2 nash welfare\n",
      "2 image compression\n",
      "2 random matrix theory\n",
      "2 dense correspondence\n",
      "2 heterogeneous treatment effects\n",
      "2 counterfactual estimation\n",
      "2 list-decodable learning\n",
      "2 similarity\n",
      "2 graph laplacian\n",
      "2 diffusion probabilistic models\n",
      "2 feature\n",
      "2 distribution learning\n",
      "2 sequence-to-sequence\n",
      "2 homophily\n",
      "2 quantum chemistry\n",
      "2 partial differential equation\n",
      "2 low-rank methods\n",
      "2 video compression\n",
      "2 stackelberg equilibrium\n",
      "2 visual cortex\n",
      "2 mean estimation\n",
      "2 gwas\n",
      "2 high dimension\n",
      "2 disentangled representation learning\n",
      "2 equivariant\n",
      "2 invariant\n",
      "2 tabular\n",
      "2 learning invariants\n",
      "2 class-incremental learning\n",
      "2 image manipulation\n",
      "2 exploration-exploitation\n",
      "2 scrna-seq\n",
      "2 rule-based model\n",
      "2 pca\n",
      "2 few-shot object detection\n",
      "2 discrimination\n",
      "2 mallows model\n",
      "2 fair machine learning\n",
      "2 dueling\n",
      "2 preference\n",
      "2 optimal\n",
      "2 proximal policy optimization\n",
      "2 regime switching\n",
      "2 spectral method\n",
      "2 riemannian manifold\n",
      "2 bures-wasserstein\n",
      "2 model evaluation\n",
      "2 sample selection\n",
      "2 optimistic algorithms\n",
      "2 no-regret learning\n",
      "2 subgradient\n",
      "2 controllable generation\n",
      "2 ensemble method\n",
      "2 meta-learning theory\n",
      "2 treatment effect\n",
      "2 adaptively collected data\n",
      "2 combinatorial bandits\n",
      "2 cognitive neuroscience\n",
      "2 randomized numerical linear algebra\n",
      "2 tensor decompositions\n",
      "2 minimax optimality\n",
      "2 outlier detection\n",
      "2 weakly supervised\n",
      "2 batch rl\n",
      "2 bioinformatics\n",
      "2 multi-head attention\n",
      "2 neural sampling\n",
      "2 corruption robustness\n",
      "2 perceptual similarity\n",
      "2 zero-shot generalization\n",
      "2 weak-shot learning\n",
      "2 learning to hash\n",
      "2 covid-19\n",
      "2 uncertainty learning\n",
      "2 ordinary differential equation\n",
      "2 auxiliary learning\n",
      "2 optimal regret\n",
      "2 image-to-image translation\n",
      "2 episodic memory\n",
      "2 overparametrization\n",
      "2 low-rank matrix optimization\n",
      "2 computational photography\n",
      "2 kernel method\n",
      "2 theory of deep learning\n",
      "2 maximum likelihood\n",
      "2 value iteration\n",
      "2 input-convex neural networks\n",
      "2 dictionary learning\n",
      "2 adjoint method\n",
      "2 entropy\n",
      "2 secure multi-party computation\n",
      "2 super resolution\n",
      "2 symmetry breaking\n",
      "2 stackelberg game\n",
      "2 counterfactual inference\n",
      "2 information theory.\n",
      "1 saddle point problem\n",
      "1 data similarity\n",
      "1 normalization\n",
      "1 time-varying networks\n",
      "1 adom\n",
      "1 optimal algorithms\n",
      "1 multi-task linear regression\n",
      "1 hierarchical bayesian learning\n",
      "1 type-ii maximum-likelihood inference\n",
      "1 toeplitz\n",
      "1 circulant embedding\n",
      "1 sparse bayesian learning\n",
      "1 sparse regression\n",
      "1 sparse denoising\n",
      "1 eeg/meg\n",
      "1 brain source imaging\n",
      "1 restricted boltzmann machine\n",
      "1 out of equilibrium\n",
      "1 monte carlo mixing time\n",
      "1 energy based model\n",
      "1 disordered systems\n",
      "1 streaming object detection\n",
      "1 lidar segmentation\n",
      "1 3d panoptic segmentation\n",
      "1 polar grid\n",
      "1 species classification\n",
      "1 fine-grained classification\n",
      "1 insects\n",
      "1 poincare embedding\n",
      "1 partial dependence plots\n",
      "1 rationales\n",
      "1 federated\n",
      "1 recall\n",
      "1 learning rule\n",
      "1 key-value network\n",
      "1 nonlinear bandit\n",
      "1 algebraic variety\n",
      "1 part segmentation\n",
      "1 outlier exposure\n",
      "1 coordinate-based\n",
      "1 implicit function\n",
      "1 cross-modal\n",
      "1 cortical microcircuits\n",
      "1 prospective coding\n",
      "1 optimality\n",
      "1 wavelet\n",
      "1 cosmology\n",
      "1 cell biology\n",
      "1 contaminated stochastic bandits\n",
      "1 multilevel monte carlo\n",
      "1 bias variance and cost tradeoff\n",
      "1 focal attention\n",
      "1 long-range interactions\n",
      "1 local-global interactions\n",
      "1 inductive biases\n",
      "1 cooperative bandit\n",
      "1 imperfect communication\n",
      "1 cost\n",
      "1 budgeted\n",
      "1 saliency estimation\n",
      "1 data transformations\n",
      "1 model invariance\n",
      "1 covering number\n",
      "1 model complexity\n",
      "1 non-parametric kernels\n",
      "1 kernel learning\n",
      "1 bayesian functional optimisation\n",
      "1 hyperkernels\n",
      "1 black-box optimisation\n",
      "1 sample-efficient optimisation\n",
      "1 pac-bayesian analysis\n",
      "1 composite\n",
      "1 nested\n",
      "1 grey\n",
      "1 box\n",
      "1 cognition\n",
      "1 interpretable ai\n",
      "1 human visual perception\n",
      "1 bnns\n",
      "1 vi\n",
      "1 underfitting\n",
      "1 collapsed elbo\n",
      "1 overpruning\n",
      "1 gradient compression\n",
      "1 multilingual nlp\n",
      "1 open-domain qa\n",
      "1 cross-lingual information retrieval\n",
      "1 nonconvex-strongly-concave\n",
      "1 nonconvex-pl\n",
      "1 sets\n",
      "1 non-euclidean\n",
      "1 semantic parsing\n",
      "1 random matrices\n",
      "1 fast adversarial training\n",
      "1 single-step adversarial training\n",
      "1 view synthesis\n",
      "1 decentralized stochastic optimization\n",
      "1 gradient tracking\n",
      "1 non-iid data\n",
      "1 transduction\n",
      "1 vertex classification\n",
      "1 convexity theory\n",
      "1 shortest paths\n",
      "1 subgraph mining\n",
      "1 semi supervised domain adaption\n",
      "1 meta reinforcement learning\n",
      "1 hindsight\n",
      "1 adaptive residual\n",
      "1 abnormal features\n",
      "1 conformal\n",
      "1 visual imitation learning\n",
      "1 tensor factorization\n",
      "1 finite sample analysis\n",
      "1 average-reward reinforcement learning\n",
      "1 td learning with linear function approximation\n",
      "1 asymptotics\n",
      "1 co-design\n",
      "1 soft robotics\n",
      "1 evolutionary algorithms\n",
      "1 sparse distributed memory\n",
      "1 cerebellum\n",
      "1 iterative machine teaching\n",
      "1 label\n",
      "1 music\n",
      "1 piano transcrition\n",
      "1 music transcription\n",
      "1 semi-markov\n",
      "1 sound event detection\n",
      "1 music information retrieval\n",
      "1 pac-learning\n",
      "1 iterative\n",
      "1 latent variables models\n",
      "1 schrodinger bridge\n",
      "1 trainability\n",
      "1 constraint\n",
      "1 narrow\n",
      "1 expert demonstrations\n",
      "1 directed acyclic graphs\n",
      "1 continuous optimization\n",
      "1 rank\n",
      "1 degeneracy\n",
      "1 singularity\n",
      "1 copulas\n",
      "1 implicit generative models\n",
      "1 distributed online learning\n",
      "1 information-theoretic generalization\n",
      "1 conditional mutual information\n",
      "1 leave-one-out\n",
      "1 sample compression schemes\n",
      "1 dynamic reconstruction\n",
      "1 implicit network\n",
      "1 association measure\n",
      "1 heteroscedasticity\n",
      "1 nonfunctional dependence\n",
      "1 graph aggregation network\n",
      "1 text-to-sql\n",
      "1 efficient numerical methods\n",
      "1 matrix-free algorithms\n",
      "1 functional variational inference\n",
      "1 reverse model-based imagination\n",
      "1 emergence of language\n",
      "1 group communication\n",
      "1 communication graph\n",
      "1 graph optimization\n",
      "1 almost sure\n",
      "1 convergence rates\n",
      "1 row stochastic\n",
      "1 gossip\n",
      "1 law of iterated logarithm\n",
      "1 concentration\n",
      "1 combinatorial semi-bandit\n",
      "1 linear bandit\n",
      "1 data-dependent regret bound\n",
      "1 compositional optimization\n",
      "1 program generation\n",
      "1 neurosymbolic learning\n",
      "1 attribute grammars\n",
      "1 quantum kernels\n",
      "1 inter-experimental variability\n",
      "1 cell type classification\n",
      "1 retina\n",
      "1 autoencoder\n",
      "1 adversarial optimization\n",
      "1 humans\n",
      "1 robustness transfer\n",
      "1 robust pre-training\n",
      "1 recursive neural network\n",
      "1 online tracking\n",
      "1 concept drift\n",
      "1 ood generalizationm\n",
      "1 chinese restaurant process\n",
      "1 relational model\n",
      "1 few-shot\n",
      "1 prompt-based models\n",
      "1 statistical analysis\n",
      "1 sparse gradients\n",
      "1 activation sharing\n",
      "1 weight transport problem\n",
      "1 bidirectional connection\n",
      "1 biologically plausible algorithms\n",
      "1 neuromorphic algorithms\n",
      "1 deep convolutional neural network\n",
      "1 biological neural network\n",
      "1 sequential prediction\n",
      "1 gaussian cox processes\n",
      "1 point processes\n",
      "1 path integral\n",
      "1 cognitive psychology\n",
      "1 common sense\n",
      "1 cognitive development\n",
      "1 intuitive psychology\n",
      "1 multivariate analysis\n",
      "1 independence test\n",
      "1 correlated data\n",
      "1 neuro_ai\n",
      "1 rodent visual cortex\n",
      "1 mouse brains\n",
      "1 optical physiology\n",
      "1 local minima\n",
      "1 residual networks\n",
      "1 densely connected networks\n",
      "1 nonlinear estimation\n",
      "1 margin maximization\n",
      "1 linearly separable\n",
      "1 two-layer neural networks\n",
      "1 reproducible kernel hilbert space\n",
      "1 scaling law\n",
      "1 infinite-width neural networks\n",
      "1 multi-agent exploration\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 episodic control\n",
      "1 simulator\n",
      "1 3d convolution\n",
      "1 se(3)-equivariant feature learning\n",
      "1 physics-informed neural networks\n",
      "1 unconstrained optimization\n",
      "1 distributed and parallel algorithms\n",
      "1 synthetic data generation\n",
      "1 label consistency\n",
      "1 manifold clustering\n",
      "1 batch normormalization\n",
      "1 multi-dimensional spatial tasks\n",
      "1 widget captioning\n",
      "1 ui modeling\n",
      "1 neverending learning\n",
      "1 lifelong learning\n",
      "1 plasticity-stability dilemma\n",
      "1 task incremental learning\n",
      "1 dynamic architectures\n",
      "1 model growing\n",
      "1 non-lipschitz\n",
      "1 synthetic gradient\n",
      "1 multiple-source domain adaptation\n",
      "1 communication-efficient mean estimation\n",
      "1 vector sparsification\n",
      "1 high dimensionality\n",
      "1 discrete data\n",
      "1 goal reaching\n",
      "1 data pre-processing\n",
      "1 label noise rate balancing\n",
      "1 multiple object tracking and segmentation\n",
      "1 efficient cross-attention networks\n",
      "1 space-time memory\n",
      "1 medial entorhinal cortex\n",
      "1 grid cells\n",
      "1 biologically-inspired navigation\n",
      "1 truncated statistics\n",
      "1 invariance principle\n",
      "1 robotics and control\n",
      "1 n:m\n",
      "1 structured sparsity\n",
      "1 boredom\n",
      "1 satiation\n",
      "1 coordinated influence campaigns\n",
      "1 disinformation\n",
      "1 fake news\n",
      "1 hyperspectral denoising\n",
      "1 trainable sparse coding models for image denoising\n",
      "1 material estimation\n",
      "1 lighting estimation\n",
      "1 spatio-temporal analysis\n",
      "1 pseudo-riemannian manifolds\n",
      "1 elliptic geometry\n",
      "1 ultrahyperbolic geometry\n",
      "1 optimization on manifolds\n",
      "1 pseudo-riemannian optimization\n",
      "1 quotient manifolds\n",
      "1 debiased\n",
      "1 bias detection\n",
      "1 online (stochastic) gradient descent\n",
      "1 stability and generalization\n",
      "1 wasserstein gradient flows\n",
      "1 learning under noise\n",
      "1 interactive learning\n",
      "1 example-based explanation\n",
      "1 influence functions\n",
      "1 markov decision problem\n",
      "1 stein path\n",
      "1 decision problems\n",
      "1 wl\n",
      "1 molecular graphs\n",
      "1 diagonal neural networks\n",
      "1 sde\n",
      "1 black-box adversarial attacks\n",
      "1 3d single object tracking\n",
      "1 hamiltonian neural networks\n",
      "1 hamiltonian mechanics\n",
      "1 symplectic geometry\n",
      "1 flatness\n",
      "1 deep neural network pruning\n",
      "1 dense/sparse co-training\n",
      "1 iterative hard thresholding\n",
      "1 adversarial defenses\n",
      "1 motion prediction\n",
      "1 multi-person interaction\n",
      "1 lightweight architecture\n",
      "1 non-autoregressive\n",
      "1 unpaired data\n",
      "1 mean field regime\n",
      "1 langevin algorithm\n",
      "1 bernstein polynomial approximation\n",
      "1 arbitrary spectral filters\n",
      "1 non-iid graphs\n",
      "1 structure heterogeneity\n",
      "1 feature heterogeneity\n",
      "1 overinterpretation\n",
      "1 test-time personalization\n",
      "1 gradient-free optimization\n",
      "1 evolutionary strategies\n",
      "1 randomized methods\n",
      "1 quantile regret\n",
      "1 semi-adversarial\n",
      "1 adaptive online learning\n",
      "1 f-divergence\n",
      "1 aggregation\n",
      "1 generalized bayes\n",
      "1 online variational inference\n",
      "1 delusive attacks\n",
      "1 kronecker product\n",
      "1 compact models\n",
      "1 constraint-based structure learning\n",
      "1 causal graph\n",
      "1 ancestral graph learning\n",
      "1 foreground extraction\n",
      "1 risk-sensitive reinforcement learning\n",
      "1 adaptive gradient methods\n",
      "1 universal framework\n",
      "1 subgraph node classification\n",
      "1 neighbor prediction\n",
      "1 video recogniton\n",
      "1 temporal covariance pooling\n",
      "1 temporal-based attention\n",
      "1 optimization for deep linear networks\n",
      "1 global directional convergence\n",
      "1 superlinear convergence\n",
      "1 local convergence\n",
      "1 convex optimziation\n",
      "1 multiagent\n",
      "1 latent policy\n",
      "1 second-order optimization\n",
      "1 continuous-time optimal control\n",
      "1 exact score-based method\n",
      "1 weaker assumptions\n",
      "1 gauge independence\n",
      "1 latent state-space models\n",
      "1 parallelizable algorithms\n",
      "1 adaptive complexity\n",
      "1 noether's theorem\n",
      "1 modified equation analysis\n",
      "1 conservation law\n",
      "1 acceleration/momentum\n",
      "1 instance weighting\n",
      "1 chain rule\n",
      "1 precision-recall\n",
      "1 divergence frontiers\n",
      "1 probability theory\n",
      "1 conditionally specified distributions\n",
      "1 multi agent reinforcement learning\n",
      "1 power distribution network\n",
      "1 active voltage control\n",
      "1 compositionality in language\n",
      "1 meta-linguistics\n",
      "1 systematicity\n",
      "1 spike\n",
      "1 population activity\n",
      "1 count\n",
      "1 bayesian autoencoders\n",
      "1 high dimensional statistics\n",
      "1 structural equation models\n",
      "1 latent variable modeling\n",
      "1 logic rules\n",
      "1 open rules\n",
      "1 financial markets\n",
      "1 precision matrix\n",
      "1 machine learning for code\n",
      "1 code summarization\n",
      "1 autencoders\n",
      "1 max-product\n",
      "1 discrete graphical models\n",
      "1 belief revision\n",
      "1 belief propagation\n",
      "1 label-noise learning\n",
      "1 structural causal models\n",
      "1 casual inference\n",
      "1 continuous treatments\n",
      "1 multi-scale change point detection\n",
      "1 precision medicine\n",
      "1 attack\n",
      "1 sparse neural network\n",
      "1 sample complexity analysis\n",
      "1 generalized linear bandits\n",
      "1 logistic bandits\n",
      "1 multinomial logit (mnl)\n",
      "1 deep image matching\n",
      "1 person re-identification\n",
      "1 generalizable person re-identification\n",
      "1 distributed mean estimation\n",
      "1 distributed leaning\n",
      "1 communication efficiency\n",
      "1 bandwidth reduction\n",
      "1 statistical mechanics\n",
      "1 mean field theory\n",
      "1 finite dnns\n",
      "1 min-max\n",
      "1 fisher market\n",
      "1 competitive equilibrium\n",
      "1 concentration for products of random matrices\n",
      "1 bernstein-type bounds for linear stochastic approximation\n",
      "1 fine-grained analysis of linear stochastic approximation\n",
      "1 non-asymptotic analysis of linear stochastic approximation\n",
      "1 time-dependent resource\n",
      "1 maximin share\n",
      "1 envy-freeness\n",
      "1 variability\n",
      "1 space of solutions\n",
      "1 task optimized networks\n",
      "1 incremental few-shot learning\n",
      "1 flat minima\n",
      "1 noisy image classification\n",
      "1 python package\n",
      "1 temporal receptive field\n",
      "1 motion-aware\n",
      "1 attributions\n",
      "1 attribution priors\n",
      "1 learning from label proportions\n",
      "1 linear thresholds\n",
      "1 probability path\n",
      "1 bayesian time series modeling\n",
      "1 evolving prediction\n",
      "1 degradation prediction\n",
      "1 neural variation inference\n",
      "1 deep sparse network\n",
      "1 mini-batch consistency\n",
      "1 set encoding\n",
      "1 ood generalization\n",
      "1 local image editing\n",
      "1 hierarchical bayesian modeling\n",
      "1 exchangeability\n",
      "1 frequentist properties\n",
      "1 language learning\n",
      "1 visual relational reasoning\n",
      "1 cross-modal contrastive learning\n",
      "1 grounded cognition\n",
      "1 representational similarity\n",
      "1 class separation\n",
      "1 training objectives\n",
      "1 label smoothing\n",
      "1 centered kernel alignment\n",
      "1 lossless graph compression\n",
      "1 neural compression\n",
      "1 infinite-depth-and-width\n",
      "1 log-gaussian\n",
      "1 hypoactivation\n",
      "1 balanced resnet\n",
      "1 kalman filter\n",
      "1 neural circuit\n",
      "1 medical deadends\n",
      "1 treatment security\n",
      "1 sepsis\n",
      "1 probability of causation\n",
      "1 class incremental semantic segmentation\n",
      "1 unknown class\n",
      "1 tiny memory\n",
      "1 neural volume rendering\n",
      "1 fitted q-iteration\n",
      "1 rotated object detection\n",
      "1 high-precision\n",
      "1 kullback-leibler divergence\n",
      "1 weight space\n",
      "1 parameter space\n",
      "1 model zoos\n",
      "1 behavioral stylometry\n",
      "1 player identification\n",
      "1 data distribution shift\n",
      "1 flatness minimization\n",
      "1 sharpness minimization\n",
      "1 grid cell\n",
      "1 place cell\n",
      "1 recurrent network\n",
      "1 matrix lie group\n",
      "1 knowledge graph embedding\n",
      "1 transitivity\n",
      "1 relation pattern\n",
      "1 multivariate skew laplace\n",
      "1 network stability\n",
      "1 domain invariant representation\n",
      "1 programmatic reinforcement learning\n",
      "1 combinatorial actions\n",
      "1 slate bandits\n",
      "1 variational dropout\n",
      "1 structured approximate inference\n",
      "1 probabilistic context-free grammars\n",
      "1 parsing\n",
      "1 mixed discrete-continuous\n",
      "1 tree induction\n",
      "1 hyperparameter-free\n",
      "1 three operator splitting\n",
      "1 adaptive step-size\n",
      "1 stress test\n",
      "1 second-order geometry\n",
      "1 sparse representation\n",
      "1 feature importance\n",
      "1 social alignment\n",
      "1 search methods\n",
      "1 salience methods\n",
      "1 neural radiance field\n",
      "1 sdf\n",
      "1 human reconstruction\n",
      "1 whole slide image\n",
      "1 weakly supervised classification\n",
      "1 multiple instance learning\n",
      "1 indoor localization\n",
      "1 deep decomposition model\n",
      "1 auto-correlation\n",
      "1 bayesian rule\n",
      "1 ranking loss of self-attention\n",
      "1 mixed-precision\n",
      "1 generative\n",
      "1 energy consumption\n",
      "1 laplacian eigenmaps\n",
      "1 wassertein distance\n",
      "1 kantorovich-rubinstein duality\n",
      "1 block-contrastive\n",
      "1 geometric mean\n",
      "1 adder neural networks\n",
      "1 binary neural network\n",
      "1 frequency domain approximation\n",
      "1 fourier series\n",
      "1 noise\n",
      "1 scene classification\n",
      "1 convolution neural networks\n",
      "1 local lipschitz constant\n",
      "1 causal confusion\n",
      "1 compression coding\n",
      "1 feature interpretation\n",
      "1 open-ended generation\n",
      "1 neural text generation\n",
      "1 divergence frontier\n",
      "1 human judgement\n",
      "1 synchronous grammars\n",
      "1 architectural inductive bias\n",
      "1 algorithmic alignment\n",
      "1 online control\n",
      "1 linear time-varying systems\n",
      "1 multi-person pose estimation\n",
      "1 crowded scenes pose estimation\n",
      "1 derivative-free optimization\n",
      "1 private erm\n",
      "1 per-instance privacy\n",
      "1 objective perturbation\n",
      "1 social media regulation\n",
      "1 audit\n",
      "1 algorithmic filtering\n",
      "1 performance-regulation trade-off\n",
      "1 performance cost\n",
      "1 content diversity\n",
      "1 minimum-variance unbiased estimator\n",
      "1 fairwashing\n",
      "1 post-hoc explanation\n",
      "1 dual-system\n",
      "1 coherence\n",
      "1 dual-process\n",
      "1 algorithmic recourse\n",
      "1 structured bandits\n",
      "1 topological relational learning\n",
      "1 persistence based graph representation\n",
      "1 robust graph learning\n",
      "1 generative learning\n",
      "1 sinkhorn divergence\n",
      "1 language\n",
      "1 qualification rate disparity\n",
      "1 replicator dynamics\n",
      "1 feedback control\n",
      "1 cdf\n",
      "1 ope\n",
      "1 high-confidence bounds\n",
      "1 noisy reward\n",
      "1 imperfect demonstration\n",
      "1 co-training\n",
      "1 pretrained models\n",
      "1 hard-label attack\n",
      "1 geometric-based attack\n",
      "1 tangent point\n",
      "1 tangent line\n",
      "1 hopskipjumpattack\n",
      "1 foreground and background\n",
      "1 shortcut learning\n",
      "1 end-to-end learning\n",
      "1 fully differentiable\n",
      "1 structured outputs\n",
      "1 extrapolation error\n",
      "1 generative radiance fields\n",
      "1 gibbs distribution\n",
      "1 partition functions\n",
      "1 self-evolution\n",
      "1 reward functions\n",
      "1 reward\n",
      "1 reward hypothesis\n",
      "1 proper scoring rules\n",
      "1 diverse behaviors\n",
      "1 partial parameter sharing\n",
      "1 auto-curricula\n",
      "1 large neighborhood search\n",
      "1 convergence rate\n",
      "1 embedding principle\n",
      "1 critical points\n",
      "1 degree of degeneracy\n",
      "1 scientific progress\n",
      "1 multi-view representation learning\n",
      "1 multimodal generative models\n",
      "1 minimax problems\n",
      "1 nonconvex-nonconcave problems\n",
      "1 extragradient method\n",
      "1 backdoor attack\n",
      "1 behavioral disparity\n",
      "1 sketching algorithms\n",
      "1 vector quantization\n",
      "1 group sparsity\n",
      "1 operator learning\n",
      "1 galerkin methods\n",
      "1 graph contrastive learning\n",
      "1 self-supervised graph representation learning\n",
      "1 model adaptation\n",
      "1 detection\n",
      "1 nonsmooth\n",
      "1 robust neural network training\n",
      "1 audio generation\n",
      "1 single example\n",
      "1 raw waveform\n",
      "1 bandwidth extension\n",
      "1 audio inpainting\n",
      "1 audio denoising\n",
      "1 music generation\n",
      "1 linear classification\n",
      "1 heavy hitters\n",
      "1 kernel classification\n",
      "1 episode sampling\n",
      "1 pairwise\n",
      "1 intransitive\n",
      "1 graph representation\n",
      "1 ogb-lsc\n",
      "1 multiple descent\n",
      "1 adversarial data\n",
      "1 causal effect identification\n",
      "1 maximal ancestral graph\n",
      "1 hawkes process\n",
      "1 minorization-maximization\n",
      "1 cardinality\n",
      "1 temporal events\n",
      "1 bayesian online learning\n",
      "1 change detection\n",
      "1 non-stationary continual learning\n",
      "1 gaussian space\n",
      "1 probabilistic embeddings\n",
      "1 query reasoning\n",
      "1 pu learning\n",
      "1 mixture proportion estimation\n",
      "1 hierarchical reasoning\n",
      "1 speech separation\n",
      "1 single-channel\n",
      "1 time-domain\n",
      "1 recurrent convolutional neural network\n",
      "1 mcts\n",
      "1 sample-efficient\n",
      "1 cross-modal matching\n",
      "1 mismatching\n",
      "1 error correction\n",
      "1 non-autoregressive model\n",
      "1 edit alignment\n",
      "1 diachronic word representation\n",
      "1 word vectors\n",
      "1 temporal analogy\n",
      "1 support recovery\n",
      "1 mixtures of linear regressions\n",
      "1 mixtures of linear classifiers\n",
      "1 low rank tensor decomposition\n",
      "1 byzantine-tolerant optimization\n",
      "1 path sampling\n",
      "1 scheduling\n",
      "1 stochastic holding costs\n",
      "1 scheduling while learning\n",
      "1 $c\\mu$ rule\n",
      "1 empirical $c\\mu$ rule\n",
      "1 dag\n",
      "1 distributed reinforcement learning\n",
      "1 dataflow programming model\n",
      "1 non co-occurrence\n",
      "1 algebraic multigrid\n",
      "1 graph partitioning\n",
      "1 tractablity\n",
      "1 probabilistic programming\n",
      "1 object pose estimation\n",
      "1 hand object interaction\n",
      "1 object segmentation\n",
      "1 embeddings\n",
      "1 genetic programming\n",
      "1 neural-guided search\n",
      "1 nonparametric bayesian model selection\n",
      "1 stochastic variational inference\n",
      "1 over-parametrization\n",
      "1 isoperimetry\n",
      "1 deep reinforcement learing\n",
      "1 explainable deep reinforcement learing\n",
      "1 policy debugging\n",
      "1 prefix sums\n",
      "1 mazes\n",
      "1 cyber-physical system\n",
      "1 projected gradient descent\n",
      "1 batched multi-armed bandits\n",
      "1 var\n",
      "1 tail-risk\n",
      "1 heavy-tailed distributions\n",
      "1 irl\n",
      "1 inverse decision theory\n",
      "1 idt\n",
      "1 preference elicitation\n",
      "1 unlabeled sensing\n",
      "1 linear regression without correspondences\n",
      "1 robust principal component analysis\n",
      "1 algebraic geometry\n",
      "1 mean field limit\n",
      "1 finite-width correction\n",
      "1 fluctuation\n",
      "1 open-set noisy labels\n",
      "1 neural architecture search (nas)\n",
      "1 one-shot nas\n",
      "1 zero-shot nas\n",
      "1 bayes optimality\n",
      "1 deep implicit models\n",
      "1 multiple imputation\n",
      "1 knowledge compilation\n",
      "1 decision under uncertainty\n",
      "1 image search\n",
      "1 landmark retrieval\n",
      "1 query expansion\n",
      "1 representational learning\n",
      "1 shifted self-attention\n",
      "1 contrastive examples\n",
      "1 sequence optimization\n",
      "1 combinatorial construction\n",
      "1 sequential assembly\n",
      "1 generalized linear model\n",
      "1 random matrix theory.\n",
      "1 hard-attention\n",
      "1 multi-scale\n",
      "1 capsules\n",
      "1 primary capsules\n",
      "1 3d point clouds\n",
      "1 sample and class representation distillation\n",
      "1 privileged experts\n",
      "1 neural scene representations\n",
      "1 neural implicit representations\n",
      "1 light fields\n",
      "1 neural variability\n",
      "1 neural correlations\n",
      "1 discrete distributions\n",
      "1 latent variable modelling\n",
      "1 auxiliary balanced classifier\n",
      "1 class-imbalanced semi-supervised learning\n",
      "1 adversarial transferability\n",
      "1 probabilistic database\n",
      "1 logic reasoning\n",
      "1 neural symbolic\n",
      "1 constrained learning\n",
      "1 semi-infinite programming\n",
      "1 nonnegative\n",
      "1 brain\n",
      "1 auto-segmentation\n",
      "1 off-the-shelf-features\n",
      "1 shape-modeling\n",
      "1 resolvent method\n",
      "1 cumulant expansion\n",
      "1 pac-bayesian theory\n",
      "1 spline approximation\n",
      "1 nurbs\n",
      "1 k-histogram\n",
      "1 cost-sensitive losses\n",
      "1 over-parameterized models\n",
      "1 logit-adjustment\n",
      "1 margin\n",
      "1 self-supervised learning theory\n",
      "1 expectation-solution algorithm\n",
      "1 functional principal component analysis\n",
      "1 marked point processes\n",
      "1 model-based clustering\n",
      "1 semiparametric model\n",
      "1 graph heat equation\n",
      "1 seismic tomography\n",
      "1 sparse\n",
      "1 model\n",
      "1 mixture\n",
      "1 experts\n",
      "1 conditional\n",
      "1 computation\n",
      "1 router\n",
      "1 compute\n",
      "1 eye tracking\n",
      "1 probability divergences\n",
      "1 novel category discovery\n",
      "1 decomposable submodular function minimization\n",
      "1 sparse graphs\n",
      "1 graph cuts\n",
      "1 speech analysis\n",
      "1 information perturbation\n",
      "1 bellman-ford algorithm\n",
      "1 invariant risk minimization\n",
      "1 group representation\n",
      "1 vqa-cp\n",
      "1 perceptiveness\n",
      "1 visual dialog\n",
      "1 socialiq\n",
      "1 relu\n",
      "1 human\n",
      "1 pose\n",
      "1 shape\n",
      "1 people\n",
      "1 mesh\n",
      "1 semantic edge detection\n",
      "1 propagation network\n",
      "1 self-supervised visual representation learning\n",
      "1 neural implicit function\n",
      "1 octree\n",
      "1 3d representation\n",
      "1 multi-task reinforcement learning\n",
      "1 subgaussian\n",
      "1 point cloud detection\n",
      "1 bayesian active learning\n",
      "1 gaussian process classification\n",
      "1 expected error reduction\n",
      "1 query synthesis\n",
      "1 feature-level augmentation\n",
      "1 model matching\n",
      "1 unsupervised pretraining\n",
      "1 neural models\n",
      "1 causal identification\n",
      "1 causal estimation\n",
      "1 representational similarity analysis\n",
      "1 neural representations\n",
      "1 shape analysis\n",
      "1 metric space\n",
      "1 risk-aware bandits\n",
      "1 mean-covariance metric\n",
      "1 online action detection\n",
      "1 action and behavior recognition\n",
      "1 video analysis\n",
      "1 query embeddings\n",
      "1 multi-hop reasoning\n",
      "1 network architecture design\n",
      "1 convolutional sparse coding\n",
      "1 weight normalization\n",
      "1 model mismatch\n",
      "1 model-free\n",
      "1 markov property\n",
      "1 robotic manipulation\n",
      "1 motion primitives\n",
      "1 hierarchical rl\n",
      "1 video driven speech synthesis\n",
      "1 speech reconstruction from silent video\n",
      "1 lip reading\n",
      "1 audio-visual attention\n",
      "1 context attentional gan\n",
      "1 markov models\n",
      "1 stochastic stability\n",
      "1 causal identification formulas\n",
      "1 frontdoor criterion\n",
      "1 adjustment criterion\n",
      "1 multi armed bandits\n",
      "1 best-arm-identification\n",
      "1 confidence sequences\n",
      "1 causal effect estimator\n",
      "1 nuisance parameter\n",
      "1 isotonic regression\n",
      "1 risk monotonicity\n",
      "1 deep leearning\n",
      "1 trustworthiness\n",
      "1 separation theorem\n",
      "1 data oblivious\n",
      "1 generative vision transformer\n",
      "1 minimax rates\n",
      "1 online data collection\n",
      "1 online moment selection\n",
      "1 subspaces\n",
      "1 deep equilibrium models\n",
      "1 stack recurrent neural network\n",
      "1 neural turing machine\n",
      "1 turing complete\n",
      "1 turing machine\n",
      "1 symbolic matrix\n",
      "1 fast\n",
      "1 grl\n",
      "1 gradient-free\n",
      "1 splitrelu\n",
      "1 convex-nonconvex\n",
      "1 resource efficient training\n",
      "1 deepfakes\n",
      "1 frequency bias\n",
      "1 high-frequency artifacts\n",
      "1 spectrum discrepancies\n",
      "1 spectrum\n",
      "1 frequency\n",
      "1 cross-validation\n",
      "1 local optima\n",
      "1 quasiconvexity\n",
      "1 average reward\n",
      "1 parameterized distillation\n",
      "1 auto-bidding\n",
      "1 reserve pricing\n",
      "1 information measures\n",
      "1 realistic\n",
      "1 rare classes\n",
      "1 k-median\n",
      "1 thomsson sampling\n",
      "1 human-machine teaming\n",
      "1 situational awareness\n",
      "1 ad hoc teaming\n",
      "1 adversarial reweighting\n",
      "1 negative domain transfer\n",
      "1 multimodal regression\n",
      "1 trustworthy\n",
      "1 evidential\n",
      "1 batch-independent normalization\n",
      "1 layer normalization\n",
      "1 instance normalization\n",
      "1 resnets\n",
      "1 resnexts\n",
      "1 efficientnets\n",
      "1 metalearning\n",
      "1 mean field\n",
      "1 mrfs\n",
      "1 conditional random fields\n",
      "1 map inference\n",
      "1 semantic segementation\n",
      "1 test-time training\n",
      "1 feature alignment\n",
      "1 reinforcement-learning\n",
      "1 convex optimisation\n",
      "1 parametrized quantum circuits\n",
      "1 quantum neural networks\n",
      "1 quantum reinforcement learning\n",
      "1 quantum\n",
      "1 variational quantum circuits\n",
      "1 continuous domain generalization\n",
      "1 time-evolving classifiers\n",
      "1 gradient interpolation\n",
      "1 fitting\n",
      "1 spikes\n",
      "1 mle\n",
      "1 glm\n",
      "1 spiking\n",
      "1 recurrent\n",
      "1 rsnn\n",
      "1 neural data\n",
      "1 straight through\n",
      "1 binary networks\n",
      "1 out-of-domain data\n",
      "1 patch learning\n",
      "1 misspecification\n",
      "1 fixed-confidence top-m identification\n",
      "1 recommendation systems\n",
      "1 macroscopic time series forecasting\n",
      "1 parameter prediction\n",
      "1 graph networks\n",
      "1 computational graphs\n",
      "1 robust estimation\n",
      "1 independent causal mechanisms\n",
      "1 volunteer computing\n",
      "1 heterogeneous hardware\n",
      "1 self-supervised pretraining\n",
      "1 negative curvature finding\n",
      "1 distribution distillation\n",
      "1 large-scale tasks\n",
      "1 hierarchical planning\n",
      "1 densenet\n",
      "1 recurrent structures\n",
      "1 layer aggregation\n",
      "1 sparse neural networks\n",
      "1 decentralized training\n",
      "1 conditional generation\n",
      "1 virtual trajectory\n",
      "1 canonical correlation analysis\n",
      "1 shortcut solutions\n",
      "1 low-resource drug discovery\n",
      "1 functional regions\n",
      "1 distinguishing distributions\n",
      "1 statistical testing\n",
      "1 representation analysis\n",
      "1 structured\n",
      "1 pareto optimization\n",
      "1 branch and bound\n",
      "1 censoring\n",
      "1 games\n",
      "1 ipcw\n",
      "1 linear attention\n",
      "1 sample-complexity\n",
      "1 method-of-moments\n",
      "1 embodied active learning\n",
      "1 latent variable\n",
      "1 predictive state representation\n",
      "1 responsible ml\n",
      "1 data minimization\n",
      "1 double q-learning\n",
      "1 estimation bias\n",
      "1 off-line multi-agent rl\n",
      "1 mean-field approximation\n",
      "1 pessimistic value iteration\n",
      "1 sub-optimality bound\n",
      "1 output diversified sampling\n",
      "1 batch ensemble\n",
      "1 algorithm stability\n",
      "1 momentum methods\n",
      "1 partial label learning\n",
      "1 label enhancement\n",
      "1 label distribution\n",
      "1 pseudo label\n",
      "1 class disentanglement\n",
      "1 geometric processing\n",
      "1 neural implicit fields\n",
      "1 implicit fields\n",
      "1 shape editing\n",
      "1 shape manipulation\n",
      "1 shape smoothing and sharpening\n",
      "1 black-box defense\n",
      "1 black-box attacks\n",
      "1 invariant theory\n",
      "1 group theory\n",
      "1 scalars\n",
      "1 multiagent reinforcement learning\n",
      "1 option\n",
      "1 succesor representation\n",
      "1 duplex network\n",
      "1 reversible machine translation\n",
      "1 optimal auction\n",
      "1 autoregressive\n",
      "1 bias-only model\n",
      "1 nli\n",
      "1 text-image matching\n",
      "1 heterogeneous feature representation\n",
      "1 hardware design\n",
      "1 test generation\n",
      "1 3d voxel features\n",
      "1 monocular 3d detection and reconstruction\n",
      "1 multiple objects\n",
      "1 local pca-sdf\n",
      "1 model debugging\n",
      "1 superresolution\n",
      "1 indistinguishability\n",
      "1 experimental data\n",
      "1 density model\n",
      "1 maximum entropy rl\n",
      "1 mujoco\n",
      "1 neural bandits\n",
      "1 bank loan problem\n",
      "1 deep-learning theory\n",
      "1 deep relu networks\n",
      "1 instrumental variables\n",
      "1 local treatment effect\n",
      "1 complier average causal effects\n",
      "1 semiparametric inference\n",
      "1 a/b testing\n",
      "1 two-sided marketplace\n",
      "1 treatment effect estimation\n",
      "1 spike-sorting\n",
      "1 neuropixels\n",
      "1 registration\n",
      "1 keyword search\n",
      "1 node embedding\n",
      "1 user-level\n",
      "1 learning from observation\n",
      "1 point cloud matching\n",
      "1 coarse-to-fine mechanism\n",
      "1 representational geometry\n",
      "1 biologically inspired vision models\n",
      "1 biologically inspired auditory models\n",
      "1 robust perception\n",
      "1 black box\n",
      "1 sobol\n",
      "1 discrete latent variable\n",
      "1 coupling\n",
      "1 approximate conditional independence\n",
      "1 reconstruction-based self-supervised learning\n",
      "1 right to be forgotten\n",
      "1 graph-based planning\n",
      "1 regularized optimal transport\n",
      "1 langevin sampling\n",
      "1 score-based generative model\n",
      "1 rerm\n",
      "1 regularized erm\n",
      "1 multiple-passes\n",
      "1 gd\n",
      "1 neural ordinary differential equations\n",
      "1 convolutional filter decomposition\n",
      "1 continuous image generation\n",
      "1 imitation learning from observation alone\n",
      "1 imitation learning theory\n",
      "1 offline imitation learning\n",
      "1 agnostic learning\n",
      "1 low rank mdp\n",
      "1 rl theory\n",
      "1 generative priors\n",
      "1 mri reconstruction\n",
      "1 inverse rendering\n",
      "1 coordinate-based mlp\n",
      "1 brdf estimation\n",
      "1 illumination estimation\n",
      "1 nerf\n",
      "1 np-hard\n",
      "1 policy collaboration\n",
      "1 hierarchical solving strategy\n",
      "1 continuous-time edges\n",
      "1 sigmoidal gaussian process\n",
      "1 group invariance\n",
      "1 convolutional architecture\n",
      "1 point cloud recognition\n",
      "1 few-shot-learning\n",
      "1 continuous-time neural models\n",
      "1 numerical methods\n",
      "1 distributionally robust learning\n",
      "1 learning to plan\n",
      "1 mutual boosting\n",
      "1 sub-tasking\n",
      "1 underdamped langevin diffusion\n",
      "1 shapley\n",
      "1 shap\n",
      "1 xai\n",
      "1 axioms\n",
      "1 smoothed analysis\n",
      "1 activity recognition\n",
      "1 human-object interaction\n",
      "1 temporal action detection\n",
      "1 convex geometry\n",
      "1 separation oracles\n",
      "1 low rank approximation\n",
      "1 numerical linear algebra\n",
      "1 learning-based algorithms\n",
      "1 matrix sketching\n",
      "1 molecular conformer generation\n",
      "1 molecular geometry\n",
      "1 molecular generative models\n",
      "1 message passing neural networks\n",
      "1 3d generation\n",
      "1 molecular conformations\n",
      "1 consistent estimation\n",
      "1 robust optimization\n",
      "1 oblivious outliers\n",
      "1 sparse regression.\n",
      "1 ai safety\n",
      "1 algorithms evaluation\n",
      "1 misclassification detection\n",
      "1 view invariance\n",
      "1 object representations\n",
      "1 momentum-based methods\n",
      "1 statistical physics of learning\n",
      "1 dynamical mean field theory\n",
      "1 high-dimensional non-convex dynamics\n",
      "1 deep learning or neural networks\n",
      "1 sparsity and feature selection\n",
      "1 (application) natural language and text processing\n",
      "1 contrastive training\n",
      "1 learning from noise\n",
      "1 memory-economic training\n",
      "1 edge device training\n",
      "1 mobile training acceleration\n",
      "1 differentiable architecture search\n",
      "1 dl software implementation\n",
      "1 fairness variance\n",
      "1 empirical study\n",
      "1 bandit phase retrieval\n",
      "1 data recommendation\n",
      "1 weak supervision\n",
      "1 document understanding\n",
      "1 quadrature\n",
      "1 numerical integration\n",
      "1 imitation\n",
      "1 pure exploration strategies\n",
      "1 subpopulations\n",
      "1 gaussian approximation\n",
      "1 streaming pca\n",
      "1 bidirectional bounds\n",
      "1 jacobi-determinant estimator\n",
      "1 topk\n",
      "1 contractive compressor\n",
      "1 structured architecture\n",
      "1 discretization\n",
      "1 communication\n",
      "1 specialist components\n",
      "1 health\n",
      "1 persistence homology\n",
      "1 trojan attack\n",
      "1 bayesian optimal experimental design\n",
      "1 boed\n",
      "1 sequential boed\n",
      "1 likelihood-free methods\n",
      "1 parameter estimation\n",
      "1 mutual information lower bounds\n",
      "1 stochastic simulator models\n",
      "1 data manifolds\n",
      "1 mode-dropping\n",
      "1 3d-shapes\n",
      "1 multilabel classification\n",
      "1 recurrent classifier chains\n",
      "1 classifier chains\n",
      "1 exact classification\n",
      "1 subset accuracy\n",
      "1 distributed non-convex optimization\n",
      "1 minibatch sgd\n",
      "1 iteratively reweighted least squares\n",
      "1 adaptive convolutions\n",
      "1 3d super-resolution\n",
      "1 3d content creation\n",
      "1 3d shape representation\n",
      "1 gain\n",
      "1 distribution approximation\n",
      "1 multi-domain learning\n",
      "1 lexicographic optimization\n",
      "1 pareto set\n",
      "1 dynamic treatment regime\n",
      "1 asynchronous optimization\n",
      "1 delayed gradients\n",
      "1 dynamic visual reasoning\n",
      "1 graph structure\n",
      "1 common neighbors\n",
      "1 biologically plausible deep learning\n",
      "1 hebbian plasticity\n",
      "1 computational education\n",
      "1 automated testing\n",
      "1 mdp equivalence\n",
      "1 lipschitz regularization\n",
      "1 gradient regularization\n",
      "1 security-constrained optimal power flow\n",
      "1 implicit layers\n",
      "1 remote sensing\n",
      "1 event selection\n",
      "1 gradient methods\n",
      "1 rates\n",
      "1 strict nash equilibria\n",
      "1 follow the regularized leader\n",
      "1 tight bounds\n",
      "1 accelerated gradient descent\n",
      "1 uniform stability\n",
      "1 dependence maximization\n",
      "1 hsic\n",
      "1 causal effects\n",
      "1 adversarial environment generation\n",
      "1 compositional reinforcement learning\n",
      "1 minimax regret adversary\n",
      "1 auto curriculum\n",
      "1 motion analysis\n",
      "1 bidirectional compression\n",
      "1 entropy regularisation\n",
      "1 functional regularisation\n",
      "1 sublinear algorithms\n",
      "1 label imbalance\n",
      "1 partial information decomposition\n",
      "1 performance estimation\n",
      "1 neural prior\n",
      "1 scene flow\n",
      "1 implicit regularizer\n",
      "1 adversarial corruptions\n",
      "1 classification evaluation\n",
      "1 performance measures\n",
      "1 subpopulation shift\n",
      "1 risk-awareness\n",
      "1 intuitive physics\n",
      "1 physics learning\n",
      "1 algorithmic bias\n",
      "1 fairness mitigation\n",
      "1 partial observation\n",
      "1 subgoals\n",
      "1 dynamic environments\n",
      "1 long-horizon task\n",
      "1 non-stationary smdp\n",
      "1 egocentric human pose estimation\n",
      "1 augmented reality\n",
      "1 humanoid control\n",
      "1 kinematics and dynamics\n",
      "1 continuous dynamics\n",
      "1 efficient transformer\n",
      "1 long-sequence modeling\n",
      "1 lightweight image super-resolution\n",
      "1 aligned structured sparsity learning\n",
      "1 stochastic matching\n",
      "1 prophet inequality\n",
      "1 prophet secretary\n",
      "1 contention resolution\n",
      "1 uncertainty principle\n",
      "1 long-tailed distribution\n",
      "1 representation cost\n",
      "1 linear neural networks\n",
      "1 doubly robust estimator\n",
      "1 semiparametric efficiency\n",
      "1 dependent samples\n",
      "1 degree-corrected mix-membership model\n",
      "1 non-uniform hypergraph\n",
      "1 global testing\n",
      "1 minimax lower bound\n",
      "1 region of impossibility\n",
      "1 tensor scaling\n",
      "1 degree matching\n",
      "1 sbm\n",
      "1 intrinsic reward\n",
      "1 3d from a single image\n",
      "1 3d scene understanding\n",
      "1 mesh-free\n",
      "1 decision-time planning\n",
      "1 long-term effects\n",
      "1 dynamic treatment effects\n",
      "1 surrogates\n",
      "1 symmetry discovery\n",
      "1 group convolutional neural network\n",
      "1 group equivariant architecture\n",
      "1 lie algebra\n",
      "1 deep model learning\n",
      "1 physics-based priors\n",
      "1 contact models\n",
      "1 algorithms with predictions\n",
      "1 reliable machine learning\n",
      "1 training time attacks\n",
      "1 attacks on sgd\n",
      "1 poisoning\n",
      "1 backdoors\n",
      "1 gradual domain adaptation\n",
      "1 neural network dynamics\n",
      "1 deep graph neural networks\n",
      "1 dirichlet energy\n",
      "1 orthogonal weight\n",
      "1 syntactic representations\n",
      "1 bipartite graph\n",
      "1 network analysis\n",
      "1 singular value thresholding\n",
      "1 minimax theory\n",
      "1 discrete-discrete optimal transport\n",
      "1 kantorovich relaxation\n",
      "1 legendre-fenchel dual\n",
      "1 semi-discrete optimal transport\n",
      "1 wasserstein distance.\n",
      "1 neural network architectures\n",
      "1 pdes  in deep learning\n",
      "1 topic model evaluation\n",
      "1 npmi\n",
      "1 topic coherence\n",
      "1 validation\n",
      "1 crowdsourcing\n",
      "1 model comparison\n",
      "1 automatic metric\n",
      "1 automated metric\n",
      "1 two-timescale stochastic approximation\n",
      "1 anti-aliasing\n",
      "1 heuristic\n",
      "1 warm-start\n",
      "1 truncated horizon\n",
      "1 human in the loop rl\n",
      "1 conditional neural network\n",
      "1 image denoising\n",
      "1 jpeg deblocking\n",
      "1 audio-visual learning\n",
      "1 video to music\n",
      "1 multi-modality\n",
      "1 learning for code\n",
      "1 program understanding\n",
      "1 program repair\n",
      "1 relation-aware transformers\n",
      "1 graph-based deep learning\n",
      "1 tensor decomposition techniques\n",
      "1 tensor train\n",
      "1 tensor ring\n",
      "1 positive definite models\n",
      "1 probabilistic inference\n",
      "1 probability representation\n",
      "1 degroot\n",
      "1 consenesus finding\n",
      "1 combining expert opinion\n",
      "1 opinion pool\n",
      "1 adaptive model weighting\n",
      "1 social sciences\n",
      "1 human feedback\n",
      "1 reinforcement learning for optimization\n",
      "1 multi-task gaussian processes\n",
      "1 online knapsack\n",
      "1 semi-online algorithms\n",
      "1 dpsgd\n",
      "1 jax\n",
      "1 vectorization\n",
      "1 just-in-time compilation\n",
      "1 learned optimizers\n",
      "1 monte carlo gradient estimation\n",
      "1 slice sampling\n",
      "1 targeted transferability\n",
      "1 realistic evaluation\n",
      "1 universal adversarial perturbations\n",
      "1 6d pose\n",
      "1 se(3) equivariance\n",
      "1 category-level\n",
      "1 real data\n",
      "1 shape reconstruction\n",
      "1 neural radiance fields\n",
      "1 human performance capture\n",
      "1 generalizable neural radiance fields\n",
      "1 federated bandits\n",
      "1 g-optimal design\n",
      "1 pate\n",
      "1 alibi\n",
      "1 memorization attacks\n",
      "1 gaussian processen\n",
      "1 black-box\n",
      "1 dissimilarity\n",
      "1 cka\n",
      "1 orthogonal procrustes\n",
      "1 probing\n",
      "1 generalized depthwise-seprarable\n",
      "1 multiple sources\n",
      "1 multimodal understanding\n",
      "1 audio recognition\n",
      "1 early stopping\n",
      "1 depth\n",
      "1 sparse recovery\n",
      "1 discrete latent variables\n",
      "1 unbiased\n",
      "1 low variance\n",
      "1 probabilistic modeling\n",
      "1 copula\n",
      "1 cost-sensitive methods\n",
      "1 learning curves\n",
      "1 support vector machine\n",
      "1 long-range context\n",
      "1 opengraphbenchmark\n",
      "1 surrogate regret bounds\n",
      "1 excess risk bounds\n",
      "1 polyhedral losses\n",
      "1 few-shot text classification\n",
      "1 conditional neural process\n",
      "1 dnn training\n",
      "1 memory efficient training\n",
      "1 drawing\n",
      "1 perceptual loss\n",
      "1 visual communication\n",
      "1 false discovery rate control\n",
      "1 statistical machine learning\n",
      "1 inverse design\n",
      "1 differentiable surrogate\n",
      "1 3d printing\n",
      "1 soft robot\n",
      "1 observation cost\n",
      "1 partially observable markov decision process\n",
      "1 pac\n",
      "1 health care\n",
      "1 non-stationary\n",
      "1 multi-armed\n",
      "1 blocking\n",
      "1 maximization\n",
      "1 pipeline model parallelism\n",
      "1 dnn partitioning\n",
      "1 tensor parallelism\n",
      "1 adaptive batching\n",
      "1 large batch size\n",
      "1 gradient similarity measure\n",
      "1 gradient variance\n",
      "1 gradient noise\n",
      "1 large scale training\n",
      "1 multiple testing\n",
      "1 off policy evaluation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 double robustness\n",
      "1 cumulative distribution functions\n",
      "1 risk functionals\n",
      "1 adaptive gradient algorithms\n",
      "1 amsgrad\n",
      "1 unimodal bandits\n",
      "1 optimal algorithm\n",
      "1 one-dimensional exponential family distributions\n",
      "1 recourse\n",
      "1 actionable recourse\n",
      "1 retrosynthesis\n",
      "1 synthons\n",
      "1 computational chemistry\n",
      "1 graph autoencoder\n",
      "1 never-ending learning\n",
      "1 auxiliary tasks\n",
      "1 general value functions\n",
      "1 reconnaissance blind chess\n",
      "1 surrogate loss functions\n",
      "1 prediction dimension\n",
      "1 route recommendation\n",
      "1 road networks\n",
      "1 inductive learning\n",
      "1 quadratic assignment problem\n",
      "1 automorphic equivalence\n",
      "1 structural role\n",
      "1 graph analysis\n",
      "1 bellman-consistent pessimism\n",
      "1 sample complexity bounds\n",
      "1 linear mdp\n",
      "1 probabilistic model\n",
      "1 interactive segmentation\n",
      "1 fuzzy clustering\n",
      "1 oracle\n",
      "1 similarity queries\n",
      "1 soft clustering.\n",
      "1 latent-variable models\n",
      "1 deep state-space models\n",
      "1 bayesian filtering and smoothing\n",
      "1 empirical bayes\n",
      "1 constrained optimisation\n",
      "1 probability distributions\n",
      "1 statistical rates\n",
      "1 matching markets\n",
      "1 learning equilibria\n",
      "1 out-of-the-domain\n",
      "1 hard negative mining\n",
      "1 committee elections\n",
      "1 participatory budgeting\n",
      "1 aggregating preferences\n",
      "1 local learning rules\n",
      "1 algorithm configuration\n",
      "1 budgeted learning\n",
      "1 variable importances\n",
      "1 feature ranking\n",
      "1 meta-continual learning\n",
      "1 generative classifier\n",
      "1 bayesian classifier\n",
      "1 neuro-inspired artificial intelligence\n",
      "1 video summarization\n",
      "1 language-guided video summarization\n",
      "1 query-focused video summarization\n",
      "1 multimodal video summarization\n",
      "1 dual encoders\n",
      "1 extreme classification\n",
      "1 functional brain networks\n",
      "1 linear factor models\n",
      "1 directed functional connectivity\n",
      "1 deepcca\n",
      "1 fractals\n",
      "1 product space\n",
      "1 overlapping space\n",
      "1 gumbel-softmax\n",
      "1 binarization\n",
      "1 lottery-ticket hypothesis\n",
      "1 stochastic variational gaussian processes\n",
      "1 asynchrony\n",
      "1 non-blocking algorithms\n",
      "1 decentralized mini-max optimization\n",
      "1 nonlinear function approximation\n",
      "1 policy evaluation\n",
      "1 probabilistic graphical models\n",
      "1 constrained most probable explanation\n",
      "1 video temporal grounding\n",
      "1 kernelized model\n",
      "1 optimal regret bounds\n",
      "1 model-based\n",
      "1 implicit\n",
      "1 seismic inversion\n",
      "1 sustainability\n",
      "1 seismic data ingestion\n",
      "1 property testing\n",
      "1 sub-population shift\n",
      "1 fairness accuracy trade-off\n",
      "1 adaptive task scheduler\n",
      "1 discounted mdp\n",
      "1 bernstein inequality\n",
      "1 population-based methods\n",
      "1 few-shot generalization\n",
      "1 human-ai coordination\n",
      "1 image representations\n",
      "1 conditional gradients\n",
      "1 bregman projections\n",
      "1 submodular base polytopes\n",
      "1 streaming algorithm\n",
      "1 local algorithm\n",
      "1 bayesian reinforcement learning\n",
      "1 learning with errors\n",
      "1 lattice algorithms\n",
      "1 cryptography\n",
      "1 computational-to-statistical gap\n",
      "1 reinforcememt learning\n",
      "1 grounded language learning\n",
      "1 combinatory categorial grammar\n",
      "1 probabilistic reasoning\n",
      "1 neural retrieval\n",
      "1 multi-hop question answering\n",
      "1 claim verification\n",
      "1 colbert\n",
      "1 visual representation\n",
      "1 structured discrete latent variable\n",
      "1 gumbel-max trick\n",
      "1 score function\n",
      "1 monotone variational inequalities\n",
      "1 stochastic variational inequalities\n",
      "1 improved rates\n",
      "1 neural network analysis\n",
      "1 weak approximation\n",
      "1 linear scaling rule\n",
      "1 sparse vectors\n",
      "1 mixture of binary linear classifiers\n",
      "1 1-bit compessed sensing\n",
      "1 noisy measurements\n",
      "1 event-dependent scaling\n",
      "1 intrinsic parameters\n",
      "1 teacher-student paradigm\n",
      "1 surrogate gradient\n",
      "1 learning in games\n",
      "1 dynamic graph cnn\n",
      "1 streaming model\n",
      "1 cardinality constraint\n",
      "1 example difficulty\n",
      "1 prediction depth\n",
      "1 spectral gap\n",
      "1 mixing time\n",
      "1 kullback leibler risk\n",
      "1 text style transfer\n",
      "1 adversarial risk\n",
      "1 2-alternating capacities\n",
      "1 strassen's theorem\n",
      "1 measurable selection theorem\n",
      "1 unsupervised clustering\n",
      "1 robust loss functions\n",
      "1 jensen-shannon divergence\n",
      "1 nearest neighbors\n",
      "1 stanford dog\n",
      "1 user-study\n",
      "1 multi-agent interaction modeling\n",
      "1 certification\n",
      "1 top-k\n",
      "1 relaxations\n",
      "1 nonlinear control\n",
      "1 latency\n",
      "1 out-of-context\n",
      "1 audio-visual\n",
      "1 synchronization\n",
      "1 dynamic neural network\n",
      "1 neural network interpretability\n",
      "1 efficient neural network\n",
      "1 example-based control\n",
      "1 dialog- or communication-based learning\n",
      "1 pedagogy\n",
      "1 dueling bandits\n",
      "1 data-driven regularization\n",
      "1 iterative unrolling\n",
      "1 large scale\n",
      "1 batch active learning\n",
      "1 denseflow\n",
      "1 densely connected couplings\n",
      "1 value function\n",
      "1 muzero\n",
      "1 chemical application\n",
      "1 teaching via demonstrations\n",
      "1 curriculum design\n",
      "1 feature compression\n",
      "1 recommendation system\n",
      "1 signaling games\n",
      "1 noisy channel\n",
      "1 disease progression model\n",
      "1 alzheimer's disease\n",
      "1 cognition trajectory prediction\n",
      "1 renyi divergence\n",
      "1 privacy amplification via shuffling\n",
      "1 privacy composition.\n",
      "1 adaptive sample size methods\n",
      "1 large-scale optimization.\n",
      "1 online rl\n",
      "1 policy finetuning\n",
      "1 automated algorithm configuration\n",
      "1 automated algorithm design\n",
      "1 branch-and-bound\n",
      "1 branch-and-cut\n",
      "1 cutting planes\n",
      "1 chvátal-gomory cuts\n",
      "1 computational social choice\n",
      "1 iterative voting\n",
      "1 best-response dynamics\n",
      "1 transparency\n",
      "1 discrepancy\n",
      "1 sortition\n",
      "1 general-purpose meta-learning\n",
      "1 learned learning rules\n",
      "1 fast weights\n",
      "1 distributed memory\n",
      "1 efficient representation learning\n",
      "1 explainable artificial intelligence\n",
      "1 dialogue response generation\n",
      "1 sequential decision-making under uncertainty\n",
      "1 efficient exploration\n",
      "1 sequential generative model\n",
      "1 temporal difference\n",
      "1 human-in-the-loop reinforcement learning\n",
      "1 interactive reinforcement learning\n",
      "1 saliency map\n",
      "1 visual explanations\n",
      "1 human-agent interaction\n",
      "1 multimodal human-agent interaction\n",
      "1 implicit functions\n",
      "1 revenue maximization\n",
      "1 adversarial noise\n",
      "1 randomized douglas-rachford splitting method\n",
      "1 nonconvex federated optimization\n",
      "1 asynchronous algorithm\n",
      "1 sparse variational inference\n",
      "1 natural gradients\n",
      "1 data deletion\n",
      "1 max information\n",
      "1 audiovisual\n",
      "1 inertial manifold\n",
      "1 theoretical evidence\n",
      "1 approximation guarantee\n",
      "1 sequential hypothesis testing\n",
      "1 greedy aglorithm\n",
      "1 cancer detection\n",
      "1 egocentric\n",
      "1 contour\n",
      "1 action delay impact\n",
      "1 bandit learning\n",
      "1 generative biology\n",
      "1 variant prediction\n",
      "1 gumbel-softmax trick\n",
      "1 auto augmentation\n",
      "1 overparameterized neural networks\n",
      "1 low-dimensional structure\n",
      "1 continuous time models\n",
      "1 distributed estimation\n",
      "1 instance-optimal\n",
      "1 feature matching\n",
      "1 optimization for deep learning\n",
      "1 ica\n",
      "1 identifiable\n",
      "1 reps\n",
      "1 facility location\n",
      "1 machine-learned advice\n",
      "1 online clustering\n",
      "1 inducing points\n",
      "1 model inversion attacks\n",
      "1 flows\n",
      "1 posterior collapse\n",
      "1 latent variable identifiability\n",
      "1 monte carlo methods\n",
      "1 fused lasso\n",
      "1 high-dimensional regression\n",
      "1 shrinkage prior\n",
      "1 tree-based methods\n",
      "1 gumbel max\n",
      "1 reparameterization trick\n",
      "1 stochastic programming\n",
      "1 large deviations\n",
      "1 holographic reduced representations\n",
      "1 binding\n",
      "1 neuro-symbolic\n",
      "1 model personalization\n",
      "1 linear non-gaussian models\n",
      "1 faithfulness\n",
      "1 confounding\n",
      "1 run time\n",
      "1 sequential probability assignment\n",
      "1 conditional density estimation\n",
      "1 logarithmic loss\n",
      "1 feedback alignment\n",
      "1 slam\n",
      "1 simultaneous localization and mapping\n",
      "1 wasserstein gradient flow\n",
      "1 efficient semi supervised learning\n",
      "1 semi supervised learning\n",
      "1 data efficient learning\n",
      "1 kernel design\n",
      "1 bayesian model selection\n",
      "1 forster transform\n",
      "1 massart noise\n",
      "1 transference analysis\n",
      "1 graph generative models\n",
      "1 edge independent models\n",
      "1 node embeddings\n",
      "1 triangle density\n",
      "1 deep gaussian process\n",
      "1 vanilla q-learning\n",
      "1 linear transition model\n",
      "1 leave-one-out analysis\n",
      "1 sparse mixture of experts\n",
      "1 sparse gate\n",
      "1 subset selection\n",
      "1 logical disjunction\n",
      "1 oblique tree\n",
      "1 speed-up\n",
      "1 drug discovery\n",
      "1 dense keypoint estimation\n",
      "1 multiview supervision\n",
      "1 dense epipolar geometry\n",
      "1 trajectory forecasting\n",
      "1 interacting dynamical systems\n",
      "1 roto-translation equivariance\n",
      "1 geometric graphs\n",
      "1 markov boundary\n",
      "1 pooling\n",
      "1 feature aggregation\n",
      "1 set learning\n",
      "1 understanding human decisions\n",
      "1 inverse decision-making\n",
      "1 augmenting clinical decision support\n",
      "1 partial models\n",
      "1 affordances\n",
      "1 smooth games\n",
      "1 unconstrained stochastic variational inequality\n",
      "1 stochastic algorithms\n",
      "1 stochastic gradient descent-ascent (sgda)\n",
      "1 stochastic consensus optimization\n",
      "1 nested sampling\n",
      "1 provably efficient reinforcement learning\n",
      "1 model transfer\n",
      "1 symbol grounding\n",
      "1 neurosymbolic reasoning\n",
      "1 satnet\n",
      "1 optimal weak transport\n",
      "1 barycenter of probability measures\n",
      "1 out-of-distribution robustness\n",
      "1 infinitely-armed bandit models\n",
      "1 cumulative regret\n",
      "1 marginal likelihood estimation\n",
      "1 universal function approximation\n",
      "1 tree-decomposition\n",
      "1 3d scene graphs\n",
      "1 video domain adaptation\n",
      "1 human mesh recovery\n",
      "1 3d from single images\n",
      "1 silhouette topology extraction\n",
      "1 convolutional neural tangent kernel\n",
      "1 cntk\n",
      "1 information aggregation\n",
      "1 unsupervised learning theory\n",
      "1 self-driving\n",
      "1 online linear regression\n",
      "1 convolution neural network\n",
      "1 edge computing\n",
      "1 edge\n",
      "1 low-bit\n",
      "1 multiplication-free\n",
      "1 bit-shift\n",
      "1 leading eigenvector\n",
      "1 bit complexity\n",
      "1 sphere\n",
      "1 long sequence modeling\n",
      "1 conditional expectation factorization\n",
      "1 full attention\n",
      "1 structural credit assignment\n",
      "1 fmri encoding models\n",
      "1 language representations\n",
      "1 incentivized exploration\n",
      "1 principal agent models\n",
      "1 latent variable model\n",
      "1 behavioural neuroscience\n",
      "1 motor neuroscience\n",
      "1 medical image segmentation\n",
      "1 adversarial mdp\n",
      "1 bandit feedback\n",
      "1 dilated bonuses\n",
      "1 randomized response\n",
      "1 time-evolution\n",
      "1 meta-learning evaluation\n",
      "1 empirical risk\n",
      "1 generalization measures\n",
      "1 value function factorization\n",
      "1 part\n",
      "1 relational reasoning\n",
      "1 model diagnostics\n",
      "1 kl divergence\n",
      "1 reliable estimation\n",
      "1 greedy algorithms\n",
      "1 bregman divergence\n",
      "1 bregman information\n",
      "1 exponential families\n",
      "1 exponential family\n",
      "1 m-estimation\n",
      "1 maximum likelihood estimation\n",
      "1 normality\n",
      "1 high-dimensional data\n",
      "1 neural implict functions\n",
      "1 3d computer vision\n",
      "1 clothed human modeling\n",
      "1 cloth modeling\n",
      "1 set prediction\n",
      "1 image captioning\n",
      "1 data generation\n",
      "1 frank-wolfe like algorithms\n",
      "1 non-convex quadratic programming\n",
      "1 font generation\n",
      "1 implicit neural networks\n",
      "1 switching linear dynamical systems\n",
      "1 slds\n",
      "1 fixed points\n",
      "1 prioritized replay\n",
      "1 fréchet mean\n",
      "1 laplace mechanism\n",
      "1 k-norm mechanism\n",
      "1 primal-dual\n",
      "1 convex-concave\n",
      "1 local smoothness\n",
      "1 local lipschitz continuity\n",
      "1 secure aggregation\n",
      "1 spatial temporal modeling\n",
      "1 covid-19 pandemic\n",
      "1 health disparity\n",
      "1 disease transmission\n",
      "1 latent process\n",
      "1 batch\n",
      "1 exploitation\n",
      "1 exact probabilistic reasoning\n",
      "1 propositional satisfiability\n",
      "1 representation learning from unlabelled videos\n",
      "1 3d dense correspondence\n",
      "1 point autoencoder\n",
      "1 pde\n",
      "1 graphon\n",
      "1 vertex similarity\n",
      "1 link probability\n",
      "1 edge probability\n",
      "1 deep inversion\n",
      "1 minimax optimal\n",
      "1 graph semi-supervised learning\n",
      "1 nonseparable\n",
      "1 full information\n",
      "1 hints\n",
      "1 query cost\n",
      "1 combinatorial spaces\n",
      "1 generative neural network\n",
      "1 denoise\n",
      "1 gradient type method\n",
      "1 arbitrary conditioning\n",
      "1 graph combinatorial optimization problems\n",
      "1 agent modelling\n",
      "1 opponent modelling\n",
      "1 bisimulation\n",
      "1 sparse rewards\n",
      "1 state similarity metrics\n",
      "1 probabilistic forecasting\n",
      "1 quantile regression trees\n",
      "1 proximal splitting algorithms\n",
      "1 matrix optimization\n",
      "1 eigenvalue computation\n",
      "1 jacobi's method for eigenvalue decomposition\n",
      "1 exponential family distribution\n",
      "1 adversarial evaluation\n",
      "1 model in the loop\n",
      "1 instruction following\n",
      "1 dag estimation\n",
      "1 time-cells\n",
      "1 recurrent neural-network\n",
      "1 neural circuits\n",
      "1 unsupervised goal reaching\n",
      "1 unsupervised rl\n",
      "1 model-based rl\n",
      "1 heavy tailed noise\n",
      "1 infinite variance\n",
      "1 learning-to-rank\n",
      "1 differentiable sorting\n",
      "1 continuous relaxations\n",
      "1 motion planning\n",
      "1 collision\n",
      "1 collision checking\n",
      "1 scikit-learn\n",
      "1 programming models\n",
      "1 functional programming\n",
      "1 quasi-self-concordance\n",
      "1 multiplicative weights update\n",
      "1 width reduction\n",
      "1 uncertainty calibration\n",
      "1 open-domain question answering\n",
      "1 information retrieval\n",
      "1 closed-book qa\n",
      "1 task space\n",
      "1 feature encoding\n",
      "1 global pooling\n",
      "1 texture representation\n",
      "1 learning from demonstration\n",
      "1 learning from suboptimal demonstrations\n",
      "1 statistical fault localization\n",
      "1 order embeddings\n",
      "1 gaussian embeddings\n",
      "1 hierarchical topic models\n",
      "1 gamma belief network\n",
      "1 median of means\n",
      "1 metric entropy bounds\n",
      "1 bregman divergences\n",
      "1 iterative optimization\n",
      "1 active classification\n",
      "1 inner maximization\n",
      "1 outer minimization\n",
      "1 attribution map\n",
      "1 non-iid learning\n",
      "1 small-ball method\n",
      "1 power method\n",
      "1 non-convexity\n",
      "1 cp decomposition\n",
      "1 bayesian nonparametric regression\n",
      "1 constrained domain\n",
      "1 ensemble learning\n",
      "1 random spanning trees\n",
      "1 magnetic laplacian\n",
      "1 data valuation\n",
      "1 replication robustness\n",
      "1 model-agnostic\n",
      "1 minmax optimization\n",
      "1 von neumann\n",
      "1 asymptotic stability\n",
      "1 hidden games\n",
      "1 incentives\n",
      "1 biologically-plausible deep learning\n",
      "1 multilingual\n",
      "1 strategic incentives\n",
      "1 allocation\n",
      "1 markets\n",
      "1 social learning\n",
      "1 herding\n",
      "1 defocus deblurring\n",
      "1 image recovery\n",
      "1 trust region optimization\n",
      "1 out-of-domain generalization\n",
      "1 collaboration\n",
      "1 cooperation\n",
      "1 common-payoff\n",
      "1 human-ai interaction\n",
      "1 pruning plasticity\n",
      "1 pruning during training\n",
      "1 gradual pruning\n",
      "1 neuroregeneration\n",
      "1 online matching\n",
      "1 differential equation method\n",
      "1 ownership verification\n",
      "1 statistical reinforcement learning\n",
      "1 horizon-free\n",
      "1 neural population dynamics\n",
      "1 intermittent sampling\n",
      "1 electrophysiology\n",
      "1 calcium imaging\n",
      "1 brain-computer interfaces\n",
      "1 neuroprosthetics\n",
      "1 sequential autoencoders\n",
      "1 statistical query learning\n",
      "1 mini-batch sgd\n",
      "1 contextual bandit\n",
      "1 adaptive data collection\n",
      "1 ensemble clustering\n",
      "1 soft clustering\n",
      "1 approximation algorithm\n",
      "1 steerable cnns\n",
      "1 group convolution\n",
      "1 harmonic distortion analysis\n",
      "1 missing not at random\n",
      "1 offline\n",
      "1 risk-sensitive\n",
      "1 distributional\n",
      "1 conservative\n",
      "1 decision-focused learning\n",
      "1 woodbury matrix identity\n",
      "1 kkt conditions\n",
      "1 optimality conditions\n",
      "1 sequential decision problems\n",
      "1 leverage score sampling\n",
      "1 lewis weight sampling\n",
      "1 maximum margin classification\n",
      "1 over-parameterization\n",
      "1 benign overfitting\n",
      "1 temporal splits\n",
      "1 model analysis\n",
      "1 dataset distillation\n",
      "1 infinite-width limit\n",
      "1 kernel ridge-regression\n",
      "1 nash bargaining\n",
      "1 policy robustness\n",
      "1 visual control task\n",
      "1 derived memory\n",
      "1 equivariant sampling\n",
      "1 stein variational gradient descent\n",
      "1 active sampling\n",
      "1 efficient robust neural network training\n",
      "1 robustness against common and adversarial corruptions\n",
      "1 accelerate robust neural network training\n",
      "1 large-scale kernel methods\n",
      "1 partitions\n",
      "1 natural language processing applications of continual learning\n",
      "1 graph feedback\n",
      "1 mlp\n",
      "1 networks\n",
      "1 state aggregation\n",
      "1 design space\n",
      "1 transition model\n",
      "1 entities\n",
      "1 monet\n",
      "1 moe\n",
      "1 intervention design\n",
      "1 causal graphical models\n",
      "1 boltzmann generators\n",
      "1 backpropagation through root-finding\n",
      "1 internet-of-things\n",
      "1 gaussian design\n",
      "1 laplace approximation\n",
      "1 software library\n",
      "1 sparse updates\n",
      "1 parameter-efficient transfer learning\n",
      "1 efficient checkpointing\n",
      "1 speech mining\n",
      "1 large-scale mining\n",
      "1 speech translation\n",
      "1 group testing\n",
      "1 near neighbor search\n",
      "1 index\n",
      "1 (other) statistics\n",
      "1 reward design\n",
      "1 explicable reward functions\n",
      "1 mmse\n",
      "1 optimal estimation\n",
      "1 supervised and unsupervised learning\n",
      "1 generalization estimates\n",
      "1 hilbert spaces\n",
      "1 distribution mismatch\n",
      "1 dynamic auctions\n",
      "1 value-maximizing buyer\n",
      "1 return on investment (roi) constraint\n",
      "1 cold posterior\n",
      "1 curation\n",
      "1 data-augmentation\n",
      "1 explanation-based learning\n",
      "1 spurious patterns\n",
      "1 post-hoc model explanation\n",
      "1 moco\n",
      "1 momentum contrastive self supervised learning\n",
      "1 histopathology\n",
      "1 chest xray\n",
      "1 diabetic retinopathy\n",
      "1 referring expression comprehension\n",
      "1 referring expression segmentation\n",
      "1 criminal justice\n",
      "1 dynamic mechanism design\n",
      "1 automated mechanism design\n",
      "1 unbalanced optimal transport\n",
      "1 penalized linear regression\n",
      "1 mm algorithms\n",
      "1 meijer-g\n",
      "1 production systems\n",
      "1 attention-based sparse entity interactions\n",
      "1 knowledge factorization\n",
      "1 over-smoothing issue\n",
      "1 networks with heterophily\n",
      "1 theoretical guarantee\n",
      "1 neural architecture design\n",
      "1 continued fractions\n",
      "1 bayesian statistics\n",
      "1 probabilistic numerical methods\n",
      "1 numerical analysis\n",
      "1 contraction theory\n",
      "1 robust neural networks.\n",
      "1 sparse representations\n",
      "1 sequential learning\n",
      "1 critical learning periods\n",
      "1 eigen decomposition\n",
      "1 epidemic forecasting\n",
      "1 deep probabilistic models\n",
      "1 extractive qa\n",
      "1 introspection\n",
      "1 privacy leakage\n",
      "1 ai security\n",
      "1 spatial robustness\n",
      "1 personalized models\n",
      "1 condorcet winner\n",
      "1 dvoretzky–kiefer–wolfowitz inequality\n",
      "1 optimization error\n",
      "1 tdc\n",
      "1 tracking error bound\n",
      "1 markovian noise\n",
      "1 garment reconstruction\n",
      "1 dynamic garment reconstruction\n",
      "1 point cloud sequence\n",
      "1 gcn\n",
      "1 dressed human modeling\n",
      "1 sequential games\n",
      "1 opponent exploitation\n",
      "1 scene text detection\n",
      "1 scene text recognition\n",
      "1 text instance representation\n",
      "1 episodic-learning\n",
      "1 analysis\n",
      "1 case-study\n",
      "1 switching dynamical systems\n",
      "1 explicit duration models\n",
      "1 max-k-cut\n",
      "1 gaussian sampling\n",
      "1 multi-layered perceptrons\n",
      "1 mouse visual cortex\n",
      "1 neural system identification\n",
      "1 noise correlations\n",
      "1 non-parametric classifiers\n",
      "1 large sample limit\n",
      "1 model-based planning\n",
      "1 structured objects\n",
      "1 computer-aided design\n",
      "1 pointers\n",
      "1 model explanation\n",
      "1 sample-based explanation\n",
      "1 representer point selection\n",
      "1 local jacobian taylor expansion\n",
      "1 ensemble models\n",
      "1 hardness of learning\n",
      "1 robust markov decision processing\n",
      "1 rectangular ambiguity sets\n",
      "1 recursive momentum\n",
      "1 design of experiments\n",
      "1 matrix tree theorem\n",
      "1 watershed\n",
      "1 random walker\n",
      "1 multilvel optimization\n",
      "1 gradient method\n",
      "1 non-convex stochastic optimization\n",
      "1 distirbutionally robust learning\n",
      "1 reversibility\n",
      "1 kernel attention\n",
      "1 graph regression\n",
      "1 graph prediction\n",
      "1 hyperedge prediction\n",
      "1 changepoint detection\n",
      "1 quickest change detection\n",
      "1 detection delay\n",
      "1 adaptive sensing\n",
      "1 nesterov\n",
      "1 euler-lagrange equations\n",
      "1 line search\n",
      "1 high probability\n",
      "1 complexity bound\n",
      "1 improper learning\n",
      "1 diplomacy\n",
      "1 super heavy-tailed payoffs\n",
      "1 hierarchical clustering\n",
      "1 graph algorithms\n",
      "1 structure preserving machine learning\n",
      "1 dissipative systems\n",
      "1 matrix recovery\n",
      "1 distribution-free inference\n",
      "1 humans and ai\n",
      "1 cognitive systems\n",
      "1 inductive programming\n",
      "1 occam's razor\n",
      "1 automatic differentiation\n",
      "1 using contexts of all arms\n",
      "1 an improved regret bound\n",
      "1 auprc\n",
      "1 generalization under weight perturbation\n",
      "1 weight perturbation\n",
      "1 bifurcations\n",
      "1 parameter inference\n",
      "1 recursive gradient estimator\n",
      "1 hessian vector computation\n",
      "1 opinion dynamics\n",
      "1 graph algorithm\n",
      "1 frequentist inference\n",
      "1 memory models\n",
      "1 content style separation\n",
      "1 compositional zero-shot learning\n",
      "1 prototypes\n",
      "1 independence\n",
      "1 3d registration\n",
      "1 shape matching\n",
      "1 ensembles\n",
      "1 dnn security\n",
      "1 dnn robustness\n",
      "1 learning aided algorithm design\n",
      "1 learning augmented online algorithms\n",
      "1 algorithms under uncertainty\n",
      "1 local descriptors\n",
      "1 non-rigid matching\n",
      "1 deformation\n",
      "1 spatial transformers\n",
      "1 weak labels\n",
      "1 neural differential equations\n",
      "1 stochastic hybrid systems\n",
      "1 newton sketch\n",
      "1 stochastic compositional optimization problem\n",
      "1 model-agnostic meta-learning\n",
      "1 articulated shape from videos\n",
      "1 nonrigid shape reconstruction\n",
      "1 goal-aware\n",
      "1 multi-target environment\n",
      "1 machine learning system\n",
      "1 gauge equivariance\n",
      "1 3d human motion\n",
      "1 future prediction\n",
      "1 high-dimensional robust statistics\n",
      "1 statistical query model\n",
      "1 traffic simulation\n",
      "1 causal effect identifiability\n",
      "1 policy search\n",
      "1 nlp applications\n",
      "1 adversarial robust models\n",
      "1 hierarchical clustering effect\n",
      "1 domain adaption tasks\n",
      "1 noisy gradient descent\n",
      "1 least squares regression\n",
      "1 fast and slow learning\n",
      "1 automatic machine learning\n",
      "1 automated graph neural network\n",
      "1 point cloud completion\n",
      "1 similarity metrics\n",
      "1 pruning criteria\n",
      "1 applicability\n",
      "1 convolutional filter\n",
      "1 weight distribution\n",
      "1 pareto front\n",
      "1 multi-objective learning\n",
      "1 inverse solutions\n",
      "1 multi-label learning\n",
      "1 pairwise relevance ordering\n",
      "1 unbiased estimator\n",
      "1 backward compatibility\n",
      "1 algorithm evaluation\n",
      "1 applications in computer vision\n",
      "1 multi-label ranking\n",
      "1 data pruning\n",
      "1 neural network training dynamics\n",
      "1 understanding deep learning\n",
      "1 gail\n",
      "1 bbvi\n",
      "1 divergences\n",
      "1 pre-asymptotics\n",
      "1 linear time-varying system\n",
      "1 predictive control\n",
      "1 sensitivity analysis\n",
      "1 continuous-and-bounded learning\n",
      "1 outliers\n",
      "1 dynamic setting\n",
      "1 linear regions of neural networks\n",
      "1 maxout units\n",
      "1 expected complexity\n",
      "1 decision boundary\n",
      "1 parameter initialisation\n",
      "1 stragglers\n",
      "1 adversaries\n",
      "1 voting rules\n",
      "1 social decision making\n",
      "1 spatial networks\n",
      "1 spatio-temporal reasoning\n",
      "1 object attention\n",
      "1 consciousness\n",
      "1 neuro-inspired ai\n",
      "1 artificial intelligence\n",
      "1 brain-inspired ai\n",
      "1 data-free quantization\n",
      "1 generative method\n",
      "1 boundary supporting samples\n",
      "1 billion-scale\n",
      "1 vector search\n",
      "1 inverted index solution\n",
      "1 inductive matrix completion\n",
      "1 nuclear norm regularisation\n",
      "1 video-language knowledge distillation\n",
      "1 video-text transfer\n",
      "1 autoregressive models\n",
      "1 integral probability metric\n",
      "1 separation\n",
      "1 harmonics\n",
      "1 legendre\n",
      "1 long-range dependencies\n",
      "1 implicit model\n",
      "1 neural decoding\n",
      "1 neural population activity\n",
      "1 convex functions\n",
      "1 strongly convex functions\n",
      "1 exponentially concave functions\n",
      "1 finite model theory\n",
      "1 homomorphism counts\n",
      "1 privacy preserving machine learning\n",
      "1 private inference\n",
      "1 stochastic relu\n",
      "1 mixtures of gaussians\n",
      "1 overparametrized neural networks\n",
      "1 robust mean estimation\n",
      "1 adaptivity constraint\n",
      "1 neural collapse\n",
      "1 low-dimensional model\n",
      "1 beyond eluder dimension\n",
      "1 neural net function approximation\n",
      "1 implicit fuction\n",
      "1 continous super-resolution\n",
      "1 screen content images\n",
      "1 transformations\n",
      "1 factors of variation\n",
      "1 proximal gradient descent for adaptive methods\n",
      "1 multiclass learning\n",
      "1 query-based video moment retrieval\n",
      "1 query-based video highlight detection\n",
      "1 beam search\n",
      "1 global optimal\n",
      "1 global attention distribution\n",
      "1 summarization\n",
      "1 distribution estimation\n",
      "1 sequential selection\n",
      "1 image segmentaion\n",
      "1 dynamic kernels\n",
      "1 pretraining and finetuning\n",
      "1 subgame solving\n",
      "1 common knowledge\n",
      "1 model interpretability\n",
      "1 reference distribution\n",
      "1 neighbourhood sampling\n",
      "1 fine-grained dataset\n",
      "1 cross-modal alignment\n",
      "1 re-initialization mechanism\n",
      "1 data programming\n",
      "1 optimisation for deep learning\n",
      "1 game playing\n",
      "1 goal-based learning\n",
      "1 information-theoretical bound\n",
      "1 optimal noise covariance\n",
      "1 vision-language pre-training\n",
      "1 inter-modality\n",
      "1 lm\n",
      "1 architecture search\n",
      "1 nas\n",
      "1 primer\n",
      "1 multi-facet clustering\n",
      "1 deep clustering\n",
      "1 decision graph\n",
      "1 few-shot image classification\n",
      "1 episodic\n",
      "1 3d detection\n",
      "1 lidar\n",
      "1 few-shot segmentation\n",
      "1 classifier-to-detector\n",
      "1 across tasks\n",
      "1 state representation learning\n",
      "1 auxiliary task\n",
      "1 inundation modeling\n",
      "1 physics-informed\n",
      "1 downsampling\n",
      "1 flood modeling\n",
      "1 parameter-compact fine-tuning methods\n",
      "1 adapters\n",
      "1 hypercomplex multiplication layers\n",
      "1 adapting large-scale language models\n",
      "1 multi arm bandit\n",
      "1 data poisoning attack\n",
      "1 tail performance\n",
      "1 ensemble methods\n",
      "1 neural representation for videos\n",
      "1 video denoising\n",
      "1 single time-scale stochastic approximation\n",
      "1 without-replacement sgd\n",
      "1 overconfidence\n",
      "1 accelerated gradient methods\n",
      "1 optimal methods\n",
      "1 stochastic bandits\n",
      "1 parallel computation\n",
      "1 graph centrality\n",
      "1 learning-driven scientific discovery\n",
      "1 learning physics systems\n",
      "1 operations research\n",
      "1 large scale optimization\n",
      "1 augmented lagrangian method\n",
      "1 locomotion control\n",
      "1 parameter freezing\n",
      "1 strategic regression\n",
      "1 effort accumulation\n",
      "1 oracle access optimization\n",
      "1 neural populations\n",
      "1 real-time\n",
      "1 visual system\n",
      "1 gaussian estimation\n",
      "1 tukey depth\n",
      "1 learning under triage\n",
      "1 human-ai collaboration\n",
      "1 weighted majority vote\n",
      "1 group elastic net\n",
      "1 function-on-scalar regression\n",
      "1 functional principal components\n",
      "1 augmented lagrangian\n",
      "1 byzantine attack\n",
      "1 continuous switching constraint\n",
      "1 barron norms\n",
      "1 gmrf\n",
      "1 gaussian processes regression\n",
      "1 linear constraints\n",
      "1 federated hyperparameter tuning\n",
      "1 distributed exploration\n",
      "1 coagent network\n",
      "1 emergent language\n",
      "1 referential games\n",
      "1 mid-level patches\n",
      "1 simple\n",
      "1 psd factorizations\n",
      "1 lee-seung's algorithm\n",
      "1 semidefinite optimization\n",
      "1 lieb's concavity theorem\n",
      "1 psd tensor factorization\n",
      "1 pre-trained models\n",
      "1 ising model\n",
      "1 least-squares\n",
      "1 last iterate\n",
      "1 non-parametric rates.\n",
      "1 modular architectures\n",
      "1 attention networks\n",
      "1 abstract reasoning\n",
      "1 systematic generalisation.\n",
      "1 barrier certificate\n",
      "1 training-time safety\n",
      "1 meta-gradients\n",
      "1 multi-objective rl\n",
      "1 rl safety\n",
      "1 safe policy improvement\n",
      "1 seldonian algorithms\n",
      "1 interpretable reinforcement learning\n",
      "1 mimic learning\n",
      "1 identifiable disentangling object encoder\n",
      "1 monte carlo regression tree search\n",
      "1 plug-and-play priors\n",
      "1 regularization by denoising\n",
      "1 generalized zero-shot learning\n",
      "1 progressive prototypes\n",
      "1 instance-dependent regret bounds\n",
      "1 gap-dependent\n",
      "1 indoor scene synthesis\n",
      "1 layout generation\n",
      "1 autoregressive set generation\n",
      "1 active touch\n",
      "1 active sensing\n",
      "1 3d perception\n",
      "1 width based planning\n",
      "1 planning and learning\n",
      "1 planning over simulators\n",
      "1 pac-bayesian\n",
      "1 social influence maximization\n",
      "1 robustess\n",
      "1 real-time data\n",
      "1 constant step size sgd\n",
      "1 clt\n",
      "1 novelty detection\n",
      "1 open-set recognition\n",
      "1 loss function search\n",
      "1 metric surrogate\n",
      "1 stein's method\n",
      "1 mcmc dynamics\n",
      "1 particle variational inference\n",
      "1 dqn\n",
      "1 policy improvement\n",
      "1 empirical analysis\n",
      "1 empirical method\n",
      "1 instance-specific explanations\n",
      "1 post-hoc interpretability\n",
      "1 feature attributions\n",
      "1 input gradients\n",
      "1 bayes classifiers\n",
      "1 safe learning and control\n",
      "1 constrained learning and control\n",
      "1 safety-critical tasks\n",
      "1 graph theory\n",
      "1 transducer\n",
      "1 alignment learning\n",
      "1 debiased representation\n",
      "1 neural delay differential equations\n",
      "1 partially observed systems\n",
      "1 time-delay systems\n",
      "1 stable system identification\n",
      "1 safe learning\n",
      "1 semialgebraic optimization\n",
      "1 robustness certification\n",
      "1 3d scene graph\n",
      "1 knowledge embedding\n",
      "1 abductive learning\n",
      "1 abduction\n",
      "1 symbolic learning\n",
      "1 neuro-symbolic learning\n",
      "1 gpfa\n",
      "1 neural data analysis\n",
      "1 training behavior\n",
      "1 dnn complexity\n",
      "1 lipschitz constants\n",
      "1 benevolent training hypothesis\n",
      "1 natural gradient\n",
      "1 multi-objective\n",
      "1 multi-grained explainability\n",
      "1 generative adversarial networks (gan)\n",
      "1 diversity in sample generation\n",
      "1 fair generative model\n",
      "1 minor attributes\n",
      "1 training dynamics\n",
      "1 statistics of log-density ratio\n",
      "1 weighted sampling for sgd.\n",
      "1 multi-head self-attention\n",
      "1 dot-product attention\n",
      "1 interactions\n",
      "1 masking\n",
      "1 gradients\n",
      "1 baselines\n",
      "1 reinforcement\n",
      "1 traffic\n",
      "1 object-centric\n",
      "1 network caching\n",
      "1 regret lower bounds\n",
      "1 abstention learning\n",
      "1 labeling\n",
      "1 gibbs algorithm\n",
      "1 information-theoretic bounds\n",
      "1 cortico-cerebellar loop\n",
      "1 cerebellar function\n",
      "1 decoupled neural interfaces\n",
      "1 locking problem\n",
      "1 temporal credit assignment\n",
      "1 bayesian test\n",
      "1 stein's methods\n",
      "1 representation learning on textual graph\n",
      "1 text mining\n",
      "1 relevance modeling\n",
      "1 superset learning\n",
      "1 credal sets\n",
      "1 label relaxation\n",
      "1 pseudo-labeling\n",
      "1 temporal logic\n",
      "1 synthesis\n",
      "1 circuits\n",
      "1 diffeomorphisms\n",
      "1 network architecture\n",
      "1 extensive-form game\n",
      "1 equilibrium refinement\n",
      "1 deep model acceleration\n",
      "1 trajectory prediction\n",
      "1 semantic correspondence\n",
      "1 cost aggregation\n",
      "1 visual correspondence\n",
      "1 tractable probabilistic models\n",
      "1 parameter regularization\n",
      "1 weisfeiler-lehman\n",
      "1 visual token\n",
      "1 problem-dependent analysis\n",
      "1 representation selection\n",
      "1 power sum functional\n",
      "1 minimax estimation\n",
      "1 interactive privacy mechanism\n",
      "1 non-interactive privacy mechanism\n",
      "1 plug-in estimator\n",
      "1 threshold estimation\n",
      "1 tabular datasets\n",
      "1 regularization cocktails\n",
      "1 combined algorithm selection and hyperparameter optimization.\n",
      "1 public goods games\n",
      "1 network games\n",
      "1 multi-agent systems\n",
      "1 maximal independent sets\n",
      "1 3d generative models\n",
      "1 drug design\n",
      "1 video captioning\n",
      "1 tree-structured decoding\n",
      "1 unpaired virtual try-on\n",
      "1 patch-routed warping\n",
      "1 compressed communication\n",
      "1 sparse tensors\n",
      "1 bloom filter\n",
      "1 3d shape reconstruction\n",
      "1 fast moving objects\n",
      "1 motion blur\n",
      "1 temporal super-resolution\n",
      "1 test-time optimization\n",
      "1 shape from blur\n",
      "1 vector autoregressive models\n",
      "1 dirty statistical models\n",
      "1 linear convergence rate\n",
      "1 non-asymptotic analysis\n",
      "1 image registration\n",
      "1 geometric transformations\n",
      "1 bounding box regression\n",
      "1 localization loss\n",
      "1 intersection over union\n",
      "1 statistical parity\n",
      "1 bandit optimization\n",
      "1 model misspecification\n",
      "1 zero-sum polymatrix games\n",
      "1 quantal response equilibria\n",
      "1 bounded rationality\n",
      "1 3d pose transfer\n",
      "1 correspondence learning\n",
      "1 conditional normalization\n",
      "1 prototypical classifier\n",
      "1 efficient dnns\n",
      "1 distributed systems\n",
      "1 theory rl\n",
      "1 marl\n",
      "1 overestimation\n",
      "1 compressed video\n",
      "1 motion vector\n",
      "1 umap\n",
      "1 t-sne\n",
      "1 non-linear dimension reduction\n",
      "1 recommender system\n",
      "1 multi-feedback\n",
      "1 multi-agent trajectory forecasting\n",
      "1 uncertainty analysis\n",
      "1 interaction modeling\n",
      "1 combinatorial multi-armed bandit (cmab)\n",
      "1 thompson sampling (ts)\n",
      "1 approximation oracle\n",
      "1 greedy oracle\n",
      "1 weekly supervised learning\n",
      "1 life-long learning\n",
      "1 hyper-parameter tuning\n",
      "1 hyper-parameter optimization\n",
      "1 energy-efficient algorithms\n",
      "1 power management\n",
      "1 ski rental\n",
      "1 interpretable\n",
      "1 rule set\n",
      "1 lifelong machine learning\n",
      "1 internal distribution\n",
      "1 multimodal output spaces\n",
      "1 conditional generative models\n",
      "1 combinatorial optimization algorithms\n",
      "1 rematerialization\n",
      "1 offloading\n",
      "1 checkpointing\n",
      "1 memory constraint\n",
      "1 feed forward backpropagation training\n",
      "1 riemannian gradient descent\n",
      "1 tight rate\n",
      "1 gap-free rate\n",
      "1 pomo\n",
      "1 matrix encoding\n",
      "1 traveling salesman problem\n",
      "1 flow shop problem\n",
      "1 bootstrapping\n",
      "1 covariance matrix\n",
      "1 nonlinear dimension reduction\n",
      "1 matrix factorisation\n",
      "1 isomap\n",
      "1 causal factor\n",
      "1 latent causal invariant model\n",
      "1 instrumental variable\n",
      "1 edge representation learning\n",
      "1 graph pooling\n",
      "1 graph neural architecture\n",
      "1 association\n",
      "1 theory of deep neural networks\n",
      "1 optimization for neural networks\n",
      "1 identity testing\n",
      "1 homomorphic encryption\n",
      "1 parameter-free\n",
      "1 visual recognition\n",
      "1 data imbalance\n",
      "1 long tail\n",
      "1 event cameras\n",
      "1 environment design\n",
      "1 poincar\\'{e} recurrence\n",
      "1 simplicial complexes\n",
      "1 cell complexes\n",
      "1 cw complexes\n",
      "1 simplicial neural networks\n",
      "1 end-to-end pre-training\n",
      "1 temporal action localization\n",
      "1 levy-prokhorov distance\n",
      "1 bottleneck matching\n",
      "1 unit disc graph matching\n",
      "1 drug trafficker detection\n",
      "1 perception-distortion tradeoff\n",
      "1 statistical estimation theory\n",
      "1 adversarial defences\n",
      "1 animal behavior\n",
      "1 behavioral videos\n",
      "1 model-based bayesian reinforcement learning\n",
      "1 risk\n",
      "1 subsetwise\n",
      "1 contextual\n",
      "1 neighborhood graph\n",
      "1 few-shot regression\n",
      "1 learning rate\n",
      "1 step size\n",
      "1 dynamical system\n",
      "1 safe screening\n",
      "1 filter pruning\n",
      "1 channel pruning\n",
      "1 3d scenes\n",
      "1 3d from x\n",
      "1 multiagent learning\n",
      "1 starcraft\n",
      "1 sparse regularisation\n",
      "1 basis pursuit\n",
      "1 iterative reweighted least squares\n",
      "1 bilevel\n",
      "1 hidden state\n",
      "1 audio-visual video parsing\n",
      "1 weakly-supervised learning\n",
      "1 vision applications and systems\n",
      "1 regular surface recosntruction\n",
      "1 cortical surface reconstruction\n",
      "1 multi-agent policy gradients\n",
      "1 symmetric positive definite\n",
      "1 affine-invariant\n",
      "1 non-negative curvature\n",
      "1 kernel mean embedding\n",
      "1 stochastic process\n",
      "1 filtration\n",
      "1 maximum mean discrepancy\n",
      "1 signature transform.\n",
      "1 interactive theorem proving\n",
      "1 hol4\n",
      "1 dual learning\n",
      "1 stylized dialogue generation\n",
      "1 tcfc\n",
      "1 sdgc\n",
      "1 adaptive algorithms\n",
      "1 tabular data synthesis\n",
      "1 fake data\n",
      "1 diffusion approximation\n",
      "1 distribution of arm-pulls\n",
      "1 filtering\n",
      "1 open-world extrapolation\n",
      "1 feature embedding learning\n",
      "1 accountability\n",
      "1 blame attribution\n",
      "1 multi-agent decision making\n",
      "1 high dimensional\n",
      "1 statistical inference\n",
      "1 deep bayesian bandits\n",
      "1 random graph\n",
      "1 universality\n",
      "1 over-parametrized neural network\n",
      "1 protein contact prediction\n",
      "1 co-evolution principle\n",
      "1 active estimation\n",
      "1 interpolation learning\n",
      "1 uniform convergence\n",
      "1 dependent arms\n",
      "1 relu neural networks\n",
      "1 depth bounds\n",
      "1 polyhedral methods\n",
      "1 mixed-integer optimization\n",
      "1 consensus\n",
      "1 gordon comparison theorem\n",
      "1 robust mdps\n",
      "1 sleeping\n",
      "1 data efficient training\n",
      "1 task-free continual learning\n",
      "1 memory-based continual learning\n",
      "1 last-iterate convergence\n",
      "1 extensive-form games\n",
      "1 game dynamics\n",
      "1 temporal graphs\n",
      "1 goal-conditioned reinforcement learning\n",
      "1 block mdp\n",
      "1 cross-modality\n",
      "1 nonconvex nonsmooth optimization\n",
      "1 smoothing\n",
      "1 approximation scheme\n",
      "1 matrix permanent\n",
      "1 practice\n",
      "1 rejection sampling\n",
      "1 gaussian mixture models\n",
      "1 robust recovery\n",
      "1 rank overspecification\n",
      "1 curriculum\n",
      "1 autonomous learning\n",
      "1 reset-free reinforcement learning\n",
      "1 person identification\n",
      "1 forensics\n",
      "1 polynomial-time algorithms\n",
      "1 query learning\n",
      "1 model extraction\n",
      "1 learning from passive videos\n",
      "1 visual semantic planning\n",
      "1 interaction exploration\n",
      "1 object interaction\n",
      "1 egocentric video\n",
      "1 human activity understanding\n",
      "1 k-nearest neighbors\n",
      "1 voronoi diagram\n",
      "1 uncertainty based method\n",
      "1 diversity base method\n",
      "1 sequence-to-sequence text generation\n",
      "1 rule execution tracking\n",
      "1 pre-trained transformer-based language models\n",
      "1 bayes error\n",
      "1 noisy supervision\n",
      "1 visual question generation\n",
      "1 probability discrepancy measure\n",
      "1 controlling neural networks\n",
      "1 incorporating rules\n",
      "1 unsupervised adaptation\n",
      "1 explaining deep neural networks\n",
      "1 perturbation based explanations\n",
      "1 graph machine learning\n",
      "1 minibatch\n",
      "1 optimistic\n",
      "1 collective graphical model\n",
      "1 aggregated data\n",
      "1 dc algorithm\n",
      "1 minimum cost flow\n",
      "1 multi-view\n",
      "1 direct\n",
      "1 camera ray\n",
      "1 multi-area computation\n",
      "1 multi-modal learning theory\n",
      "1 learning rules\n",
      "1 hyperparameters\n",
      "1 rnn dynamics\n",
      "1 biological models\n",
      "1 implicit likelihood\n",
      "1 marginal posterior\n",
      "1 likelihood-to-evidence ratio estimation\n",
      "1 neural ratio estimation\n",
      "1 empirically testable inference\n",
      "1 positional embedding\n",
      "1 data release\n",
      "1 availability attack\n",
      "1 sparse generalized eigenvalue problem\n",
      "1 perturbation\n",
      "1 penalization\n",
      "1 compositional generation\n",
      "1 growth\n",
      "1 training neural network\n",
      "1 geometric search\n",
      "1 noise contrastive estimation\n",
      "1 molecular conformation generation\n",
      "1 neural scene presentation\n",
      "1 3d human modeling\n",
      "1 character animation\n",
      "1 stackelberg equilibria\n",
      "1 general-sum games\n",
      "1 multi-agent rl\n",
      "1 3d filter decomposition\n",
      "1 efficient learning\n",
      "1 gym\n",
      "1 ngram extraction\n",
      "1 visual search\n",
      "1 asymmetry\n",
      "1 recognition\n",
      "1 eye movement\n",
      "1 psychophyiscs\n",
      "1 human behavior\n",
      "1 visual cognition\n",
      "1 natural statistics\n",
      "1 online decision making\n",
      "1 energy landscape\n",
      "1 action poisoning\n",
      "1 black-box attack.\n",
      "1 non-linear dynamical systems\n",
      "1 learning with dependent data\n",
      "1 linear system identification\n",
      "1 optical neural networks\n",
      "1 on-chip learning\n",
      "1 efficient training\n",
      "1 hardware-software co-design\n",
      "1 imbalanced data learning\n",
      "1 rare-event modeling\n",
      "1 bounded arm-memory\n",
      "1 kl-divergence\n",
      "1 hoeffding's inequality\n",
      "1 jensen inequality\n",
      "1 homology embedding\n",
      "1 hodge laplacian\n",
      "1 3d point cloud processing\n",
      "1 contextual stochastic optimization\n",
      "1 blackbox explanations\n",
      "1 provable guarantees\n",
      "1 ensemble attack\n",
      "1 universal perturbation\n",
      "1 quality diversity optimization\n",
      "1 latent space exploration\n",
      "1 deformable butterfly\n",
      "1 linear transform\n",
      "1 game-theoretic interaction\n",
      "1 online classification\n",
      "1 low-rank matrix estimation\n",
      "1 panel data\n",
      "1 theoretical reinforcement learning\n",
      "1 non-markovian rewards\n",
      "1 local validity\n",
      "1 prediction interval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 coarse correlated equilibrium\n",
      "1 optimistic hedge\n",
      "1 offpolicy\n",
      "1 diffusion algorithm\n",
      "1 local graph clustering\n",
      "1 robust control\n",
      "1 nonconvex-nonconcave optimization\n",
      "1 maximal inequality\n",
      "1 metric entropy\n",
      "1 empirical process theory\n",
      "1 context agnostic learning\n",
      "1 hybrid\n",
      "1 latent flow\n",
      "1 optimization with noise\n",
      "1 convex interpolation\n",
      "1 certifiable training\n",
      "1 euclidean geometry\n",
      "1 gradient norm\n",
      "1 small gradients\n",
      "1 making gradients small\n",
      "1 ogm\n",
      "1 fista\n",
      "1 ogm-g\n",
      "1 potential function-based\n",
      "1 lyapunov analysis\n",
      "1 complexity bounds\n",
      "1 test-time adaptation\n",
      "1 sensory neuroscience\n",
      "1 systems identification\n",
      "1 goal-driven models\n",
      "1 vision neuroscience\n",
      "1 tiny deep learning\n",
      "1 tinyml\n",
      "1 neighbor sampling\n",
      "1 combinatorial pure exploration\n",
      "1 bottleneck reward function\n",
      "1 cascaded networks\n",
      "1 anytime prediction\n",
      "1 parallel networks\n",
      "1 biologically inspired computing\n",
      "1 speed-accuracy trade off\n",
      "1 temporal difference methods\n",
      "1 bellman eluder dimension\n",
      "1 sum product networks\n",
      "1 discrete density estimation\n",
      "1 approximation theorem\n",
      "1 query release\n",
      "1 relative positional encoding\n",
      "1 fast fourier transform\n",
      "1 language pre-training\n",
      "1 temporal specifications\n",
      "1 hierarchical learning\n",
      "1 dynamic algorithms\n",
      "1 polynomial time algorithms\n",
      "1 learning relu networks\n",
      "1 lower confidence bound (lcb)\n",
      "1 kernel regression\n",
      "1 bures-wasserstein barycenter\n",
      "1 dimension-free convergence\n",
      "1 entropic regularization\n",
      "1 geometric median\n",
      "1 data assimilation\n",
      "1 self-supervised denoising\n",
      "1 model averaging\n",
      "1 low-data setting\n",
      "1 lookahead\n",
      "1 excess risk error\n",
      "1 deep learning optimization\n",
      "1 deep learning generalization\n",
      "1 cooperative compression\n",
      "1 online distillation\n",
      "1 gradual change\n",
      "1 rationalization\n",
      "1 interlocking\n",
      "1 cooperative game\n",
      "1 model explainability\n",
      "1 science of machine learning\n",
      "1 reproducibility\n",
      "1 visual representations\n",
      "1 topology imbalance learning\n",
      "1 distributed computing\n",
      "1 lista\n",
      "1 graph structure learning\n",
      "1 multi-source-free domain adaptation\n",
      "1 time series imputation\n",
      "1 score-based diffusion models\n",
      "1 perturbation theory\n",
      "1 strong data processing inequality\n",
      "1 multimodal transformers\n",
      "1 non i.i.d.\n",
      "1 vector graphics\n",
      "1 computational statistics\n",
      "1 social recommendation\n",
      "1 secure machine learning\n",
      "1 pir\n",
      "1 robust pca\n",
      "1 deep unfolding\n",
      "1 video background subtraction\n",
      "1 ultrasound imaging\n",
      "1 joint representation\n",
      "1 flow model\n",
      "1 entropy coder\n",
      "1 transferability estimation\n",
      "1 accessibility\n",
      "1 autocorrelation\n",
      "1 3d animal pose and shape estimation\n",
      "1 coarse-to-fine approach\n",
      "1 batch reinforcement learning\n",
      "1 overestimation bias\n",
      "1 generalization gap\n",
      "1 liquid state machine\n",
      "1 astrocytes\n",
      "1 neuron-astrocyte networks\n",
      "1 stdp\n",
      "1 self organized criticality\n",
      "1 capped simplex\n",
      "1 sparse regression via boolean relaxation\n",
      "1 orthogonal polynomials\n",
      "1 learning-augmented algorithm\n",
      "1 pareto-optimality\n",
      "1 online conversion problem\n",
      "1 efficient inference methods\n",
      "1 sparsification\n",
      "1 extreme multi-label text classification\n",
      "1 neural network priors\n",
      "1 infinite width limits\n",
      "1 dynamics adaptation\n",
      "1 sim2real\n",
      "1 tensor completion\n",
      "1 nonparametric learning\n",
      "1 bi-level programming\n",
      "1 gradient-based method\n",
      "1 asymptotic convergence\n",
      "1 data hyper-cleaning\n",
      "1 matrix-valued weighted graph\n",
      "1 multi-agent perception\n",
      "1 program induction\n",
      "1 program understanding and generation\n",
      "1 programming by example\n",
      "1 matrix/tensor estimation\n",
      "1 continuous-time neural networks\n",
      "1 continuous-depth models\n",
      "1 neural network fine-tuning\n",
      "1 hanabi\n",
      "1 temporal integration\n",
      "1 receptive field\n",
      "1 timescale\n",
      "1 black box variational inference\n",
      "1 amortized variational inference\n",
      "1 scalable variational inference\n",
      "1 structured variational inference\n",
      "1 gaussian vi\n",
      "1 market equilibrium\n",
      "1 adaptive inference\n",
      "1 jl projections\n",
      "1 per-sample gradients\n",
      "1 polyak-lojasiewicz inequality\n",
      "1 lloyd's algorithm\n",
      "1 deep leakage from gradients\n",
      "1 random initialization\n",
      "1 classification with a reject option\n",
      "1 linear sems\n",
      "1 potential outcomes\n",
      "1 hilbert-schmidt independence criterion\n",
      "1 nonlinear synaptic plasticity\n",
      "1 bayesian rl\n",
      "1 average-case\n",
      "1 hyperbolic\n",
      "1 hierarchy\n",
      "1 unsupervised segmentation\n",
      "1 biomedical\n",
      "1 protein design\n",
      "1 shift invariance\n",
      "1 unsupervised-learning\n",
      "1 invexity\n",
      "1 primal dual witness method\n",
      "1 information constraints\n",
      "1 local privacy\n",
      "1 random coordinate descent\n",
      "1 sparse inference\n",
      "1 contextual bandit algorithms\n",
      "1 differentiable algorithms\n",
      "1 algorithmic supervision\n",
      "1 continuous relaxation\n",
      "1 perturbed\n",
      "1 smooth\n",
      "1 sorting\n",
      "1 gradient-based\n",
      "1 gradient degradation\n",
      "1 forward-mode differentiation\n",
      "1 temporal point processes\n",
      "1 event data\n",
      "1 hamiltonian dynamics\n",
      "1 odes\n",
      "1 surrogate objective\n",
      "1 soft constraint\n",
      "1 quadratic programming\n",
      "1 pareto frontier\n",
      "1 human-machine\n",
      "1 human-ai\n",
      "1 human-in-the-loop\n",
      "1 local polytope\n",
      "1 l-katyusha\n",
      "1 evaluation of interpretability\n",
      "1 feature visualization\n",
      "1 activation maximization\n",
      "1 human psychophysics\n",
      "1 understanding cnns\n",
      "1 explanation method\n",
      "1 causal understanding\n",
      "1 perfect simulation\n",
      "1 3d pose estimation\n",
      "1 analysis-by-synthesis.\n",
      "1 low-rank matrix factorization\n",
      "1 uniformity testing\n",
      "1 task groupings\n",
      "1 which tasks should train together\n",
      "1 pre-trained language models\n",
      "1 passive-aggressive updates\n",
      "1 qcqp\n",
      "1 graph similarity computation\n",
      "1 efficient model\n",
      "1 configurable mdp\n",
      "1 transition\n",
      "1 displacement interpolation\n",
      "1 simplex random walk\n",
      "1 state space\n",
      "1 dynamical model\n",
      "1 human activity recognition\n",
      "1 spiking network\n",
      "1 optimal decision making\n",
      "1 physics-integrated machine learning\n",
      "1 gray-box modeling\n",
      "1 hybrid modeling\n",
      "1 experimentation\n",
      "1 agnostic statistics\n",
      "1 debiased machine learning\n",
      "1 semiparametrics\n",
      "1 experiment splitting\n",
      "1 model optimizability\n",
      "1 mixed-effect model\n",
      "1 disease progression modelling\n",
      "1 longitudinal data\n",
      "1 multi-component floating-point\n",
      "1 natural language processing (nlp)\n",
      "1 generative language models\n",
      "1 gpt\n",
      "1 occupations\n",
      "1 intersections\n",
      "1 joint neural architecture search and quantization\n",
      "1 mixed-precision quantization\n",
      "1 hamiltonian\n",
      "1 continual dynamics\n",
      "1 hamiltonian generative networks\n",
      "1 object-centric representations\n",
      "1 latent dynamical systems\n",
      "1 decoding\n",
      "1 neural alignment\n",
      "1 across-animal neural analysis\n",
      "1 optimal order simple regret\n",
      "1 discrete probabilistic models\n",
      "1 continuous-time markov chains\n",
      "1 cancer genomics\n",
      "1 self concordance\n",
      "1 iterated tikhonov\n",
      "1 proximal point\n",
      "1 langevin mcmc\n",
      "1 mirror-langevin\n",
      "1 mesh-based model\n",
      "1 conditional parameterization\n",
      "1 computational physics\n",
      "1 selective sampling\n",
      "1 theoretical guarantees\n",
      "1 rényi differential privacy\n",
      "1 adaptive composition\n",
      "1 privacy filter\n",
      "1 deep latent variable model\n",
      "1 cevae\n",
      "1 single image generation\n",
      "1 generalized linear models\n",
      "1 synchrony\n",
      "1 orthogonal matching pursuit\n",
      "1 high-dimensional inference\n",
      "1 high-cardinality\n",
      "1 categorical features\n",
      "1 random effects\n",
      "1 mixed effects\n",
      "1 general constraints\n",
      "1 pessimistic-optimistic algorithm\n",
      "1 statistical downscaling\n",
      "1 spatial disaggregation\n",
      "1 deconditioning\n",
      "1 conditional mean embeddings\n",
      "1 conditional expectation\n",
      "1 two-stage regression\n",
      "1 discretization of sde\n",
      "1 optimisation\n",
      "1 sequential\n",
      "1 strongly convex\n",
      "1 logarithmic\n",
      "1 pseudoregret\n",
      "1 expected regret\n",
      "1 curvature\n",
      "1 sequence matching\n",
      "1 instructional videos\n",
      "1 step localization\n",
      "1 distributed machine learning\n",
      "1 heterogeneous data\n",
      "1 federated machine learning\n",
      "1 variational learning\n",
      "1 linear stability\n",
      "1 sobolev seminorm\n",
      "1 maximum mean discrepancy (mmd)\n",
      "1 neural tangent kernel (ntk)\n",
      "1 two-sample test\n",
      "1 change-point detection\n",
      "1 latent\n",
      "1 exampled-based\n",
      "1 explanation\n",
      "1 feature-based\n",
      "1 importance\n",
      "1 mask classification\n",
      "1 besov space\n",
      "1 spectral embedding\n",
      "1 selective prediction\n",
      "1 attacking uncertainty estimation\n",
      "1 self-supervised representation learning\n",
      "1 unsupervised accuracy estimation\n",
      "1 error detection\n",
      "1 self-training ensembles\n",
      "1 theory of clustering\n",
      "1 clustering in metric spaces\n",
      "1 convex hulls\n",
      "1 clustering stability\n",
      "1 same-cluster queries\n",
      "1 code\n",
      "1 obfuscation\n",
      "1 programming languages\n",
      "1 deobfuscation\n",
      "1 ml for code\n",
      "1 ml for programming languages\n",
      "1 event camera\n",
      "1 optical flow\n",
      "1 multilingual pre-trained language model\n",
      "1 universal syntactic dependency parsing\n",
      "1 memory augmented recurrent neural networks\n",
      "1 fast weight programmers\n",
      "1 early exit\n",
      "1 model acceleration\n",
      "1 off-policy multi-step td-learning\n",
      "1 generalized bellman operator\n",
      "1 contraction mapping\n",
      "1 image and video synthesis\n",
      "1 limited data\n",
      "1 discriminator overfitting\n",
      "1 descriptors\n",
      "1 deep-features\n",
      "1 iqa\n",
      "1 image-restoration\n",
      "1 motion-deblurring\n",
      "1 probabilistic computation\n",
      "1 wake-sleep\n",
      "1 bandit algorithms\n",
      "1 surrogate losses\n",
      "1 normalized maximum likelihood\n",
      "1 laplacian score\n",
      "1 neural representation\n",
      "1 participating media\n",
      "1 volume rendering\n",
      "1 relighting\n",
      "1 conditional image synthesis\n",
      "1 multi-modal control\n",
      "1 neural flow\n",
      "1 perception\n",
      "1 encoding-decoding models\n",
      "1 efficient coding\n",
      "1 bayesian mean\n",
      "1 perceptual biases\n",
      "1 average precision\n",
      "1 differentiability\n",
      "1 decomposability\n",
      "1 annotation\n",
      "1 training data\n",
      "1 dynamic neural representation\n",
      "1 cad\n",
      "1 rotational invariance\n",
      "1 bessel functions\n",
      "1 bessel-convolutional neural networks\n",
      "1 direct feedback alignment\n",
      "1 optical computing\n",
      "1 alternative training methods\n",
      "1 histograms\n",
      "1 skewed data.\n",
      "1 instance-dependent bounds.\n",
      "1 debugging\n",
      "1 testing\n",
      "1 test input prioritization\n",
      "1 bayesian dynamical matrix factorization\n",
      "1 functional mri (fmri)\n",
      "1 graph convolutional network\n",
      "1 fine-grained image retrieval\n",
      "1 large-scale data\n",
      "1 attribute-aware\n",
      "1 dynamic bottleneck\n",
      "1 topographic organization\n",
      "1 split learning\n",
      "1 zero-order optimization\n",
      "1 uncertainty-driven loss\n",
      "1 single image super-resolution\n",
      "1 ideal prototype\n",
      "1 imbalanced data\n",
      "1 rare events data\n",
      "1 optimal sampling\n",
      "1 multi-label active learning\n",
      "1 bayesian bernoulli mixture\n",
      "1 label correlation\n",
      "1 graphical model\n",
      "1 latent trees\n",
      "1 arbitrary corruptions\n",
      "1 meg\n",
      "1 shared response modeling\n",
      "1 component analysis\n",
      "1 lévy flights\n",
      "1 neural adaptation\n",
      "1 attractor neural networks\n",
      "1 information searching\n",
      "1 free memory retrieval\n",
      "1 zero-shot understanding\n",
      "1 reference games\n",
      "1 mixed-integer programming\n",
      "1 rectified linear activation\n",
      "1 autorl\n",
      "1 population based training\n",
      "1 hybrid processes\n",
      "1 continuous time\n",
      "1 markov jump processes\n",
      "1 bnn\n",
      "1 safety verification\n",
      "1 control as inference\n",
      "1 inference-based reinforcement learning\n",
      "1 policy updates\n",
      "1 adversarial regression\n",
      "1 kernel weighted regression\n",
      "1 covariate perturbation\n",
      "1 distributional robust\n",
      "1 doubly non-negative matrices\n",
      "1 log-determinant divergence\n",
      "1 low-sample-size problem\n",
      "1 n:m sparsity\n",
      "1 pruning.\n",
      "1 ode\n",
      "1 stable\n",
      "1 facial expression recognition\n",
      "1 snn\n",
      "1 spike-based backpropagation\n",
      "1 debugger\n",
      "1 3d meshes\n",
      "1 non-rigid\n",
      "1 structure from template\n",
      "1 structure from motion\n",
      "1 learnable optimization\n",
      "1 symmetric spaces\n",
      "1 spd space\n",
      "1 spd manifold\n",
      "1 symmetric positive definite matrices\n",
      "1 spd\n",
      "1 rotations\n",
      "1 reflections\n",
      "1 translations\n",
      "1 gyro vector\n",
      "1 gyro calculus\n",
      "1 gyro groups\n",
      "1 gyrocalculus\n",
      "1 tangent space optimization\n",
      "1 non euclidean optimization\n",
      "1 matrix models\n",
      "1 non-euclidean geometry\n",
      "1 finsler metrics\n",
      "1 finsler distance\n",
      "1 finsler geometry\n",
      "1 vector valued distance\n",
      "1 vector valued distance function\n",
      "1 riemannian manifold learning\n",
      "1 knowledge graph embeddings\n",
      "1 item recommendations\n",
      "1 human mobility\n",
      "1 poi prediction\n",
      "1 contrastive predictive coding\n",
      "1 random search\n",
      "1 derivative-free\n",
      "1 saddle\n",
      "1 queuing systems\n",
      "1 one-armed bandits\n",
      "1 time allocation\n",
      "1 neural topic model\n",
      "1 adversarial-neural topic model\n",
      "1 psychophysics\n",
      "1 machine vision\n",
      "1 human vision\n",
      "1 out-of-distribution generalisation\n",
      "1 human behaviour\n",
      "1 cross-view geo-localization\n",
      "1 bfs\n",
      "1 seasonality\n",
      "1 nonsmooth algorithmic differentiation\n",
      "1 numerical precision\n",
      "1 conservative fields\n",
      "1 network width\n",
      "1 invariant learning\n",
      "1 latent heterogeneity\n",
      "1 single neuron\n",
      "1 polynomial expansions\n",
      "1 polynomial neural networks\n",
      "1 unseen combinations\n",
      "1 conditional data generation\n",
      "1 implicit differentiation\n",
      "1 algorithmic differentiation\n",
      "1 conservative fields.\n",
      "1 anderson mixing\n",
      "1 nonconvex stochastic optimization\n",
      "1 user-level privacy\n",
      "1 global stability\n",
      "1 representation dimension\n",
      "1 correlated sampling\n",
      "1 replay buffer\n",
      "1 stylized face synthesis\n",
      "1 arbitrary style transfer\n",
      "1 mirror samples\n",
      "1 mirror loss\n",
      "1 anti-backdoor learning\n",
      "1 ranking from comparisons\n",
      "1 duelling bandits\n",
      "1 graph attentions\n",
      "1 reward-free exploration\n",
      "1 model based rl\n",
      "1 transformation equivariance\n",
      "1 bandit theory\n",
      "1 deep reinforcement learning theory\n",
      "1 sequential rademacher complexity\n",
      "1 backpropagation with constraints\n",
      "1 weight quantization\n",
      "1 pseudo-lagrange multiplier method\n",
      "1 balancedness\n",
      "1 dynamic pricing\n",
      "1 adversarial features\n",
      "1 affine invariant\n",
      "1 distribution-free.\n",
      "1 homophily assumption\n",
      "1 propagation mechanism\n",
      "1 interpretation\n",
      "1 decision logic\n",
      "1 pseudo labeling\n",
      "1 consistency regularization\n",
      "1 capsule network\n",
      "1 motion representation\n",
      "1 skeleton-based action recognition\n",
      "1 influence maximization\n",
      "1 dynamic algorithm\n",
      "1 implicit semantic discovery\n",
      "1 feature-level weighting schema\n",
      "1 semantic alignment\n",
      "1 sample-efficiency\n",
      "1 model confidentiality\n",
      "1 dnn poisoning\n",
      "1 model ip protection\n",
      "1 data-free distillation\n",
      "1 natural policy gradient\n",
      "1 pessimism\n",
      "1 linear value functions\n",
      "1 teaching dimension\n",
      "1 learning-with-equivalence-queries\n",
      "1 best-case teacher\n",
      "1 education\n",
      "1 symbolic reasoning\n",
      "1 constrained clustering\n",
      "1 weight initialization\n",
      "1 normalizer-free\n",
      "1 message passing\n",
      "1 stability analysis\n",
      "1 sequential data modeling\n",
      "1 long-term dependencies\n",
      "1 asymptotic normality\n",
      "1 posterior consistency\n",
      "1 prior annealing\n",
      "1 structure selection\n",
      "1 near-field and far-field decomposition\n",
      "1 fast multipole method\n",
      "1 binary connect\n",
      "1 generalized conditional gradient\n",
      "1 proximal connect\n",
      "1 alternating least squares\n",
      "1 price of stability\n",
      "1 cooperative game theory\n",
      "1 hedonic game theory\n",
      "1 shuffle model\n",
      "1 re-ranking\n",
      "1 action elimination\n",
      "1 explore-then-commit\n",
      "1 hybrid model\n",
      "1 expert-designed ode\n",
      "1 label-free data alignment\n",
      "1 procrustes analysis\n",
      "1 batch correction\n",
      "1 axis-aligned rectangles\n",
      "1 taylor’s approximations\n",
      "1 inverse optimal control\n",
      "1 signal-dependent noise\n",
      "1 feedback connections\n",
      "1 equilibrium state\n",
      "1 training method\n",
      "1 semi-supervised object detection\n",
      "1 k-median clustering\n",
      "1 constant approximation\n",
      "1 interpretable classification\n",
      "1 polarization-based image dehazing\n",
      "1 attention-guided mask strategy\n",
      "1 model smoothing\n",
      "1 student-teacher framework\n",
      "1 self-supervised image denoising\n",
      "1 tweedie's formula\n",
      "1 the score function\n",
      "1 noises from general exponential family\n",
      "1 multi-fidelity bayesian optimization\n",
      "1 batch acquisition function\n",
      "1 full auto-regressive modeling\n",
      "1 multi-fidelity max-value entropy search\n",
      "1 ordinary differential equations\n",
      "1 local elasticity\n",
      "1 architectures\n",
      "1 efficientnet\n",
      "1 vit\n",
      "1 dudley distance\n",
      "1 empirical process\n",
      "1 xformers\n",
      "1 additive models\n",
      "1 bayesian bandits\n",
      "1 bayesian decision making\n",
      "1 system-level evaluation\n",
      "1 model compatibility\n",
      "1 error decomposition\n",
      "1 invertible\n",
      "1 densenets\n",
      "1 max-min optimization framework\n",
      "1 utility theory\n",
      "1 saliency detection\n",
      "1 weakly supervised rgb-d salient object detection\n",
      "1 artistic style transfer\n",
      "1 internal-external learning\n",
      "1 quality\n",
      "1 conditional coverage\n",
      "1 step-decay step-size\n",
      "1 non-asymptotic convergence\n",
      "1 shape representation\n",
      "1 poisson equation\n",
      "1 alpha-divergence\n",
      "1 entropic mirror descent\n",
      "1 r\\'{e}nyi's alpha-divergence\n",
      "1 tucker rank\n",
      "1 mean-field theory\n",
      "1 information geometry\n",
      "1 multi-scale vision transformer\n",
      "1 computation efficient\n",
      "1 talking head\n",
      "1 spatial attention\n",
      "1 adaptive equalization learning\n",
      "1 blind kernel estimation\n",
      "1 no-reference\n",
      "1 speech quality\n",
      "1 program-guided tasks\n",
      "1 learning to execute\n",
      "1 program-guided agent\n",
      "1 neural symbolic reasoning\n",
      "1 community recovery\n",
      "1 graph matching\n",
      "1 correlated random graphs\n",
      "1 information-theoretic limits\n",
      "1 multi-object tracking\n",
      "1 training stability\n",
      "1 classification and regression trees (cart)\n",
      "1 recursive dyadic partitions\n",
      "1 piecewise constant signals\n",
      "1 partition recovery\n",
      "1 sequential vae\n",
      "1 multi-stage matching\n",
      "1 decentralized markets\n",
      "1 uncertain preference\n",
      "1 college admissions\n",
      "1 neural operators\n",
      "1 multiwavelet transform\n",
      "1 data-efficient gan training\n",
      "1 the lottery tickets hypothesis\n",
      "1 data and architecture sparse co-training\n",
      "1 path planning\n",
      "1 latent discovery\n",
      "1 bayesian network\n",
      "1 removable variable\n",
      "1 recursive structure learning\n",
      "1 vehicle routing problems\n",
      "1 reverse-complement\n",
      "1 video synthesis\n",
      "1 multimodal generative modeling\n",
      "1 vector-quantized generative adversarial networks\n",
      "1 diffusion model\n",
      "1 hierarchical vae\n",
      "1 variational lower bound\n",
      "1 random feature model\n",
      "1 epoch-wise double descent\n",
      "1 random matrix\n",
      "1 linear pencil\n",
      "1 cauchy integrals\n",
      "1 high-dimensional limits\n",
      "1 stieltjes transform\n",
      "1 gradient\n",
      "1 multi-label classification\n",
      "1 probabilistic numerics\n",
      "1 neuromorphic\n",
      "1 surrogate gradient descent\n",
      "1 categorical\n",
      "1 self distillation\n",
      "1 active\n",
      "1 contrastive\n",
      "1 free\n",
      "1 energy\n",
      "1 bias mitigation\n",
      "1 language model behavior\n",
      "1 approximative inference\n",
      "1 self-supervsied learning\n",
      "1 risk measures\n",
      "1 two-step task\n",
      "1 time-consistency\n",
      "1 anxiety\n",
      "1 automatic hyperparameter scheduling\n",
      "1 molecular representation\n",
      "1 molecular fingerprints\n",
      "1 neural molecular dynamics\n",
      "1 monocular 3d detection\n",
      "1 progressive coordinate transform\n",
      "1 feature fusion\n",
      "1 network models\n",
      "1 thresholding bandits\n",
      "1 smoothed online learning\n",
      "1 competitive ratio\n",
      "1 dynamic regret with switching cost\n",
      "1 polyhedral functions\n",
      "1 quadratic growth functions\n",
      "1 knowledge distillation； object detection\n",
      "1 mlp-mixer\n",
      "1 connectome\n",
      "1 event memory\n",
      "1 image memorability\n",
      "1 visual semantics\n",
      "1 lifelog\n",
      "1 damain adaptation\n",
      "1 label shift\n",
      "1 density-ratio estimation\n",
      "1 relative density-ratio estimation\n",
      "1 large batch training\n",
      "1 large cohort training\n",
      "1 sliced mutual information\n",
      "1 feature extraction\n",
      "1 independence tests\n",
      "1 multidimensional scaling\n",
      "1 score-based models\n",
      "1 denoising diffusion probabilistic models\n",
      "1 human-ai teaming\n",
      "1 explainable planning\n",
      "1 navigation under uncertainty\n",
      "1 explainable artificial intelligence (xai)\n",
      "1 soft-argmax\n",
      "1 probability map\n",
      "1 structure-aware random fourier kernel\n",
      "1 random fourier feature\n",
      "1 task inference\n",
      "1 mode connectivity\n",
      "1 stochastic optimal control\n",
      "1 input-affine systems\n",
      "1 fenchel duality\n",
      "1 computational complexity.\n",
      "1 similarity transfer\n",
      "1 neural network architecture\n",
      "1 influence function\n",
      "1 tracin\n",
      "1 instance-based interpretability\n",
      "1 stochastic depth\n",
      "1 multi-view clustering\n",
      "1 subspace clustering\n",
      "1 causal bandit\n",
      "1 partial multi-label learning，mutual information\n",
      "1 dynamic pickup and delivery problem\n",
      "1 logistics\n",
      "1 under-coverage bias\n",
      "1 wasserstein-2 gradient flows\n",
      "1 jko stepping\n",
      "1 diffusion processes\n",
      "1 optimal transport solvers\n",
      "1 continuous measures\n",
      "1 quadratic cost\n",
      "1 wasserstein-2 distance\n",
      "1 parametric methods\n",
      "1 world modeling\n",
      "1 text games\n",
      "1 abstract meaning representation\n",
      "1 graph ensemble\n",
      "1 2d graphics\n",
      "1 offline policy evaluation\n",
      "1 instance optimality\n",
      "1 scene generation\n",
      "1 kernel density estimation\n",
      "1 class conditional gan\n",
      "1 unbalanced classes\n",
      "1 long-tail distribution\n",
      "1 stiefel manifold\n",
      "1 quadratic optimisation\n",
      "1 permutation synchronisation\n",
      "1 multi-matching\n",
      "1 correspondence problems\n",
      "1 manifold optimisation\n",
      "1 qr decomposition\n",
      "1 orthogonal iteration algorithm\n",
      "1 explainable neural networks\n",
      "1 byzantine\n",
      "1 heterogeneous\n",
      "1 decentralized\n",
      "1 asynchronous\n",
      "1 reflection separation\n",
      "1 interactive network\n",
      "1 relu rectifier\n",
      "1 application of e-commerce market；coupons allocation\n",
      "1 multi-agent trajectory\n",
      "1 natural language inference\n",
      "1 deep kernel learning\n",
      "1 bio-inspired learning\n",
      "1 forgetting\n",
      "1 normalization layers\n",
      "1 batchnorm\n",
      "1 unified framework\n",
      "1 parameterized complexity\n",
      "1 fixed-parameter tractability\n",
      "1 polytree learning\n",
      "1 performance inconsistency\n",
      "1 cellular automata\n",
      "1 checkpointing scheme\n",
      "1 symplectic integrator\n",
      "1 topology inference\n",
      "1 algorithm unrolling\n",
      "1 learning to optimise\n",
      "1 moiré effect\n",
      "1 efficient deep learning\n",
      "1 prunning\n",
      "1 non-stationary task distribution\n",
      "1 dynamic gaussian mixture model\n",
      "1 structural variational inference\n",
      "1 multipartite ranking\n",
      "1 constrained metric\n",
      "1 anderson acceleration\n",
      "1 strategic learning\n",
      "1 pricing\n",
      "1 scene graph generation\n",
      "1 conditional random field\n",
      "1 mean-field variational inference\n",
      "1 restless bandits\n",
      "1 whittle index\n",
      "1 conditional distribution\n",
      "1 mode-covering\n",
      "1 mode-seeking\n",
      "1 simulation\n",
      "1 majority vote\n",
      "1 bound-driven algorithm\n",
      "1 gaussian process regression\n",
      "1 least-squares support vector machine\n",
      "1 policy gradient method\n",
      "1 gradient truncation\n",
      "1 uci adult\n",
      "1 census data\n",
      "1 archaeology\n",
      "1 offline learning\n",
      "1 multiple objectives\n",
      "1 linearized networks\n",
      "1 reward-free mdp\n",
      "1 successor states\n",
      "1 provable representation learning\n",
      "1 look-ahead acquisition\n",
      "1 translation\n",
      "1 graph parameters\n",
      "1 benjamini-schramm convergence\n",
      "1 random sampling\n",
      "1 graph learning theory\n",
      "1 deep-learning framework.\n",
      "1 lqr\n",
      "1 policy gradients\n",
      "1 zero-sum matrix game\n",
      "1 zero-sum markov game\n",
      "1 multiplicative updates\n",
      "1 extragradient methods\n",
      "1 extreme multilabel classification\n",
      "1 locally private data\n",
      "1 online change point detection\n",
      "1 multivariate nonparametric regression\n",
      "1 steerable networks\n",
      "1 message passing networks\n",
      "1 infinite-width limits\n",
      "1 data bias\n",
      "1 linearly realizable optimal q-functions\n",
      "1 sub-optimality gap\n",
      "1 state revisiting\n",
      "1 recursive networks\n",
      "1 convolution networks\n",
      "1 parameter-efficiency\n",
      "1 nlp - nlg - language - summarization - gan - generative - adversarial - discriminator - cooperative - decoding - search - beam\n",
      "1 lasso-type svm\n",
      "1 multi-kernel learning\n",
      "1 deep hashing\n",
      "1 instance level retrieval\n",
      "1 model-free rl\n",
      "1 episodic mdps\n",
      "1 kernel $k$-means，risk bound\n",
      "1 differentiable economics\n",
      "1 human in the loop\n",
      "1 hardware\n",
      "1 systolic array\n",
      "1 tensor core\n",
      "1 performance\n",
      "1 optimal sample complexity\n",
      "1 spectral initialization\n",
      "1 neural stochastic differential equation\n",
      "1 neural ordinary differential equation\n",
      "1 nde\n",
      "1 neural differential equation\n",
      "1 optimise-then-discretise\n",
      "1 optimize-then-discretize\n",
      "1 discretise-then-optimise\n",
      "1 discretize-then-optimize\n",
      "1 evolutionary algorithm\n",
      "1 spatial-filling curve\n",
      "1 imagenet classification\n",
      "1 spurious minima\n",
      "1 bad local minima\n",
      "1 geometric analysis\n",
      "1 l#-convex function minimization\n",
      "1 simulation optimization\n",
      "1 submodular function minimization\n",
      "1 momentum centering\n",
      "1 asynchronous update\n",
      "1 adaptive optimizer\n",
      "1 frank wolfe\n",
      "1 heavy ball momentum\n",
      "1 performer\n",
      "1 slim-performer\n",
      "1 memory efficient\n",
      "1 linear transformer\n",
      "1 singular value decomposition\n",
      "1 enhancement\n",
      "1 video question answering\n",
      "1 data-effeciency reasoning\n",
      "1 estimation\n",
      "1 dimension-free\n",
      "1 resource allocation\n",
      "1 online advertising\n",
      "1 social welfare\n",
      "1 smoothness matrices\n",
      "1 blackwell approachability\n",
      "1 aliasing\n",
      "1 large-scale training\n",
      "1 multi-layer perceptrons\n",
      "1 existential theory of the reals\n",
      "1 er-hardness\n",
      "1 np-hardness.\n",
      "1 ml4code\n",
      "1 bug detection\n",
      "1 world model\n",
      "1 human-object interaction detection\n",
      "1 decision diagrams\n",
      "1 combinatorial congestion game\n",
      "1 saddle-point\n",
      "1 regret minimizer\n",
      "1 parameter-free algorithm\n",
      "1 blackwell's approachability\n",
      "1 regret matching\n",
      "1 low-level vision\n",
      "1 real image denoising\n",
      "1 realistic noisy image generation\n",
      "1 real noise removal\n",
      "1 deep video compression\n",
      "1 conditional coding\n",
      "1 residue coding\n",
      "1 context\n",
      "1 program execution\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 source-free domain adaptation\n",
      "1 reciprocal nearest neighbors\n",
      "1 decision and control\n",
      "1 applications (societal systems)\n",
      "1 laplacian regularization\n",
      "1 spectral filtering\n",
      "1 partial labelling\n",
      "1 vehicle routing problem\n",
      "1 efficient classification\n",
      "1 error correcting output codes\n",
      "1 binary codes\n",
      "1 large-scale classification\n",
      "1 action repetition\n",
      "1 off-policy rl\n",
      "1 sequence similarity\n",
      "1 hyperbolic embeddings\n",
      "1 low-distortion embeddings\n",
      "1 implicit planning\n",
      "1 algorithmic bottleneck\n",
      "1 information-directed sampling\n",
      "1 sparse linear bandits\n",
      "1 bayesian regret\n",
      "1 loss function\n",
      "1 embodied autonomous agents\n",
      "1 lipschitz optimization\n",
      "1 packing bound\n",
      "1 function-dependent bound\n",
      "1 piyavskii-shubert algorithm\n",
      "1 ai alignment\n",
      "1 mdp theory\n",
      "1 optimal policies\n",
      "1 strategic classification\n",
      "1 strategic agents\n",
      "1 few shot learning\n",
      "1 supervised contrastive learning\n",
      "1 cardiac signals\n",
      "1 weight loss landscape\n",
      "1 dynamic gradient projection memory\n",
      "1 sharpness flatten\n",
      "1 quantum learning theory\n",
      "1 continuum-armed bandit\n",
      "1 online learning applications\n",
      "1 factored mdp\n",
      "1 hierarchical latent factor modeling\n",
      "1 fmri analysis\n",
      "1 space-time networks\n",
      "1 memory networks\n",
      "1 autocorrelated errors\n",
      "1 human-in-the-loop learning\n",
      "1 sequential decision-making\n",
      "1 pragmatics\n",
      "1 data-free\n",
      "1 evolution strategies\n",
      "1 model predictive control\n",
      "1 real-time iteration\n",
      "1 deconvolutional networks\n",
      "1 graph generation\n",
      "1 vision and language pre-training\n",
      "1 image-text retrieval\n",
      "1 vision-language reasoning\n",
      "1 dirichlet distribution\n",
      "1 bayesian learning\n",
      "1 movies\n",
      "1 tv\n",
      "1 differential solver\n",
      "1 assignment problem\n",
      "1 stable matching\n",
      "1 graph pre-training\n",
      "1 robustness and consistency\n",
      "1 linear quadratic control\n",
      "1 competitive analysis\n",
      "1 bioimaging\n",
      "1 heterophily\n",
      "1 filterbank\n",
      "1 global optima\n",
      "1 data representation\n",
      "1 voronoi\n",
      "1 random reshuffling\n",
      "1 proximal methods\n",
      "1 proxrr\n",
      "1 fedrr\n",
      "1 data integration\n",
      "1 batch effect correction\n",
      "1 rna-seq\n",
      "1 omics\n",
      "1 transcriptomics\n",
      "1 invariant representations\n",
      "1 tcga\n",
      "1 ccle\n",
      "1 single-cell\n",
      "1 probabilistical modeling\n",
      "1 learning rate schedules\n",
      "1 activation pattern temperature\n",
      "1 cvae\n",
      "1 semi-supervised\n",
      "1 locality\n",
      "1 symmetries\n",
      "1 spherical harmonic\n",
      "1 infinite width\n",
      "1 hyperparameter selection\n",
      "1 non-smooth optimization\n",
      "1 clipping\n",
      "1 high-probability bounds\n",
      "1 mode-switching\n",
      "1 cooperative multi-agent reinforcement learning\n",
      "1 supervised causal learning\n",
      "1 vicinity\n",
      "1 conditional dependency\n",
      "1 entanglement\n",
      "1 learnability\n",
      "1 heavy ball\n",
      "1 cyclical step-sizes\n",
      "1 first-order\n",
      "1 stochastic gradient variational bayes\n",
      "1 wind farms\n",
      "1 balanced representation learning\n",
      "1 cate\n",
      "1 ate\n",
      "1 weak overlap\n",
      "1 limited overlap\n",
      "1 prognostic model\n",
      "1 prognostic score\n",
      "1 gradient conflict\n",
      "1 negative transfer\n",
      "1 values\n",
      "1 justification\n",
      "1 negative consequences\n",
      "1 corporate affiliations\n",
      "1 theory of mind\n",
      "1 target-oriented multi-agent cooperation\n",
      "1 learning bound\n",
      "1 infrastructure\n",
      "1 output layer\n",
      "1 m-estimators\n",
      "1 adaptive parameter tuning\n",
      "1 p/n->const\n",
      "1 huber loss\n",
      "1 elastic-net\n",
      "1 post-processing method\n",
      "1 fairness-accuracy trade-off\n",
      "1 dynamic\n",
      "1 social behavior forecasting\n",
      "1 situated interactions\n",
      "1 free-standing conversations\n",
      "1 complex hyperbolic embeddings\n",
      "1 taxonomy embeddings\n",
      "1 representation learning for hierarchical structures\n",
      "1 multitask learning theory\n",
      "1 cramér distance\n",
      "1 non-crossing quantiles\n",
      "1 atari benchmark\n",
      "1 spectral graph nn\n",
      "1 hybrid perceptual systems\n",
      "1 foveation\n",
      "1 spatially-adaptive computation\n",
      "1 pre-trained language model\n",
      "1 opponent modeling\n",
      "1 chemistry\n",
      "1 behavior cloning\n",
      "1 expert-driven learning\n",
      "1 deep learning compiler\n",
      "1 ideal cache model\n",
      "1 loop tiling\n",
      "1 auto-tuning\n",
      "1 matrix multiplication\n",
      "1 occlusion\n",
      "1 shape bias\n",
      "1 evaluation fairness\n",
      "1 model interpretation\n",
      "1 model bias\n",
      "1 training bias\n",
      "1 edge devices\n",
      "1 digital annealer\n",
      "1 tensor network\n",
      "1 structure search\n",
      "1 image enhancement\n",
      "1 color correction\n",
      "1 color universal design\n",
      "1 color weakness\n",
      "1 cryo-em\n",
      "1 local\n",
      "1 markov potential games\n",
      "1 multi-codebook quantization\n",
      "1 approximate nearest neighbor search\n",
      "1 discrete sampling\n",
      "1 neural nework\n",
      "1 deep\n",
      "1 tp-agreement\n",
      "1 learning order\n",
      "1 spectral bias\n",
      "1 simplicity bias\n",
      "1 easy examples\n",
      "1 hard examples\n",
      "1 principal components\n",
      "1 ml\n",
      "1 linear networks\n",
      "1 over parametrized\n",
      "1 over-parametrized\n",
      "1 implicit differentiation bilevel optimization autodiff\n",
      "1 linear dynamical system\n",
      "1 system identification\n",
      "1 hankel matrix\n",
      "1 graph signal processing\n",
      "1 binary classification\n",
      "1 gershgorin circle theorem\n",
      "1 convex optimization.\n",
      "1 alife\n",
      "1 open-endedness\n",
      "1 free energy\n",
      "1 model-free reinforcement learning\n",
      "1 evolutionary computing\n",
      "1 statistically consistent interpolation\n",
      "1 hilbert kernel regression\n",
      "1 regularisation\n",
      "1 evolutionary computation\n",
      "1 travelling salesman problem\n",
      "1 neural\n",
      "1 time windows\n",
      "1 nlp benchmarks\n",
      "1 glue\n",
      "1 average\n",
      "1 network compression\n",
      "1 hessian approximation\n",
      "1 saliency-based pruning\n",
      "1 hardware aware architecture\n",
      "1 compressed models\n",
      "1 logical reasoning\n",
      "1 machine reading comprehension\n",
      "1 distance correlation\n",
      "1 heterogeneous populations\n",
      "1 cross-lingual word embeddings\n",
      "1 self organizing map\n",
      "1 back propagation\n",
      "1 optimizer comparison\n",
      "1 finding near-stationary points\n",
      "1 performance estimation problem\n",
      "1 mean-square analysis\n",
      "1 sde-based sampling algorithm\n",
      "1 langevin monte carlo\n",
      "1 dimension dependence\n",
      "1 non-asymptotic error analysis\n",
      "1 ipu\n",
      "1 gpu\n",
      "1 hardware-acceleration\n",
      "1 padding\n",
      "1 wikipedia\n",
      "1 floating point representations\n",
      "1 huffman encoding\n",
      "1 vector embedding\n",
      "1 memory-augmented neuronal network\n",
      "1 neural arithmetic logic modules\n",
      "1 division\n",
      "1 analytical inference\n",
      "1 deep q-learning\n"
     ]
    }
   ],
   "source": [
    "keyword_dict = {}\n",
    "for paper_name in paper_by_name_dict:\n",
    "    paper = paper_by_name_dict[paper_name]\n",
    "    for keyword in paper['keywords']:\n",
    "        if keyword.lower() not in keyword_dict:\n",
    "            keyword_dict[keyword.lower()] = 0\n",
    "        keyword_dict[keyword.lower()] += 1\n",
    "    \n",
    "\n",
    "sorted_keyword_occurrences = {k: v for k, v in sorted(keyword_dict.items(), key=lambda item: -item[1])}\n",
    "print('number of distinct keywords: %d' % (len(sorted_keyword_occurrences)))\n",
    "for keyword in sorted_keyword_occurrences:\n",
    "    print(sorted_keyword_occurrences[keyword], keyword)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f58018d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9006cc95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d4b8df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a78c2bf3",
   "metadata": {},
   "source": [
    "### Do the following: 1) filter papers to those containing specific keywords in their abstract, 2) rank papers based on average review scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "54b9ccc0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paper rank: 1\n",
      "Average Rating: 2.5\n",
      "Title: Missing Data Infill with Automunge\n",
      "Keywords: ['missing data', 'tabular', 'infrastructure']\n",
      "Code: None\n",
      "PDF URL: https://openreview.net/pdf/f3577f0d93fad2c50bcf482afeb40dd062e0bb51.pdf\n",
      "Review URL: https://openreview.net/forum?id=o2tx_m7hK3t\n",
      "Venue: NeurIPS 2021 Submitted\n",
      "Abstract: Missing data is a fundamental obstacle in the practice of data science. This paper surveys a few conventions for imputation as available in the Automunge open source python library platform for tabular data preprocessing, including \"ML infill\" in which auto ML models are trained for target features from partitioned extracts of a training set. A series of validation experiments were performed to benchmark imputation scenarios towards downstream model performance, in which it was found for the given benchmark sets that in many cases ML infill outperformed for both numeric and categoric target features, and was otherwise at minimum within noise distributions of the other imputation scenarios. Evidence also suggested supplementing ML infill with the addition of support columns with boolean integer markers signaling presence of infill was usually beneficial to downstream model performance. We consider these results sufficient to recommend defaulting to ML infill for tabular learning, and further recommend supplementing imputations with support columns signaling presence of infill, each as can be prepared with push-button operation in the Automunge library. Our contributions include an auto ML derived missing data imputation library for tabular learning in the python ecosystem, fully integrated into a preprocessing platform with an extensive library of feature transformations, with a novel production friendly implementation that bases imputation models on a designated train set for consistent basis towards additional data.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "paper rank: 2\n",
      "Average Rating: 3.0\n",
      "Title: How not to Lie with a Benchmark: Rearranging NLP Learderboards\n",
      "Keywords: ['benchmarking', 'human evaluation', 'NLP benchmarks', 'GLUE', 'average', 'model evaluation']\n",
      "Code: None\n",
      "PDF URL: https://openreview.net/pdf/f432c7133ff530011e90457581d83d0f4249ce5f.pdf\n",
      "Review URL: https://openreview.net/forum?id=PPGfoNJnLKd\n",
      "Venue: NeurIPS 2021 Submitted\n",
      "Abstract: Proper model ranking and comparison with a human level is an essential requirement for every benchmark to be a reliable measurement of the model quality. Nevertheless, the methods for model comparison could have a fundamental flaw - the arithmetic mean of separate metrics is used for all tasks of different complexity, different size of test and training sets.\n",
      "In this paper, we examine popular NLP benchmarks' overall scoring methods and rearrange the models by geometric and harmonic mean (appropriate for averaging rates) according to their reported results. We analyze several popular benchmarks including GLUE, SuperGLUE, XGLUE, and XTREME. The analysis shows that e.g. human level on SuperGLUE is still not reached, and there is still room for improvement for the current models.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "paper rank: 3\n",
      "Average Rating: 3.3333333333333335\n",
      "Title: CUD-NET: Color Universal Design Neural Filter for the Color Weakness\n",
      "Keywords: ['Computer Vision', 'Image Enhancement', 'Color Correction', 'Color Universal Design', 'Color Weakness']\n",
      "Code: None\n",
      "PDF URL: https://openreview.net/pdf/93e56540fbd46ba8d2d5f451abfd306ea31a3eef.pdf\n",
      "Review URL: https://openreview.net/forum?id=3g5KdPD8LIL\n",
      "Venue: NeurIPS 2021 Submitted\n",
      "Abstract: Information on images should be visually understood to anyone, including the color weakness. However, it is not recognizable if color that seems distorted to the color weakness meets an adjacent object. We suggest CUD-NET based on convolutional deep neural network to generate color universal design (CUD) images that satisfy both color preservation and distinguishment of color for input images. CUD-NET regresses the node point of the piecewise linear function based on information of input images and comprises a specific filter per image. We present the following methods to generate CUD images for the color weakness. First, we refine the CUD dataset on specific criteria by color experts. Second, the input image information is expanded through the pre-processing specialized on the color weakness vision. Third, we suggest a multi-modal feature fusion architecture that combines features to process expanded images. Finally, we suggest a deformable loss function by the composition of the predicted image through the model to avoid the one-to-many problems of the dataset.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "paper rank: 4\n",
      "Average Rating: 3.3333333333333335\n",
      "Title: Unsupervised Dynamic Routing Via Competition Over Network Loss\n",
      "Keywords: ['unsupervised learning', 'deep learning', 'self organizing map', 'back propagation']\n",
      "Code: None\n",
      "PDF URL: https://openreview.net/pdf/a54a990a08d0cc9a8edf7993c5909377cab8a5e2.pdf\n",
      "Review URL: https://openreview.net/forum?id=MWpaHkrsbuo\n",
      "Venue: NeurIPS 2021 Submitted\n",
      "Abstract:   This paper proposes a novel neural network architecture that can simultaneously do normal network optimizing while attaining the ability of unsupervised learning. Almost all existing unsupervised learning algorithms are based on doing calculations on the input space or feature space, this paper proposes a new possibility to discover a structure in the functional space without supervision. Using the self-organizing map over the competition of the loss of individual neural column, we route the input to the most appropriate modules dynamically, by doing this we separate the input functional space into different sub spaces which are represented by each individual neural column. At the end of the paper, we propose several possible architectures based on the philosophy of this paper that could build a neural network system block by block. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "paper rank: 5\n",
      "Average Rating: 3.6666666666666665\n",
      "Title: Rethinking supervised learning: insights from biological learning and from calling it by its name\n",
      "Keywords: ['supervised learning', 'self-supervised learning', 'biological learning', 'generalization']\n",
      "Code: None\n",
      "PDF URL: https://openreview.net/pdf/fa1ee0a75c87373d6bd71d7ed5c58cb2f3210fa3.pdf\n",
      "Review URL: https://openreview.net/forum?id=FjnCWyzXu8m\n",
      "Venue: NeurIPS 2021 Submitted\n",
      "Abstract: The renaissance of artificial neural networks was catalysed by the success of classification models, tagged by the community with the broader term supervised learning. The extraordinary results gave rise to a hype loaded with ambitious promises and overstatements. Soon the community realised that the success owed much to the availability of thousands of labelled examples. And supervised learning went, for many, from glory to shame: Some criticised deep learning as a whole and others proclaimed that the way forward had to be alternatives to supervised learning: predictive, unsupervised, semi-supervised and, more recently, self-supervised learning. However, these seem all brand names, rather than actual categories of a theoretically grounded taxonomy. Moreover, the call to banish supervised learning was motivated by the questionable claim that humans learn with little or no supervision and are capable of robust out-of-distribution generalisation. Here, we review insights about learning and supervision in nature, revisit the notion that learning and generalization are not possible without supervision or inductive biases and argue that we will make better progress if we just call it by its name.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "paper rank: 6\n",
      "Average Rating: 3.6666666666666665\n",
      "Title: Automation for Interpretable Machine Learning Through a Comparison of Loss Functions to Regularisers\n",
      "Keywords: ['regularisation', 'interpretability', 'evolutionary computation', 'neural networks']\n",
      "Code: None\n",
      "PDF URL: https://openreview.net/pdf/a750429d0bc108951cc0b04c882bfaf3fa5e7280.pdf\n",
      "Review URL: https://openreview.net/forum?id=blRJEZfyem\n",
      "Venue: NeurIPS 2021 Submitted\n",
      "Abstract: To increase the ubiquity of machine learning it needs to be automated. Automation is cost-effective as it allows experts to spend less time tuning the approach, which leads to shorter development times. However, while this automation produces highly accurate architectures, they can be uninterpretable, acting as `black-boxes' which produce low conventional errors but fail to model the underlying input-output relationships---the ground truth. This paper explores the use of the Fit to Median Error measure in machine learning regression automation, using evolutionary computation in order to improve the approximation of the ground truth. When used alongside conventional error measures it improves interpretability by regularising learnt input-output relationships to the conditional median. It is  compared to traditional regularisers to illustrate that the use of the Fit to Median Error produces regression neural networks which model more consistent input-output relationships. The problem considered is ship power prediction using a fuel-saving air lubrication system, which is highly stochastic in nature. The networks optimised for their Fit to Median Error are shown to approximate the ground truth more consistently, without sacrificing conventional Minkowski-r error values.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "paper rank: 7\n",
      "Average Rating: 3.75\n",
      "Title: Class-agnostic Reconstruction of Dynamic Objects from Videos\n",
      "Keywords: ['Dynamic reconstruction', 'implicit network', '3D vision']\n",
      "Code: https://jason718.github.io/redo\n",
      "PDF URL: https://openreview.net/pdf/f9f493c725cad449a56520b50f54d91d64abf879.pdf\n",
      "Review URL: https://openreview.net/forum?id=2Y8ikpBg6N8\n",
      "Venue: NeurIPS 2021 Poster\n",
      "Abstract: We introduce REDO, a class-agnostic framework to REconstruct the Dynamic Objects from RGBD or calibrated videos. Compared to prior work, our problem setting is more realistic yet more challenging for three reasons: 1) due to occlusion or camera settings an object of interest may never be entirely visible, but we aim to reconstruct the complete shape; 2) we aim to handle different object dynamics including rigid motion, non-rigid motion, and articulation; 3) we aim to reconstruct different  categories  of  objects  with  one  unified  framework. To  address  these challenges, we develop two novel modules.  First, we introduce a canonical 4D implicit function which is pixel-aligned with aggregated temporal visual cues. Second, we develop a 4D transformation module which captures object dynamics to support temporal propagation and aggregation. We study the efficacy of REDO in extensive experiments on synthetic RGBD video datasets SAIL-VOS 3D and DeformingThings4D++,  and on real-world video data 3DPW. We find REDO outperforms state-of-the-art dynamic reconstruction methods by a margin. In ablation studies we validate each developed component.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "paper rank: 8\n",
      "Average Rating: 3.75\n",
      "Title: Secure Quantized Training for Deep Learning\n",
      "Keywords: ['Federated learning', 'secure multi-party computation', 'quantization', 'deep learning']\n",
      "Code: None\n",
      "PDF URL: https://openreview.net/pdf/5f7f4cf776e6b71bb16bb34a5789990e2240879e.pdf\n",
      "Review URL: https://openreview.net/forum?id=NiM9Q7Z95z\n",
      "Venue: NeurIPS 2021 Submitted\n",
      "Abstract: We have implemented training of neural networks in secure multi-party\n",
      "computation (MPC) using quantization commonly used in said setting. To\n",
      "the best of our knowledge, we are the first to present training of\n",
      "MNIST purely implemented in MPC that comes within one percent of\n",
      "accuracy of training using plaintext computation.  We found that\n",
      "training with MPC is possible, but it takes more epochs and achieves a\n",
      "lower accuracy than the usual CPU/GPU computation.  More concretely,\n",
      "we have trained a network with two convolution and two dense layers to\n",
      "98.5% accuracy in 150 epochs. This took a day in our MPC\n",
      "implementation.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "paper rank: 9\n",
      "Average Rating: 3.75\n",
      "Title: ML Agent Safety Mechanisms based on Counterfactual Planning\n",
      "Keywords: []\n",
      "Code: None\n",
      "PDF URL: https://openreview.net/pdf/f31ee4f61d39873bce5306db2123c86663754283.pdf\n",
      "Review URL: https://openreview.net/forum?id=eedamFFTcK5\n",
      "Venue: NeurIPS 2021 Submitted\n",
      "Abstract: We present counterfactual planning as a design approach for creating a\n",
      "range of safety mechanisms for machine learning agents. \n",
      "We specifically target the safety problem of keeping control over\n",
      "hypothetical future AGI agents.\n",
      "The key step in counterfactual planning is to use the agent's\n",
      "machine learning system to construct a counterfactual world model,\n",
      "designed to be different from the real world the agent is in.  A\n",
      "counterfactual planning agent determines the action that best\n",
      "maximizes expected utility in this counterfactual planning world, and\n",
      "then performs the same action in the real world.\n",
      "The design approach is built around a two-diagram graphical notation\n",
      "that provides a specific vantage point on the construction of online\n",
      "machine learning agents, a vantage point designed to make the problem\n",
      "of control more tractable.\n",
      "We show two examples where the construction of a counterfactual planning world\n",
      "acts to suppress certain unsafe agent incentives, incentives for the\n",
      "agent to take control over its own safety mechanisms.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "paper rank: 10\n",
      "Average Rating: 4.0\n",
      "Title: Multi-Objective Meta Learning\n",
      "Keywords: ['Meta Learning', 'Multi-objective Optimization', 'Bi-level Optimization']\n",
      "Code: https://github.com/Baijiong-Lin/MOML\n",
      "PDF URL: https://openreview.net/pdf/3e1a1bb822b2c85f5773ee4bd93059fd59aaa8e1.pdf\n",
      "Review URL: https://openreview.net/forum?id=UJkPLV6PBr\n",
      "Venue: NeurIPS 2021 Poster\n",
      "Abstract: Meta learning with multiple objectives has been attracted much attention recently since many applications need to consider multiple factors when designing learning models. Existing gradient-based works on meta learning with multiple objectives mainly combine multiple objectives into a single objective in a weighted sum manner. This simple strategy usually works but it requires to tune the weights associated with all the objectives, which could be time consuming. Different from those works, in this paper, we propose a gradient-based Multi-Objective Meta Learning (MOML) framework without manually tuning weights. Specifically, MOML formulates the objective function of meta learning with multiple objectives as a Multi-Objective Bi-Level optimization Problem (MOBLP) where the upper-level subproblem is to solve several possibly conflicting objectives for the meta learner. To solve the MOBLP, we devise the first gradient-based optimization algorithm by alternatively solving the lower-level and upper-level subproblems via the gradient descent method and the gradient-based multi-objective optimization method, respectively. Theoretically, we prove the convergence properties of the proposed gradient-based optimization algorithm. Empirically, we show the effectiveness of the proposed MOML framework in several meta learning problems, including few-shot learning, domain adaptation, multi-task learning, and neural architecture search. The source code of MOML is available at https://github.com/Baijiong-Lin/MOML.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "paper rank: 11\n",
      "Average Rating: 4.0\n",
      "Title: On the Fundamental Trade-offs in Learning Invariant Representations\n",
      "Keywords: ['Utility', 'Invariance', 'Trade-off', 'Kernel Method', 'Global Optima']\n",
      "Code: None\n",
      "PDF URL: https://openreview.net/pdf/454c1ae72cc2fd2990aa0660e1a4993e897d2f79.pdf\n",
      "Review URL: https://openreview.net/forum?id=KOk7mUGspN9\n",
      "Venue: NeurIPS 2021 Submitted\n",
      "Abstract: Many applications of representation learning, such as privacy-preservation, algorithmic fairness and domain adaptation, desire explicit control over semantic information being discarded. This goal is often formulated as satisfying two potentially competing objectives: maximizing utility for predicting a target attribute while simultaneously being independent or invariant with respect to a known semantic attribute. In this paper, we \\emph{identify and determine} two fundamental trade-offs between utility and semantic dependence induced by the statistical dependencies between the data and its corresponding target and semantic attributes. We derive closed-form solutions for the global optima of the underlying optimization problems under mild assumptions, which in turn yields closed formulae for the exact trade-offs. We also derive empirical estimates of the trade-offs and show their convergence to the corresponding population counterparts. Finally, we numerically quantify the trade-offs on representative problems and compare the solutions achieved by baseline representation learning algorithms.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "paper rank: 12\n",
      "Average Rating: 4.0\n",
      "Title: A Cramér Distance perspective on Non-crossing Quantile Regression in Distributional Reinforcement Learning\n",
      "Keywords: ['Distributional Reinforcement Learning', 'Cramér distance', 'Quantile regression', 'Wasserstein distance', 'Non-crossing quantiles', 'Neural networks', 'Atari benchmark']\n",
      "Code: None\n",
      "PDF URL: https://openreview.net/pdf/65d3865585782ea478b6285cede157094565ac40.pdf\n",
      "Review URL: https://openreview.net/forum?id=weBSeGTv0i\n",
      "Venue: NeurIPS 2021 Submitted\n",
      "Abstract: Distributional reinforcement learning (DRL) extends the value-based approach by estimating the full distribution over future returns instead of the mean only, providing a richer signal that leads to improved performances. Quantile-based methods like QR-DQN project arbitrary distributions into a parametric subset of staircase distributions by minimizing the 1-Wasserstein distance, however,  due to biases in the gradients, the quantile regression loss is used instead for training, guaranteeing the same minimizer and enjoying unbiased gradients. Recently, monotonicity constraints on the quantiles have been shown  to improve the performance of QR-DQN for uncertainty-based exploration strategies. The contribution of this work is in the setting of fixed quantile levels and is twofold.  First, we prove that the Cramér distance yields a projection that coincides with the 1-Wasserstein one and that, under monotonicity constraints, the squared Cramér and the quantile regression losses yield collinear gradients, shedding light on the connection between these important elements of DRL. Second, we propose a novel non-crossing neural architecture that allows a good training performance using the Cramér distance, yielding significant improvements over QR-DQN in a number of games of the standard Atari 2600 benchmark.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "paper rank: 13\n",
      "Average Rating: 4.0\n",
      "Title: One-to-many Approach for Improving Super-Resolution\n",
      "Keywords: ['Super resolution', 'Deep learning']\n",
      "Code: None\n",
      "PDF URL: https://openreview.net/pdf/77920d409f912a44c28bff80aa75298f5ef59bd9.pdf\n",
      "Review URL: https://openreview.net/forum?id=Kai3KkCOCp\n",
      "Venue: NeurIPS 2021 Submitted\n",
      "Abstract: Super-resolution (SR) is a one-to-many task with multiple possible solutions. However, previous works were not concerned about this characteristic. For a one-to-many pipeline, the generator should be able to generate multiple estimates of the reconstruction, and not be penalized for generating similar and equally realistic images. To achieve this, we propose adding weighted pixel-wise noise after every Residual-in-Residual Dense Block (RRDB) to enable the generator to generate various images. We modify the strict content loss to not penalize the stochastic variation in reconstructed images as long as it has consistent content. Additionally, we observe that there are out-of-focus regions in the DIV2K, DIV8K datasets that provide unhelpful guidelines. We filter blurry regions in the training data using the method of [10]. Finally, we modify the discriminator to receive the low-resolution image as a reference image along with the target image to provide better feedback to the generator. Using our proposed methods, we were able to improve the performance of ESRGAN in x4 perceptual SR and achieve the state-of-the-art LPIPS score in x16 perceptual extreme SR.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "paper rank: 14\n",
      "Average Rating: 4.0\n",
      "Title: Persistent Homology Captures the Generalization of Neural Networks Without A Validation Set\n",
      "Keywords: ['Neural Networks', 'Topological Data Analysis', 'learning', 'evolution', 'Persistent Homology']\n",
      "Code: None\n",
      "PDF URL: https://openreview.net/pdf/7402936887aa75f614248f26d840b54261bc573f.pdf\n",
      "Review URL: https://openreview.net/forum?id=BM64dm9HvN\n",
      "Venue: NeurIPS 2021 Submitted\n",
      "Abstract: The training of neural networks is usually monitored with a validation (holdout) set to estimate the generalization of the model. This is done instead of measuring intrinsic properties of the model to determine whether it is learning appropriately. In this work, we suggest studying the training of neural networks with Algebraic Topology, specifically Persistent Homology (PH). Using simplicial complex representations of neural networks, we study the PH diagram distance evolution on the neural network learning process with different architectures and several datasets. Results show that the PH diagram distance between consecutive neural network states correlates with the validation accuracy, implying that the generalization error of a neural network could be intrinsically estimated without any holdout set.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "paper rank: 15\n",
      "Average Rating: 4.0\n",
      "Title: baller2vec++: A Look-Ahead Multi-Entity Transformer For Modeling Coordinated Agents\n",
      "Keywords: []\n",
      "Code: None\n",
      "PDF URL: https://openreview.net/pdf/69a9ab10a41ed01a596b44f70676192692e447a2.pdf\n",
      "Review URL: https://openreview.net/forum?id=p2XgjS3Qp4X\n",
      "Venue: NeurIPS 2021 Submitted\n",
      "Abstract: In many multi-agent spatiotemporal systems, the agents are under the influence of shared, unobserved variables (e.g., the play a team is executing in a game of basketball). As a result, the trajectories of the agents are often statistically dependent at any given time step; however, almost universally, multi-agent models implicitly assume the agents' trajectories are statistically independent at each time step. In this paper, we introduce baller2vec++, a multi-entity Transformer that can effectively model coordinated agents. Specifically, baller2vec++ applies a specially designed self-attention mask to a mixture of location and \"look-ahead\" trajectory sequences to learn the distributions of statistically dependent agent trajectories. We show that, unlike baller2vec (baller2vec++'s predecessor), baller2vec++ can learn to emulate the behavior of perfectly coordinated agents in a simulated toy dataset. Additionally, when modeling the trajectories of professional basketball players, baller2vec++ outperforms baller2vec by a wide margin.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "paper rank: 16\n",
      "Average Rating: 4.166666666666667\n",
      "Title: Data augmentation for efficient learning from parametric experts\n",
      "Keywords: ['behavior cloning', 'expert-driven learning']\n",
      "Code: None\n",
      "PDF URL: https://openreview.net/pdf/3d3dddd0c7ac9fcd9703dd332c597914069ed434.pdf\n",
      "Review URL: https://openreview.net/forum?id=MdZPf3qCF7s\n",
      "Venue: NeurIPS 2021 Submitted\n",
      "Abstract: We present a simple, yet powerful data-augmentation technique to enable data-efficient learning from parametric experts. Whereas behavioral cloning refers to learning from samples of an expert, we focus here on what we refer to as the policy cloning setting which allows for offline queries of an expert or expert policy. This setting arises naturally in a number of problems, especially as a component of other algorithms. We achieve a very high level of data efficiency in transferring behavior from an expert to a student policy for high Degrees of Freedom (DoF) control problems using our augmented policy cloning (APC) approach, which combines conventional image-based data augmentation to build invariance to image perturbations with an expert-aware offline data augmentation approach that induces appropriate feedback-sensitivity in a region around expert trajectories. We show that our method increases data-efficiency of policy cloning, enabling transfer of complex high-DoF behaviours from just a few trajectories, and we also show benefits of our approach in the context of algorithms in which policy cloning is a constituent part.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "paper rank: 17\n",
      "Average Rating: 4.25\n",
      "Title: Recursive Bayesian Networks: Generalising and Unifying Probabilistic Context-Free Grammars and Dynamic Bayesian Networks\n",
      "Keywords: ['Bayesian networks', 'graphical models', 'probabilistic context-free grammars', 'structure learning', 'parsing', 'mixed discrete-continuous', 'sequence models', 'tree induction']\n",
      "Code: https://github.com/robert-lieck/RBN\n",
      "PDF URL: https://openreview.net/pdf/43b82240863597ba97d502dc5a112c47c6a9c106.pdf\n",
      "Review URL: https://openreview.net/forum?id=MdS0CgsH6Lf\n",
      "Venue: NeurIPS 2021 Poster\n",
      "Abstract: Probabilistic context-free grammars (PCFGs) and dynamic Bayesian networks (DBNs) are widely used sequence models with complementary strengths and limitations. While PCFGs allow for nested hierarchical dependencies (tree structures), their latent variables (non-terminal symbols) have to be discrete. In contrast, DBNs allow for continuous latent variables, but the dependencies are strictly sequential (chain structure). Therefore, neither can be applied if the latent variables are assumed to be continuous and also to have a nested hierarchical dependency structure. In this paper, we present Recursive Bayesian Networks (RBNs), which generalise and unify PCFGs and DBNs, combining their strengths and containing both as special cases. RBNs define a joint distribution over tree-structured Bayesian networks with discrete or continuous latent variables. The main challenge lies in performing joint inference over the exponential number of possible structures and the continuous variables. We provide two solutions: 1) For arbitrary RBNs, we generalise inside and outside probabilities from PCFGs to the mixed discrete-continuous case, which allows for maximum posterior estimates of the continuous latent variables via gradient descent, while marginalising over network structures. 2) For Gaussian RBNs, we additionally derive an analytic approximation of the marginal data likelihood (evidence) and marginal posterior distribution, allowing for robust parameter optimisation and Bayesian inference. The capacity and diverse applications of RBNs are illustrated on two examples: In a quantitative evaluation on synthetic data, we demonstrate and discuss the advantage of RBNs for segmentation and tree induction from noisy sequences, compared to change point detection and hierarchical clustering. In an application to musical data, we approach the unsolved problem of hierarchical music analysis from the raw note level and compare our results to expert annotations.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "paper rank: 18\n",
      "Average Rating: 4.25\n",
      "Title: Asymptotically Best Causal Effect Identification with Multi-Armed Bandits\n",
      "Keywords: ['causal identification formulas', 'frontdoor criterion', 'adjustment criterion', 'causal inference', 'multi armed bandits', 'best-arm-identification', 'confidence sequences', 'double machine learning', 'causal effect estimator', 'nuisance parameter']\n",
      "Code: None\n",
      "PDF URL: https://openreview.net/pdf/b30835f67adc478c21a7a1cb5244f2c14ef3f9f9.pdf\n",
      "Review URL: https://openreview.net/forum?id=1dqrBgHYC0d\n",
      "Venue: NeurIPS 2021 Poster\n",
      "Abstract: This paper considers the problem of selecting a formula for identifying a causal quantity of interest among a set of available formulas. We assume an online setting in which the investigator may alter the data collection mechanism in a data-dependent way with the aim of identifying the formula with lowest asymptotic variance in as few samples as possible. We formalize this setting by using the best-arm-identification bandit framework where the standard goal of learning the arm with the lowest loss is replaced with the goal of learning the arm that will produce the best estimate. We introduce new tools for constructing finite-sample confidence bounds on estimates of the asymptotic variance that account for the estimation of potentially complex nuisance functions, and adapt the best-arm-identification algorithms of LUCB and Successive Elimination to use these bounds. We validate our method by providing upper bounds on the sample complexity and an empirical study on artificially generated data.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "paper rank: 19\n",
      "Average Rating: 4.25\n",
      "Title: EditGAN: High-Precision Semantic Image Editing\n",
      "Keywords: ['generative adversarial networks', 'image editing']\n",
      "Code: None\n",
      "PDF URL: https://openreview.net/pdf/64c953b56180826b43303ee0a72794cc7a33b8dc.pdf\n",
      "Review URL: https://openreview.net/forum?id=jLHWRxwc7_f\n",
      "Venue: NeurIPS 2021 Poster\n",
      "Abstract: Generative adversarial networks (GANs) have recently found applications in image editing. However, most GAN-based image editing methods often require large-scale datasets with semantic segmentation annotations for training, only provide high-level control, or merely interpolate between different images. Here, we propose EditGAN, a novel method for high-quality, high-precision semantic image editing, allowing users to edit images by modifying their highly detailed part segmentation masks, e.g., drawing a new mask for the headlight of a car. EditGAN builds on a GAN framework that jointly models images and their semantic segmentation, requiring only a handful of labeled examples – making it a scalable tool for editing. Specifically, we embed an image into the GAN’s latent space and perform conditional latent code optimization according to the segmentation edit, which effectively also modifies the image. To amortize optimization, we find “editing vectors” in latent space that realize the edits. The framework allows us to learn an arbitrary number of editing vectors, which can then be directly applied on other images at interactive rates. We experimentally show that EditGAN can manipulate images with an unprecedented level of detail and freedom while preserving full image quality. We can also easily combine multiple edits and perform plausible edits beyond EditGAN’s training data. We demonstrate EditGAN on a wide variety of image types and quantitatively outperform several previous editing methods on standard editing benchmark tasks.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "paper rank: 20\n",
      "Average Rating: 4.25\n",
      "Title: STEP: Out-of-Distribution Detection in the Presence of Limited In-Distribution Labeled Data\n",
      "Keywords: ['weakly supervised learning', 'semi-supervised learning', 'out-of-distribution detection']\n",
      "Code: https://www.lamda.nju.edu.cn/code_step.ashx\n",
      "PDF URL: https://openreview.net/pdf/a55520d2853f323cfadd1b52aad32e65a043f45b.pdf\n",
      "Review URL: https://openreview.net/forum?id=Xw7749MxtPV\n",
      "Venue: NeurIPS 2021 Poster\n",
      "Abstract: Existing semi-supervised learning (SSL) studies typically assume that unlabeled and test data are drawn from the same distribution as labeled data. However, in many real-world applications, it is desirable to have SSL algorithms that not only classify the samples drawn from the same distribution of labeled data but also detect out-of-distribution (OOD) samples drawn from an unknown distribution. In this paper, we study a setting called semi-supervised OOD detection. Two main challenges compared with previous OOD detection settings are i) the lack of labeled data and in-distribution data; ii) OOD samples could be unseen during training. Efforts on this direction remain limited. In this paper, we present an approach STEP significantly improving OOD detection performance by introducing a new technique: Structure-Keep Unzipping. It learns a new representation space in which OOD samples could be separated well. An efficient optimization algorithm is derived to solve the objective. Comprehensive experiments across various OOD detection benchmarks clearly show that our STEP approach outperforms other methods by a large margin and achieves remarkable detection performance on several benchmarks. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "paper rank: 21\n",
      "Average Rating: 4.25\n",
      "Title: CorticalFlow: A Diffeomorphic Mesh Transformer Network for Cortical Surface Reconstruction\n",
      "Keywords: ['3D Deep Learning', 'Geometric Deep Learning', 'Regular Surface Recosntruction', 'Cortical Surface Reconstruction']\n",
      "Code: https://lebrat.github.io/CorticalFlow/\n",
      "PDF URL: https://openreview.net/pdf/54f2eb9b260b4d1b5f9ed43612200ed0fd9ec435.pdf\n",
      "Review URL: https://openreview.net/forum?id=wDI6CNTR3yP\n",
      "Venue: NeurIPS 2021 Poster\n",
      "Abstract: In this paper, we introduce CorticalFlow, a new geometric deep-learning model that, given a 3-dimensional image, learns to deform a reference template towards a targeted object. To conserve the template mesh’s topological properties, we train our model over a set of diffeomorphic transformations. This new implementation of a flow Ordinary Differential Equation (ODE) framework benefits from a small GPU memory footprint, allowing the generation of surfaces with several hundred thousand vertices. To reduce topological errors introduced by its discrete resolution, we derive numeric conditions which improve the manifoldness of the predicted triangle mesh. To exhibit the utility of CorticalFlow, we demonstrate its performance for the challenging task of brain cortical surface reconstruction. In contrast to the current state-of-the-art, CorticalFlow produces superior surfaces while reducing the computation time from nine and a half minutes to one second. More significantly, CorticalFlow enforces the generation of anatomically plausible surfaces; the absence of which has been a major impediment restricting the clinical relevance of such surface reconstruction methods.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "paper rank: 22\n",
      "Average Rating: 4.25\n",
      "Title: Weak-shot Fine-grained Classification via Similarity Transfer\n",
      "Keywords: ['transfer learning', 'similarity transfer', 'weak-shot learning']\n",
      "Code: None\n",
      "PDF URL: https://openreview.net/pdf/7e17cc05eddab327ccfcf43f12cc2f72f5c31acf.pdf\n",
      "Review URL: https://openreview.net/forum?id=wDJUUcCTNI2\n",
      "Venue: NeurIPS 2021 Poster\n",
      "Abstract: Recognizing fine-grained categories remains a challenging task, due to the subtle distinctions among different subordinate categories, which results in the need of abundant annotated samples. To alleviate the data-hungry problem, we consider the problem of learning novel categories from web data with the support of a clean set of base categories, which is referred to as weak-shot learning. In this setting, we propose a method called SimTrans to transfer pairwise semantic similarity from base categories to novel categories. Specifically, we firstly train a similarity net on clean data, and then leverage the transferred similarity to denoise web training data using two simple yet effective strategies. In addition, we apply adversarial loss on similarity net to enhance the transferability of similarity. Comprehensive experiments demonstrate the effectiveness of our weak-shot setting and our SimTrans method. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "paper rank: 23\n",
      "Average Rating: 4.25\n",
      "Title: Watching Too Much Television is Good: Self-Supervised Audio-Visual Representation Learning from Movies and TV Shows\n",
      "Keywords: ['self-supervised learning', 'contrastive loss', 'multi-modal', 'audio', 'video', 'movies', 'TV']\n",
      "Code: None\n",
      "PDF URL: https://openreview.net/pdf/c61a60ae6ba80104808a4cf9a35a0c845c3ce509.pdf\n",
      "Review URL: https://openreview.net/forum?id=8hGabvaV2GQ\n",
      "Venue: NeurIPS 2021 Submitted\n",
      "Abstract:     The abundance and ease of utilizing sound, along with the fact that auditory clues reveal so much about what happens in the scene, make the audio-visual space a perfectly intuitive choice for self-supervised representation learning. However, the current literature suggests that training on \\textit{uncurated} data yields considerably poorer representations compared to the \\textit{curated} alternatives collected in supervised manner, and the gap only narrows when the volume of data significantly increases. Furthermore, the quality of learned representations is known to be heavily influenced by the size and taxonomy of the curated datasets used for self-supervised training. This begs the question of whether we are celebrating too early on catching up with supervised learning when our self-supervised efforts still rely almost exclusively on curated data. In this paper, we study the efficacy of learning from Movies and TV Shows as forms of uncurated data for audio-visual self-supervised learning. We demonstrate that a simple model based on contrastive learning, trained on a collection of movies and TV shows, not only dramatically outperforms more complex methods which are trained on orders of magnitudes larger uncurated datasets, but also performs very competitively with the state-of-the-art that learns from large-scale curated data. We identify that audiovisual patterns like the appearance of the main character or prominent scenes and mise-en-scène which frequently occur through the whole duration of a movie, lead to an overabundance of easy negative instances in the contrastive learning formulation. Capitalizing on such observation, we propose a hierarchical sampling policy, which despite its simplicity, effectively improves the performance, particularly when learning from TV shows which naturally face less semantic diversity.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "paper rank: 24\n",
      "Average Rating: 4.25\n",
      "Title: Improving Entropic Out-of-Distribution Detection using Isometric Distances and the Minimum Distance Score\n",
      "Keywords: ['Out-of-distribution detection']\n",
      "Code: None\n",
      "PDF URL: https://openreview.net/pdf/4491a49eb2f80239d16d6797ccac22a83caf3adc.pdf\n",
      "Review URL: https://openreview.net/forum?id=f4jw35Vrk6d\n",
      "Venue: NeurIPS 2021 Submitted\n",
      "Abstract: Current out-of-distribution detection approaches usually present special requirements (e.g., collecting outlier data and hyperparameter validation) and produce side effects (classification accuracy drop and slow/inefficient inferences). Recently, entropic out-of-distribution detection has been proposed as a seamless approach (i.e., a solution that avoids all the previously mentioned drawbacks). The entropic out-of-distribution detection solution comprises the IsoMax loss for training and the entropic score for out-of-distribution detection. The IsoMax loss works as a SoftMax loss drop-in replacement because swapping the SoftMax loss with the IsoMax loss requires no changes in the model's architecture or training procedures/hyperparameters. In this paper, we propose to perform what we call an isometrization of the distances used in the IsoMax loss. Additionally, we propose to replace the entropic score with the minimum distance score. Our experiments showed that these simple modifications increase out-of-distribution detection performance while keeping the solution seamless.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "paper rank: 25\n",
      "Average Rating: 4.25\n",
      "Title: Characterizing and Measuring the Similarity of Neural Networks with Persistent Homology\n",
      "Keywords: ['Neural Networks', 'Topological Data Analysis', 'similarity', 'Persistent Homology']\n",
      "Code: None\n",
      "PDF URL: https://openreview.net/pdf/23250b242a7c0bf314037e1c2c50e08e3ecd14f0.pdf\n",
      "Review URL: https://openreview.net/forum?id=Y4RJQO2jivm\n",
      "Venue: NeurIPS 2021 Submitted\n",
      "Abstract: Characterizing the structural properties of neural networks is crucial yet poorly understood, and there are no well-established similarity measures between networks. In this work, we observe that neural networks can be represented as abstract simplicial complex and analyzed using their topological 'fingerprints' via Persistent Homology (PH). We then describe a PH-based representation proposed for characterizing and measuring similarity of neural networks. We empirically show the effectiveness of this representation as a descriptor of different architectures in several datasets. This approach based on Topological Data Analysis is a step towards better understanding neural networks and serves as a useful similarity measure.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "paper rank: 26\n",
      "Average Rating: 4.25\n",
      "Title: Pairwise Adjusted Mutual Information\n",
      "Keywords: ['Clustering', 'Metrics', 'Information Theory.']\n",
      "Code: None\n",
      "PDF URL: https://openreview.net/pdf/6083e956629a0efa9899445c06288fb0ad6af3d9.pdf\n",
      "Review URL: https://openreview.net/forum?id=5GihaaZKL4\n",
      "Venue: NeurIPS 2021 Submitted\n",
      "Abstract: A well-known metric for quantifying the similarity between two clusterings is the adjusted mutual information. Compared to mutual information, a corrective term based on random permutations of the labels is introduced, preventing two clusterings being similar by chance. Unfortunately, this adjustment makes the metric computationally expensive. In this paper, we propose a novel adjustment based on pairwise label permutations instead of full label permutations. Specifically, we consider permutations where only two samples, selected uniformly at random, exchange their labels. We show that the corresponding adjusted metric, which can be expressed explicitly, behaves similarly to the standard adjusted mutual information for assessing the quality of a clustering, while having a much lower time complexity. Both metrics are compared in terms of quality and performance on experiments based on synthetic and real data.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "paper rank: 27\n",
      "Average Rating: 4.25\n",
      "Title: baller2vec: A Multi-Entity Transformer For Multi-Agent Spatiotemporal Modeling\n",
      "Keywords: ['Representation learning']\n",
      "Code: None\n",
      "PDF URL: https://openreview.net/pdf/4125da8426c62841bc35c1047e12d67fc9d8c1a4.pdf\n",
      "Review URL: https://openreview.net/forum?id=OsBM0sWwn_-\n",
      "Venue: NeurIPS 2021 Submitted\n",
      "Abstract: Multi-agent spatiotemporal modeling is a challenging task from both an algorithmic design and computational complexity perspective. Recent work has explored the efficacy of traditional deep sequential models in this domain, but these architectures are slow and cumbersome to train, particularly as model size increases. Further, prior attempts to model interactions between agents across time have limitations, such as imposing an order on the agents, or making assumptions about their relationships. In this paper, we introduce baller2vec, a multi-entity generalization of the standard Transformer that can, with minimal assumptions, simultaneously and efficiently integrate information across entities and time. We test the effectiveness of baller2vec for multi-agent spatiotemporal modeling by training it to perform two different basketball-related tasks: (1) simultaneously forecasting the trajectories of all players on the court and (2) forecasting the trajectory of the ball. Not only does baller2vec learn to perform these tasks well (outperforming a graph recurrent neural network with a similar number of parameters by a wide margin), it also appears to \"understand\" the game of basketball, encoding idiosyncratic qualities of players in its embeddings, and performing basketball-relevant functions with its attention heads.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "paper rank: 28\n",
      "Average Rating: 4.333333333333333\n",
      "Title: Learning Graph Models for Retrosynthesis Prediction\n",
      "Keywords: ['Retrosynthesis', 'Graph-Neural Networks', 'Synthons', 'Computational Chemistry']\n",
      "Code: https://github.com/vsomnath/graphretro\n",
      "PDF URL: https://openreview.net/pdf/48750760469fca61a21a9d19ac22a9fda17ca887.pdf\n",
      "Review URL: https://openreview.net/forum?id=LyjH88yV7F\n",
      "Venue: NeurIPS 2021 Poster\n",
      "Abstract: Retrosynthesis prediction is a fundamental problem in organic synthesis, where the task is to identify precursor molecules that can be used to synthesize a target molecule. A key consideration in building neural models for this task is aligning model design with strategies adopted by chemists. Building on this viewpoint, this paper introduces a graph-based approach that capitalizes on the idea that the graph topology of precursor molecules is largely unaltered during a chemical reaction. The model first predicts the set of graph edits transforming the target into incomplete molecules called synthons. Next, the model learns to expand synthons into complete molecules by attaching relevant leaving groups. This decomposition simplifies the architecture, making its predictions more interpretable, and also amenable to manual correction. Our model achieves a top-1 accuracy of 53.7%, outperforming previous template-free and semi-template-based methods.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "paper rank: 29\n",
      "Average Rating: 4.333333333333333\n",
      "Title: Understanding End-to-End Model-Based Reinforcement Learning Methods as Implicit Parameterization\n",
      "Keywords: ['model-based', 'reinforcement learning', 'end-to-end', 'implicit']\n",
      "Code: https://github.com/gehring/implicit-estimators\n",
      "PDF URL: https://openreview.net/pdf/de18a130824814608f5dd275b9f5b090b4872394.pdf\n",
      "Review URL: https://openreview.net/forum?id=c2UNM5HRrI\n",
      "Venue: NeurIPS 2021 Poster\n",
      "Abstract: Estimating the per-state expected cumulative rewards is a critical aspect of reinforcement learning approaches, however the experience is obtained, but standard deep neural-network function-approximation methods are often inefficient in this setting. An alternative approach, exemplified by value iteration networks, is to learn transition and reward models of a latent Markov decision process whose value predictions fit the data. This approach has been shown empirically to converge faster to a more robust solution in many cases, but there has been little theoretical study of this phenomenon. In this paper, we explore such implicit representations of value functions via theory and focused experimentation. We prove that, for a linear parametrization, gradient descent converges to global optima despite non-linearity and non-convexity introduced by the implicit representation. Furthermore, we derive convergence rates for both cases which allow us to identify conditions under which stochastic gradient descent (SGD) with this implicit representation converges substantially faster than its explicit counterpart. Finally, we provide empirical results in some simple domains that illustrate the theoretical findings.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "paper rank: 30\n",
      "Average Rating: 4.333333333333333\n",
      "Title: On the Role of Optimization in Double Descent: A Least Squares Study\n",
      "Keywords: ['Double Descent', 'Optimization Error', 'Excess Risk', 'Generalization', 'Least Squares']\n",
      "Code: None\n",
      "PDF URL: https://openreview.net/pdf/a9555d7890f81f1e1601e1e90c85f38e2477ba5b.pdf\n",
      "Review URL: https://openreview.net/forum?id=zzSVN5x8JiX1m\n",
      "Venue: NeurIPS 2021 Poster\n",
      "Abstract: Empirically it has been observed that the performance of deep neural networks steadily improves as we increase model size, contradicting the classical view on overfitting and generalization. Recently, the double descent phenomena has been proposed to reconcile this observation with theory, suggesting that the test error has a second descent when the model becomes sufficiently overparametrized, as the model size itself acts as an implicit regularizer. In this paper we add to the growing body of work in this space, providing a careful study of learning dynamics as a function of model size for the least squares scenario. We show an excess risk bound for the gradient descent solution of the least squares objective. The bound depends on the smallest non-zero eigenvalue of the sample covariance matrix of the input features, via a functional form that has the double descent behaviour. This gives a new perspective on the double descent curves reported in the literature, as our analysis of the excess risk allows to decouple the effect of optimization and generalization error. In particular, we find that in case of noiseless regression, double descent is explained solely by optimization-related quantities, which was missed in studies focusing on the Moore-Penrose pseudoinverse solution. We believe that our derivation provides an alternative view compared to existing work, shedding some light on a possible cause of this phenomena, at least in the considered least squares setting. We empirically explore if our predictions hold for neural networks, in particular whether the spectrum of the sample covariance of intermediary hidden layers has a similar behaviour as the one predicted by our derivations.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "paper rank: 31\n",
      "Average Rating: 4.333333333333333\n",
      "Title: Efficient Statistical Assessment of Neural Network Corruption Robustness\n",
      "Keywords: ['deep learning', 'robustess', 'reliability', 'Monte Carlo']\n",
      "Code: https://github.com/karimtito/efficient-statistical\n",
      "PDF URL: https://openreview.net/pdf/5058fb60eb54eb037bafe1e22cf88d0b3152fd7e.pdf\n",
      "Review URL: https://openreview.net/forum?id=RR16clcsH7\n",
      "Venue: NeurIPS 2021 Poster\n",
      "Abstract: We quantify the robustness of a trained network to input uncertainties with a stochastic simulation inspired by the field of Statistical Reliability Engineering. The robustness assessment is cast as a statistical hypothesis test: the network is deemed as locally robust if the estimated probability of failure is lower than a critical level.\n",
      "The procedure is based on an Importance Splitting simulation generating samples of rare events. We derive theoretical guarantees that are non-asymptotic w.r.t. sample size. Experiments tackling large scale networks outline the efficiency of our method making a low number of calls to the network function. \n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "search_keywords = ['']\n",
    "\n",
    "filtered_papers = []\n",
    "for paper_name in paper_by_name_dict:\n",
    "    paper = paper_by_name_dict[paper_name]\n",
    "    abstract = paper['abstract'].lower()\n",
    "    \n",
    "    found_search_keywords = True\n",
    "    for search_keyword in search_keywords:\n",
    "        if search_keyword not in abstract:\n",
    "            found_search_keywords = False\n",
    "            \n",
    "    if found_search_keywords == False:\n",
    "        print('bad')\n",
    "        continue\n",
    "    \n",
    "    ratings = []\n",
    "    for rating in paper['rating_list']:\n",
    "        ratings.append(float(rating.split(':')[0]))\n",
    "    if len(ratings) == 0:\n",
    "        ratings.append(-1)\n",
    "    \n",
    "    \n",
    "    filtered_papers.append( (np.mean(ratings), paper))\n",
    "    \n",
    "sorted_filtered_papers = sorted(filtered_papers, key=lambda paper: paper[0], reverse=False)\n",
    "average_ratings = [x[0] for x in filtered_papers]\n",
    "\n",
    "\n",
    "\n",
    "paper_id = 0\n",
    "for average_rating, paper in sorted_filtered_papers:\n",
    "    paper_id += 1\n",
    "    print('paper rank: %d' % (paper_id))\n",
    "    print('Average Rating:', average_rating)\n",
    "    print('Title:', paper['title'])\n",
    "    print('Keywords:', paper['keywords'])\n",
    "    print('Code:', paper['code'])\n",
    "    print('PDF URL:', paper['pdf'])\n",
    "    print('Review URL:', paper['url'])\n",
    "    print('Venue:',paper['venue'])\n",
    "    print('Abstract:',paper['abstract'])\n",
    "    \n",
    "    print('\\n\\n\\n')\n",
    "    \n",
    "    if paper_id > 30:\n",
    "        break\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f55423c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3b069263",
   "metadata": {},
   "source": [
    "### Plot average rating histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b161f7c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Histogram of paper average rating')"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.hist(average_ratings)\n",
    "plt.xlabel('Average rating')\n",
    "plt.ylabel('Number of papers')\n",
    "plt.title('Histogram of paper average rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b98ca5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911709cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
